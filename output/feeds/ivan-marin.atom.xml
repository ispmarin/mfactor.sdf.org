<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Another Life Form</title><link href="http://mfactor.sdf.org/" rel="alternate"></link><link href="http://mfactor.sdf.org/feeds/ivan-marin.atom.xml" rel="self"></link><id>http://mfactor.sdf.org/</id><updated>2015-12-08T22:42:00-02:00</updated><entry><title>Data Science workflow with reproducible research</title><link href="http://mfactor.sdf.org/data-science-workflow-with-reproducible-research.html" rel="alternate"></link><updated>2015-12-08T22:42:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-12-08:data-science-workflow-with-reproducible-research.html</id><summary type="html">&lt;h1&gt;Data science workflow&lt;/h1&gt;
&lt;p&gt;I've been wondering and tinkering about how to structure my data science projects, thinking on the lines of &lt;a href="http://reproducibleresearch.net/"&gt;Reproducible Research&lt;/a&gt; and separation of information. There is a lot of talk about the CRISP-DM &lt;a href="https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining"&gt;Cross Industry Standard Process for Data Mining&lt;/a&gt; and I believe that CRISP-DM is indeed a good approach. There are others like &lt;a href="https://en.wikipedia.org/wiki/SEMMA"&gt;SEMMA&lt;/a&gt; that are similar. But how these processes come down to a real project organization? Breaking down the steps, in a general overview, a data science project generally has&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data&lt;/code&gt;, either the datasets or samples, that will be worked on&lt;/li&gt;
&lt;li&gt;&lt;code&gt;src&lt;/code&gt; (a code folder), for analysis, ETL and modeling&lt;/li&gt;
&lt;li&gt;&lt;code&gt;documentation&lt;/code&gt; about the problem, business case, the data and the solution&lt;/li&gt;
&lt;li&gt;&lt;code&gt;results&lt;/code&gt;, in form of processed data, a software deployment process or final documentation (including presentation)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course your project will have other needs or either a more complex or more simple structure, also depending on how you think about CRISP-DM or your own approach. But so far this structure above has helped me to keep things organized and understandable based on CRISP-DM. I try to keep in line the ideas from both the process and reproducible research.&lt;/p&gt;
&lt;p&gt;I also have a few other requirements for my projects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;all code must be versioned&lt;/li&gt;
&lt;li&gt;all data must be identified by data and local&lt;/li&gt;
&lt;li&gt;the documentation should also be versioned a preferably autogenerated&lt;/li&gt;
&lt;li&gt;the results should be reproducible, without intervention&lt;/li&gt;
&lt;li&gt;libraries should be isolated from the system and preferably portable to other systems&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Requirements 1 and 3 are satisfied using &lt;code&gt;git&lt;/code&gt;. I usually set the root of the project as the &lt;code&gt;git&lt;/code&gt; base directory and exclude on the &lt;code&gt;.gitignore&lt;/code&gt; the data and results directories. I decided not to include the &lt;code&gt;results&lt;/code&gt; folder because of requirement 4 and also because they can be big. An exception can be made if there are presentations inside &lt;code&gt;results&lt;/code&gt; that are not autogenerated. Part of the autogeneration of the documentation is made writing it on the analysis code itself, a la &lt;code&gt;jupyter&lt;/code&gt; notebook style.&lt;/p&gt;
&lt;p&gt;Requirement 2 is satisfied using a simple directory structure. Inside the &lt;code&gt;data&lt;/code&gt; folder I create a directory with the date as the name, like &lt;code&gt;20151207&lt;/code&gt; and include hour and minute if I'm generating samples with this precision. If I need to generate a sample a &lt;code&gt;sample&lt;/code&gt; directory inside the dated directory suffices. Some people advise to save intermediate steps if there are a lot of data cleanup steps. I tend to do it if the cleanup step is too time consuming, otherwise I just recompute the cleanup step. I also tend to include the metadata with the data, outside the data file, with the same name as the data file but with a &lt;code&gt;.meta&lt;/code&gt; termination.  &lt;/p&gt;
&lt;p&gt;The local part of the &lt;code&gt;data&lt;/code&gt; can be tricky when using a database as a source, for example. This is one of the points where reproducible research helps a bit: databases can change, so let's say you run today a model with data pulled from a database. You should be able to reproduce exactly the same results any time, but the database could have been updated in the meantime and your project is not reproducible anymore. I download the data to a local storage file (either csv or HDF5 or other format at hand) and use this file to do my computations. There is a real problem if the data set is too large or the data is sensitive, but so far I've managed to do it without serious issues. &lt;/p&gt;
&lt;p&gt;I usually use &lt;code&gt;jupyter&lt;/code&gt; and &lt;code&gt;python&lt;/code&gt; to do my analysis and modeling, so to satisfy requirement 4 I tend to write my notebooks and code so they are idempotent and can be restarted from different points. That also means that the results would be overwritten everytime the code is run. This can be a problem if a experiment is being done with different inputs, so this should be taken into account when thinking on the structure of the &lt;code&gt;results&lt;/code&gt; folder (It can use the same dated approach from the &lt;code&gt;data&lt;/code&gt; directory).&lt;/p&gt;
&lt;p&gt;The last requirement depends on the language or languages that are being used in the project. This is a rather lengthy subject, so I will restrict myself to Python. I use &lt;code&gt;virtualenvs&lt;/code&gt; without site packages and keep them on the &lt;code&gt;src&lt;/code&gt; folder. Each project has its own virtualenv. Other requirements, like map data, is also included on the project structure, so the entire project folder can be moved without great impact. Virtualenvs are not that portable between systems and this has been a problem so far without solution, especially if the other system doesn't have internet access. &lt;/p&gt;
&lt;h2&gt;Project Example&lt;/h2&gt;
&lt;p&gt;As an example I have the &lt;code&gt;polls&lt;/code&gt; project, with the following directory structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="na"&gt;.pools&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;data&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151206&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls.meta&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_1000.csv&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_200.csv&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151203&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_rs.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_rs_1000.csv&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_pe_200.csv&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151202&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;all_polls.hdf&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;all_polls.meta&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;src&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;analysis&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;pools.ipynb&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sampling&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sampling.py&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;etl&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;extract_from_mongo.py&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;generate_results&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;do_models.py&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;generate_webpage.py&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;generate_approach_action.py&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;images&lt;/span&gt;
            &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;header.png&lt;/span&gt;
            &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;logo.svg&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;doc&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;business&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;use_case.md&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;algorithm&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;machine_learning.md&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;analysis_results.md&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;images&lt;/span&gt;
            &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;analysis_all.png&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;results&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151207&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;voters.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;control_group.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;approach_and_action.md&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One of the things that I also consider is the use of symbolic links from the &lt;code&gt;src&lt;/code&gt; folder to the &lt;code&gt;results&lt;/code&gt; folder or do a copy of a figure, from example. &lt;/p&gt;
&lt;p&gt;On the next article I plan to show a pattern for &lt;code&gt;jupyter&lt;/code&gt; notebooks to handle this structure. &lt;/p&gt;</summary><category term="data science"></category><category term="data"></category></entry><entry><title>Using `conda` instead of `pip`</title><link href="http://mfactor.sdf.org/conda.html" rel="alternate"></link><updated>2015-11-26T22:42:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-11-26:conda.html</id><summary type="html">&lt;p&gt;I've been struggling with which environment use to develop on Python applications that 
are going to be moved around and run on different systems. There is Hadoop and Spark on the mix, so things are getting
more complicated, too. Thinking about my environment, I have the following requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Determine the level of isolation of the application.&lt;/li&gt;
&lt;li&gt;Point to the &lt;code&gt;python&lt;/code&gt; binary that I want.&lt;/li&gt;
&lt;li&gt;Can be moved around &lt;/li&gt;
&lt;li&gt;Can be deployed and used in systems without internet&lt;/li&gt;
&lt;li&gt;Can be deployed and used without root access&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far I have two alternatives: &lt;code&gt;virtualenv&lt;/code&gt; and &lt;code&gt;Anaconda&lt;/code&gt;. I've been using &lt;code&gt;virtualenv&lt;/code&gt; for a while so I know 
better the limitations. I tried, then, to use &lt;code&gt;Anaconda&lt;/code&gt; to see how it works. The installer is heavy but it comes
with several useful things (&lt;code&gt;pandas&lt;/code&gt;, for example), so that's ok. Things got a bit complicated using the environments,
though, with the &lt;code&gt;conda&lt;/code&gt; application. To keep point 2 I changed the recommended &lt;code&gt;PATH&lt;/code&gt; variable to &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;export PATH=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="x"&gt;:/home/ispmarin/bin:/home/ispmarin/bin/anaconda3/bin&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so I get the system &lt;code&gt;python&lt;/code&gt; executable but all the other tools from &lt;code&gt;Anaconda&lt;/code&gt;. Nice. Then I created and environment
and installed some stuff there. Also works as expected, although it points to the &lt;code&gt;python&lt;/code&gt; binary from inside &lt;code&gt;Anaconda&lt;/code&gt;.
Acceptable. Then I deactivated the environment, and to my surprise, the &lt;code&gt;python&lt;/code&gt; executable didn't change back to 
the system one! Damn, that's a problem right there. There 
&lt;a href="http://stackoverflow.com/questions/33955516/anaconda-activate-deactivate-cycle-messes-up-path"&gt;are&lt;/a&gt; 
&lt;a href="https://github.com/conda/conda/issues/1846"&gt;several&lt;/a&gt; 
&lt;a href="https://github.com/conda/conda/pull/1727"&gt;bug&lt;/a&gt; reports on the &lt;code&gt;conda&lt;/code&gt; github, but still no final solution. So &lt;code&gt;conda&lt;/code&gt; is
out for now.&lt;/p&gt;</summary><category term="python"></category><category term="pip"></category><category term="conda"></category></entry><entry><title>Desktop Files on Debian/Ubuntu and XDG</title><link href="http://mfactor.sdf.org/desktop-files.html" rel="alternate"></link><updated>2015-11-23T21:57:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-11-23:desktop-files.html</id><summary type="html">&lt;p&gt;I've been struggling for a while now with custom launchers. First, a bit of organizatoin on how the launchers are supposed to work.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;desktop file&lt;/code&gt; is a file that describes a launcher for an application. This file will be indexed by a Window Manager, like KDE or XFCE and can be shown on the menus and etc. The &lt;a href="http://standards.freedesktop.org/desktop-entry-spec/latest/apa.html"&gt;standard form&lt;/a&gt; of a desktop file is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[Desktop Entry]&lt;/span&gt;
&lt;span class="na"&gt;Version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1.0&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Application&lt;/span&gt;
&lt;span class="na"&gt;Name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Foo Viewer&lt;/span&gt;
&lt;span class="na"&gt;Comment&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;The best viewer for Foo objects available!&lt;/span&gt;
&lt;span class="na"&gt;Exec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;fooview %F&lt;/span&gt;
&lt;span class="na"&gt;Icon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;fooview&lt;/span&gt;
&lt;span class="na"&gt;Actions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Gallery;Create;&lt;/span&gt;
&lt;span class="na"&gt;Categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Network&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This file should be put on a standard path in the system, like &lt;code&gt;~/.local/share/applications&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;And how to check if the file you wrote is valid? Just run &lt;code&gt;desktop-file-validate&lt;/code&gt; and it will point any errors that you have. &lt;/p&gt;
&lt;h2&gt;KDE blunder&lt;/h2&gt;
&lt;p&gt;After figuring it out how was the correct format for the file, my menus on KDE (and all actions, like changing the default application)was not changing anything. After searching for a long time, I found a solution: the context menu in Dolphin, to change the default application, was poiting to &lt;code&gt;.local/share/applications/mineapps.list&lt;/code&gt; and KDE 5 was reading the file on &lt;code&gt;.config/mimeapps.list&lt;/code&gt;. The solution? Exporting the default directory where KDE can find its icons. On my system, I changed .zshenv and added&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;XDG_DATA_DIRS=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;XDG_DATA_DIRS&lt;/span&gt;&lt;span class="x"&gt;:/home/ispmarin/.local/share/applications&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;done!&lt;/p&gt;</summary><category term="linux"></category><category term="desktop"></category></entry><entry><title>How to learn Physics (and Mathematics) with History</title><link href="http://mfactor.sdf.org/physics-and-history.html" rel="alternate"></link><updated>2015-08-19T19:30:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-08-19:physics-and-history.html</id><summary type="html">&lt;p&gt;Watching the new Cosmos series about Faraday I was struck by a very simple thought: seeing how things evolved made simpler for me to understand physical concepts. I don’t know if I had that epiphany before or if that’s common, but for me it was a revelation. Very simple things, like magnetic fields, were way more clear after showing what Faraday was trying to achieve and was thinking than any Electromagnetism A that I did as an undergrad. And I believe that this might help my new endeavor: understanding probability deeply.&lt;/p&gt;
&lt;p&gt;I’ve been reading Lady Luck, by Warren Weaver, and I’m loving it. It has a very unique balance between telling the history of probability with showing the basic concepts in a very clear way. Another fantastic thing about this book is that it doesn’t save on words: Warren repeats and repeats what it is and what is not, so it’s perfectly clear on every moment what he’s talking about. That’s uncommon for a math book: usually the authors assume that everyone knows what he means and that a beginner easily can understand everything that is going on when a formula or a concept is demonstrated. The terror of physicists – “it can be easily demonstrated” is avoided at all costs. The trade off is that sometimes verbosity can be a little tiresome, but for me it has a clarity that I wished all my undergrad textbooks had. And that’s the connection between the Cosmos episode and this book: both show the concepts from a basic point of view, but they excel in going deep in the subject without being condescending or jumping “obvious” steps, showing the history behind that idea and how it came to be.&lt;/p&gt;
&lt;p&gt;At least on my first years as a Physics undergrad, all students were eager to experiment, to go hands on the physics labs or the observatory. Two things were hammered down on us, one good and one bad. The good one was that we had to have method: just poking things randomly would not take us very far, as fun as it was. Teaching this method (called, despite all controversy, the scientific method) was one of the best things that I could have learned as an undergrad. The bad thing was that we were buried in math courses without any kind of context. On the first year alone we had an ordinary and partial differential equations course, a analytical geometry course, two calculus courses and a basic programming course, plus some optional advanced physics math courses. I know that this is common on physics courses, but those were just dumped on us. Some physics teachers tried to give us context, but it was more on the ping-pong version (“this you will see on your calculus course”, “this you will see on your physics course” and so on) and not very helpful. This demotivated me and several other students. Why did we need to learn all this calculus and geometry without any tangible reason? (The “you’re going to need this to understand that” is not very helpful, at all. You don’t know that yet!). Only after my first classical mechanics course things started to make more sense, and got better with a great electromagnetism teacher that showed how things were put together by Maxwell and Faraday.&lt;/p&gt;
&lt;p&gt;Maybe this is about the “math first”or “physics first” dilemma for a Physics course. If you already know the math you can concentrate on the Physics ideas and results. If you know the physics principles before, the math is the best support for those ideas to flourish and be useful. (On an aside, I don’t agree with a teacher that I had that said “all you need is the physical intuition, the math is the easy part! Follow your intuition!” and every time we needed the math, he would fail.) I can see both sides now and would propose a third option: teach the history first. With the context things would be easier on both sides, the ideas would permeate the ideas on both sides and maybe provide more support for thought and understanding. This maybe would prevent the effect of trusting only on the math, without reflecting what the math is telling you. As another great teacher said, “What is a sign? It’s the difference of sending the astronaut to the moon or killing him!”&lt;/p&gt;</summary><category term="physics"></category><category term="mathematics"></category><category term="history"></category><category term="learning"></category></entry><entry><title>Finally, Python 3!</title><link href="http://mfactor.sdf.org/finally-python-3.html" rel="alternate"></link><updated>2015-06-27T09:39:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-06-27:finally-python-3.html</id><summary type="html">&lt;p&gt;It's 2015 and it's the first time that I'm using Python 3
professionally. And I have to admit, if I knew that all my scripts were
going to work so easily with 3, I would have changed way before. There
were a few hurdles with the Python 3 version of some libraries - patsy,
I'm looking at you - but so far the transition was painless. The things
that I had to change were expected, like the print function and some
dict operations, and xrange. I know it's for the best now, so let's
roll.&lt;/p&gt;
&lt;p&gt;First of all, I switched from WinPython to Anaconda. Having to work on a
constrained Windows installation, Anaconda provides better support for
installing packages than pip alone. And as so far using virtualenv has
not been a success on Windows, I'm going to try the conda environment
for my projects.&lt;/p&gt;
&lt;p&gt;On the version control front, I finally got access to a git shell on
Windows, and now I can keep my sanity working with code. There's even a
Team Foundation Server plugin for it, and the client is not that bad -
actually, it's useful and keeps the git terminology, helping immensely
someone that was used to git on the command line. Not bad, Microsoft.
Git-cola is still better and is several times smaller than TFS, but hey,
sometimes we have to use what we got. So my working environment now is&lt;/p&gt;
&lt;p&gt;* Anaconda 2.2.0, Python 3 version&lt;/p&gt;
&lt;p&gt;* Packages:&lt;/p&gt;
&lt;p&gt;-pandas, sklearn, matplotlib, calendar, sqlalchemy with Oracle plugin,
seaborn (mostly for styles), statsmodels.&lt;/p&gt;
&lt;p&gt;* Editor:&lt;/p&gt;
&lt;p&gt;Vim and ipython notebook (depending on the type of work)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://msysgit.github.io/"&gt;Git for Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;and Tableau for some visualizations.&lt;/p&gt;
</summary></entry></feed>