<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags always come first -->
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>A history of packages and libraries or: how Spark and Hadoop are doing the same mistake as BLAS and LAPACK | Another Life Form
</title>
  <link rel="canonical" href="/2015_07_20_blas_lapack_spark.html">

  <link rel="alternate" type="application/atom+xml" href="/feeds/all.atom.xml" title="Full Atom Feed">
  <link rel="alternate" type="application/atom+xml" href="/feeds/data-science.atom.xml" title="Categories Atom Feed">


  <link rel="stylesheet" href="/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="/theme/css/pygments/monokai.min.css">
  <link rel="stylesheet" href="/theme/css/style.css">


<meta name="description" content="A long time ago, on a land of big iron and MPI, there were some libraries that were used everywhere. The libraries were fundamental to most of the important computation that was done, they were open source and all the cool kids on the block knew them. They also rarely â€¦">
</head>

<body>
  <header class="header">
    <div class="container">
      <div class="row">
        <div class="col-sm-12">
          <h1 class="title"><a href="">Another Life Form</a></h1>
          <ul class="list-inline">
            <li class="list-inline-item"><a href="https://br.linkedin.com/in/ispmarin/en" target="_blank">linkedin</a></li>
            <li class="list-inline-item"><a href="https://github.com/ispmarin" target="_blank">github</a></li>
            <li class="list-inline-item text-muted">|</li>
            <li class="list-inline-item"><a href="/pages/about.html">About</a></li>
          </ul>
        </div>
      </div>
    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>A history of packages and libraries or: how Spark and Hadoop are doing the same mistake as <span class="caps">BLAS</span> and <span class="caps">LAPACK</span>
</h1>
      <hr>
<article class="article">
  <header>
    <ul class="list-inline">
      <li class="list-inline-item text-muted" title="2015-07-20T09:33:00-03:00">
        <i class="fa fa-clock-o"></i>
        Seg 20 Julho 2015
      </li>
      <li class="list-inline-item">
        <i class="fa fa-folder-open-o"></i>
        <a href="/category/data-science.html">data science</a>
      </li>
      <li class="list-inline-item">
        <i class="fa fa-user-o"></i>
        <a href="/author/ivan-marin.html">Ivan Marin</a>      </li>
      <li class="list-inline-item">
        <i class="fa fa-files-o"></i>
        <a href="/tag/beowulf.html">#beowulf</a>,         <a href="/tag/big-data.html">#big data</a>,         <a href="/tag/debian.html">#debian</a>,         <a href="/tag/haddop.html">#haddop</a>,         <a href="/tag/openstack.html">#openstack</a>,         <a href="/tag/spark.html">#spark</a>      </li>
    </ul>
  </header>
  <div class="content">
    <p>A long time ago, on a land of big iron and <span class="caps">MPI</span>, there were some
libraries that were used everywhere. The libraries were fundamental to
most of the important computation that was done, they were open source
and all the cool kids on the block knew them. They also rarely were
distributed by the Linux distributions, and several versions needed to
coexist to support all the high performance software that needed to be
run. They needed to be compiled, and different versions of compilers and
libraries and binaries kept spiralling out of control. Keeping them
working was already a huge task, and working well was even harder. And
yes, I&#8217;m talking about <span class="caps">BLAS</span> and <span class="caps">LAPACK</span>.</p>
<p><a class="reference external" href="http://www.netlib.org/blas/"><span class="caps">BLAS</span></a> (Basic Linear Algebra Suprograms)
and <a class="reference external" href="http://www.netlib.org/lapack/"><span class="caps">LAPACK</span></a> (Linear Algebra PACKAge),
from <a class="reference external" href="http://www.netlib.org/">Netlib</a>, were fundamental on the <span class="caps">HPC</span>
era as the backbone of inumerous projects. The stack on those days had
one flavour or another of
<a class="reference external" href="https://en.wikipedia.org/wiki/Message_Passing_Interface"><span class="caps">MPI</span></a> to run
the parallel jobs in huge clusters, together with
<a class="reference external" href="http://www.netlib.org/scalapack/">ScaLAPACK</a>. And the job of keeping
these libraries working with several different compilers (mainly
<a class="reference external" href="https://gcc.gnu.org/"><span class="caps">GCC</span></a>,
<a class="reference external" href="https://software.intel.com/en-us/intel-compilers">Intel</a> and
<a class="reference external" href="http://www.pgroup.com/">Portland Group</a> compilers ) and linking
binaries objects were the nightmare of any sysadmin. Written mainly in
Fortran, with wrappers for C and C++, a sysadmin had to keep the entire
stack compiled with the right version of compilers and linked with the
right libraries. Projects like <a class="reference external" href="http://www.netlib.org/atlas/"><span class="caps">ATLAS</span></a>
tried to help a bit on the side of performance optimization, while
vendors had their own binary distribution, tuned to their processors
(<a class="reference external" href="https://software.intel.com/en-us/intel-mkl"><span class="caps">MKL</span></a> for Intel and
<a class="reference external" href="http://developer.amd.com/tools-and-sdks/cpu-development/amd-core-math-library-acml/"><span class="caps">ACML</span></a>
for <span class="caps">AMD</span>).</p>
<p>A sysadmin on the <span class="caps">HPC</span> world had to know all these libraries, how to
deploy them to the users that wanted to compile their own programs, and
how to make all of them play nice with each other on the same cluster.
It was hard to keep track of what was breaking, with lots of non
standard paths and binary objects, name mangling, and users trying to do
things that you never imagined possible. The <span class="caps">HPC</span> sysadmin also needed to
know the underlying architecture very well, including the network and
storage structures, the physical layout of the cables, so he or she
could have a chance to know what was breaking or lagging.&nbsp; Slowly, these
tools started to be better organized, with practices like module loading
and the linux distributions creating packages to the basic libraries,
even if the performance was not the best possible. And then the Cloud&nbsp;happened.</p>
<p>(I&#8217;m not going to dwelve on the <span class="caps">HPC</span> vs Cloud debate, not even try to
touch the Big Data vs <span class="caps">BI</span> vs computing debates, and try to focus on the
tools that make all these acronyms possible, otherwise this would be a
very long&nbsp;post.)</p>
<p>I have some time now on my hands and decided to check how the deployment
and configuration of a Spark cluster is being done on
<a class="reference external" href="https://spark.apache.org/docs/latest/">Debian</a>. And boy, <a class="reference external" href="http://spark.apache.org/docs/latest/building-spark.html">what a
surprise</a>.
I&#8217;ve been seeing several posts from sysadmins complaining about the
dockerization of applications and the mirage of the devops, but was
taken aback with the state of how Spark is suposed to be deployed on a
Debian (<a class="reference external" href="http://bigtop.apache.org/book/apache-bigtop-user-guide/apache-bigtop-user-guide.html">or any other
linux</a>)
installation. There are several binaries spread out, with
interdependencies, depending on the compiler version or library version,
without standard paths, and users making a even larger mess&#8230; where did
I hear about it&nbsp;before?</p>
<p>I expected that with the amout of resources that are being poured on the
cloud projects, some form of organization or standardization would have
happened. But no luck: all is still downloading binaries and compiling
tons of disconnected but interdependent libraries, only with more levels
of abstraction. Yes, the abstraction levels help the user, as he doesn&#8217;t
need anymore to know about if the processor has <span class="caps">SSE3</span> or <span class="caps">SSE4</span>.2. Yes, now
devops can be both programmers and sysadmins. Yes, you don&#8217;t have to buy
new machines, install them, plug the cables - you can just go to the <span class="caps">AWS</span>
console and click moar instances. But someone, on the end, has to move
all this to production, keep it working, plan on how this will grow, and
fix it when it breaks - and it will break, trust&nbsp;me.</p>
<p>Oh, but there&#8217;s <a class="reference external" href="https://www.openstack.org/">OpenStack</a>to the
rescue! Well, not really. I&#8217;m also not going to go deep into OpenStack,
but suffice to say that OpenStack is more an orchestration service than
what I&#8217;m looking into&nbsp;here.</p>
<p>And oh, there&#8217;s Docker/Vagrant/CoreOS/etc containers! Well, that&#8217;s also
an issue that I think is not the focus of this discussion. During the
<span class="caps">HPC</span> era, usually the application deployment consisted of: configuring
the computing nodes to communicate, share the data using a dedicated
network connected to a <span class="caps">RAID</span> server and running a binary on a <span class="caps">NFS</span> share.
Things got way more complicated because they are more complicated:
connection to several databases, web services, what not. But in the end
the problem is the same: how to deploy an environment that you can
maintain and fix? These technologies help immensely on empowering the
developer to create more complex solutions and abstract more, especially
parallel computations, but they actually make the maitain and fix part
way more complicated, from the sysadmin perspective. That&#8217;s why I&#8217;m not
trying to address again these tools: they solve another problem, and
anyway, you have to configure these containers with the same binaries
and libraries, that need to be compiled, going back to the initial&nbsp;problem!</p>
<p>So, is there a way to solve this mess? Unfortunately, I don&#8217;t know. I&#8217;ve
been sidelining all these issues on the day to day at work, adding
binaries and virtualenvs when needed, but this will explode soon or
later. I just think that this problem is not being looked with much
care, especially on the startup world, or just being pushed to the new
<a class="reference external" href="https://anotherlifeform.files.wordpress.com/2015/07/7d267-11359006_420191058182770_2015412754_n.jpg">shiny new
thing</a>that
will solve everything with more abstraction. What to do? Maybe to think
about these points when deploying your cluster, playing better with the
basic distributions and contributing more, and the distros trying not to
suffer from <span class="caps">NIH</span> syndrome would&nbsp;help.</p>
<p>I&#8217;m all ears for&nbsp;suggestions!</p>

  </div>
</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
      <div class="row">
       <ul class="col-sm-6 list-inline">
          <li class="list-inline-item"><a href="/authors.html">Authors</a></li>
          <li class="list-inline-item"><a href="/archives.html">Archives</a></li>
          <li class="list-inline-item"><a href="/categories.html">Categories</a></li>
          <li class="list-inline-item"><a href="/tags.html">Tags</a></li>
        </ul>
        <p class="col-sm-6 text-sm-right text-muted">
          Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a> / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
        </p>
      </div>
    </div>
  </footer>
</body>

</html>