<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Another Life Form</title><link href="http://mfactor.sdf.org/blog/" rel="alternate"></link><link href="http://mfactor.sdf.org/blog/feeds/all.atom.xml" rel="self"></link><id>http://mfactor.sdf.org/blog/</id><updated>2017-05-07T11:44:00-03:00</updated><entry><title>Using venv for Python 3 virtualenv</title><link href="http://mfactor.sdf.org/blog/2017_05_07_python3-venv-virtualenv.html" rel="alternate"></link><published>2017-05-07T11:44:00-03:00</published><updated>2017-05-07T11:44:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2017-05-07:/blog/2017_05_07_python3-venv-virtualenv.html</id><summary type="html">&lt;p class="first last"&gt;How to use &lt;cite&gt;venv&lt;/cite&gt; as a&amp;nbsp;virtualenv&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been trying to use Python 3.6 as much as I can. I&amp;#8217;ve been bitten by the encoding problems of Python 2
too many times to remember - and that&amp;#8217;s my reason why I want to use Python 3 for now, I will not enter
the &lt;a class="reference external" href="https://wiki.python.org/moin/Python2orPython3"&gt;eternal&lt;/a&gt;
&lt;a class="reference external" href="https://news.ycombinator.com/item?id=13019819"&gt;flamewar&lt;/a&gt; &lt;a class="reference external" href="https://news.ycombinator.com/item?id=13504215"&gt;between&lt;/a&gt;
&lt;a class="reference external" href="https://news.ycombinator.com/item?id=13061570"&gt;Python 2&lt;/a&gt; &lt;a class="reference external" href="https://news.ycombinator.com/item?id=13053757"&gt;vs&lt;/a&gt;
&lt;a class="reference external" href="https://www.reddit.com/r/Python/comments/qwq4l/not_trying_to_start_a_flame_war_but_which_python/"&gt;Python 3&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So I decided to try the Python 3 solution for creating virtualenvs: &lt;a class="reference external" href="https://docs.python.org/3/library/venv.html"&gt;venv&lt;/a&gt;.
It should be the default way tho create virtualenvs, as it&amp;#8217;s not based on &amp;#8220;hacks&amp;#8221; as the package &lt;cite&gt;virtualenv&lt;/cite&gt; and
it&amp;#8217;s now part of the default&amp;nbsp;distribution.&lt;/p&gt;
&lt;p&gt;So far, it seems that some nice shortcuts and functionalities are still not there, like relocate a virtualenv and
the handy &lt;cite&gt;workon&lt;/cite&gt; from the &lt;cite&gt;virtualenvwrapper&lt;/cite&gt; package. What is missing so far is a workflow management. The rest is very
similar to working with virtualenvs and &lt;cite&gt;pip&lt;/cite&gt;.&lt;/p&gt;
&lt;div class="section" id="working-with-venv"&gt;
&lt;h2&gt;Working with &lt;cite&gt;venv&lt;/cite&gt;&lt;/h2&gt;
&lt;p&gt;The standard way of working with &lt;cite&gt;venv&lt;/cite&gt; is quite similar to &lt;cite&gt;virtualenv&lt;/cite&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
/usr/bin/python3.6 -m venv test_env /home/username/bin/virtualenvs/test_env
&lt;/pre&gt;
&lt;p&gt;So now the virtualenv is created. To activate it, use the full &lt;cite&gt;source activate&lt;/cite&gt; path:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
source /home/username/bin/virtualenvs/test_env/bin/activate
&lt;/pre&gt;
&lt;p&gt;and now we are inside the virtualenv &lt;cite&gt;test_env&lt;/cite&gt;. To install packages use the traditional &lt;cite&gt;pip&lt;/cite&gt;:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pip install matplotlib sklearn pandas jupyter folium
&lt;/pre&gt;
&lt;p&gt;And that&amp;#8217;s it. To deactivate a simple &lt;cite&gt;deactivate&lt;/cite&gt; suffices.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="managing-the-virtualenvs"&gt;
&lt;h2&gt;Managing the&amp;nbsp;virtualenvs&lt;/h2&gt;
&lt;p&gt;One of the things that is both good and bad about Continuum &lt;cite&gt;conda&lt;/cite&gt; is the hability of managing the virtualenvs. We
can list the available environments&amp;nbsp;with&lt;/p&gt;
&lt;pre class="literal-block"&gt;
conda info --envs
&lt;/pre&gt;
&lt;p&gt;That will show all virtualenvs created using conda and the full paths. With &lt;cite&gt;venv&lt;/cite&gt; we have to resort to using the filesystem
tools directly, or being explicit, using &lt;cite&gt;ls&lt;/cite&gt;.&lt;/p&gt;
&lt;p&gt;Listing packages can be done using &lt;cite&gt;pip&lt;/cite&gt; directly. Removing a virtualenv is done using the good old &lt;cite&gt;rm&lt;/cite&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="virtualenvwrapper-comparison"&gt;
&lt;h2&gt;Virtualenvwrapper&amp;nbsp;comparison&lt;/h2&gt;
&lt;p&gt;The &lt;a class="reference external" href="http://virtualenvwrapper.readthedocs.io/"&gt;virtualenvwrapper&lt;/a&gt; package has the purpose of handling the steps explained
above with some shell tools. &lt;cite&gt;venv&lt;/cite&gt;, of course doesn&amp;#8217;t provide any of this. There is even an option that I was not aware on
&lt;cite&gt;virtualenvwrapper&lt;/cite&gt;, that is, managing &lt;a class="reference external" href="http://virtualenvwrapper.readthedocs.io/en/latest/projects.html#project-management"&gt;projects&lt;/a&gt;.
This looks very interesting to me, as I&amp;#8217;m &lt;a class="reference external" href="http://mfactor.sdf.org/blog/2015_12_08_reproducible_ds.html"&gt;quite found&lt;/a&gt; of reproducible environments and &lt;a class="reference external" href="http://mfactor.sdf.org/blog/2015_11_26_conda.html"&gt;automated tools&lt;/a&gt; for it.
I&amp;#8217;ll test it against the &lt;a class="reference external" href="https://github.com/ispmarin/cookiecutter-pypackage"&gt;Data Science Cookie Cutter&lt;/a&gt; and report&amp;nbsp;back.&lt;/p&gt;
&lt;/div&gt;
</content><category term="python"></category><category term="python3"></category><category term="virtualenv"></category><category term="venv"></category></entry><entry><title>Export CSV playlists to Spotify</title><link href="http://mfactor.sdf.org/blog/2017_02_04_spotify_csv_playlist.html" rel="alternate"></link><published>2017-02-04T00:00:00-02:00</published><updated>2017-02-04T00:00:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2017-02-04:/blog/2017_02_04_spotify_csv_playlist.html</id><summary type="html">&lt;p class="first last"&gt;How to create a Spotify playlist from a &lt;span class="caps"&gt;CSV&lt;/span&gt;&amp;nbsp;file&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I&amp;#8217;m a orphan from Grooveshark, used to listen to it non-stop. All kinds of music were there.
As it wasn&amp;#8217;t strictly legal, it got closed, of course. During this time, I amassed a large
number of tracks that I enjoyed, even made some&amp;nbsp;playlists.&lt;/p&gt;
&lt;p&gt;I saved these playlists on &lt;span class="caps"&gt;CSV&lt;/span&gt; files a long time ago. Cleaning up some old stuff,
I came across these files and decided that they should become some Spotify playlists.
But&amp;nbsp;how?&lt;/p&gt;
&lt;p&gt;There are several scripts that convert CSVs with Artist and Song name to a &lt;span class="caps"&gt;XPLS&lt;/span&gt; format,
but to transfer to Spotify, all scripts would need some form of access to my account.
As I was not willing to provide my credentials, they wouldn&amp;#8217;t&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;I finally found the &lt;a class="reference external" href="http://www.playlist-converter.net/#/"&gt;Playlist Converter&lt;/a&gt;, that
transforms the playlist into Spotify track codes, without needing my credentials.
Awesome! After uploading the CSVs, the site would convert to Spotify track codes.
I then created an empty playlist on Spotify, copied and pasted the track codes
on the Spotify client, and voilá, all songs were&amp;nbsp;there.&lt;/p&gt;
</content><category term="music"></category><category term="spotify"></category></entry><entry><title>Self signed certificate with Git</title><link href="http://mfactor.sdf.org/blog/2017_02_03_self_sign_git.html" rel="alternate"></link><published>2017-02-03T00:00:00-02:00</published><updated>2017-02-03T00:00:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2017-02-03:/blog/2017_02_03_self_sign_git.html</id><summary type="html">&lt;p class="first last"&gt;How to work with a self signed certificate and&amp;nbsp;Git&lt;/p&gt;
</summary><content type="html">&lt;p&gt;After setting up Gogs with a self signed certificate, I needed to commit using &lt;span class="caps"&gt;HTTPS&lt;/span&gt; now. To do that, Git must be instructed to ignore the certificate signature&amp;nbsp;with&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;`
git config http.sslVerify false
`&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;that will disable the &lt;span class="caps"&gt;SSL&lt;/span&gt; verification for this session. An one-liner&amp;nbsp;is&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;`
git &lt;span class="pre"&gt;-c&lt;/span&gt; http.sslVerify=false clone &lt;span class="pre"&gt;https://domain.com/path/to/git&lt;/span&gt;
`&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;This &lt;a class="reference external" href="http://stackoverflow.com/questions/11621768/how-can-i-make-git-accept-a-self-signed-certificate"&gt;post&lt;/a&gt; has more information about&amp;nbsp;it.&lt;/p&gt;
</content><category term="os"></category></entry><entry><title>Using Kwallet to store credentials for git</title><link href="http://mfactor.sdf.org/blog/2017_02_02_kwallet_git.html" rel="alternate"></link><published>2017-02-02T00:00:00-02:00</published><updated>2017-02-02T00:00:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2017-02-02:/blog/2017_02_02_kwallet_git.html</id><summary type="html">&lt;p class="first last"&gt;How to avoid typing your password for git &lt;span class="caps"&gt;HTTPS&lt;/span&gt;&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I switched my repos to Gogs and now I&amp;#8217;m using &lt;span class="caps"&gt;HTTPS&lt;/span&gt; to push.
The thing is that I can&amp;#8217;t use my ssh keys for that, so I have to type the password.
There is a way to use the KWallet to store these credentials and tell Git to use KWallet for&amp;nbsp;them:&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;`
sudo &lt;span class="pre"&gt;apt-get&lt;/span&gt; install ksshaskpass
`&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;and then configure git&amp;nbsp;as&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;`
git config &lt;span class="pre"&gt;--global&lt;/span&gt; core.askpass /usr/bin/ksshaskpass
`&lt;/tt&gt;&lt;/p&gt;
&lt;p&gt;and done. Quite&amp;nbsp;helpful.&lt;/p&gt;
</content><category term="os"></category></entry><entry><title>Different SSH keys for Different Hosts</title><link href="http://mfactor.sdf.org/blog/2017_01_10_ssh_keys_hosts.html" rel="alternate"></link><published>2017-01-10T10:20:00-02:00</published><updated>2017-01-10T10:20:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2017-01-10:/blog/2017_01_10_ssh_keys_hosts.html</id><summary type="html">&lt;p class="first last"&gt;Keep your keys private and&amp;nbsp;separated&lt;/p&gt;
</summary><content type="html">&lt;p&gt;The idea is simple: each of the &lt;span class="caps"&gt;SSH&lt;/span&gt; keys should grant access to only one system.
The rationale is that if one of the keys is compromised the other keys are not. Simple,&amp;nbsp;really.&lt;/p&gt;
&lt;p&gt;To do it, the first step is to generate the keys&amp;nbsp;separatedely:&lt;/p&gt;
&lt;pre class="code bash literal-block"&gt;
ssh-keygen -t rsa -b &lt;span class="m"&gt;4096&lt;/span&gt; -C &lt;span class="s2"&gt;&amp;quot;yourmail&amp;#64;mail.com&amp;quot;&lt;/span&gt; -f ~/.ssh/github
&lt;/pre&gt;
&lt;p&gt;This command generates a key pair with 4096 bits and the email above as signature.
The key will be on the full path and the filename,
something like &lt;code&gt;/home/user/.ssh/github&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now the &lt;cite&gt;config&lt;/cite&gt; file for &lt;cite&gt;ssh&lt;/cite&gt; must be configured to correspond to the expected&amp;nbsp;keys:&lt;/p&gt;
&lt;pre class="code bash literal-block"&gt;
Host github.com
    IdentityFile ~/.ssh/github

Host bitbucket.com
    IdentityFile ~/.ssh/bitbucket
&lt;/pre&gt;
&lt;p&gt;and that´s it. For each server now a different key is used. A good reference is
&lt;a class="reference external" href="https://confluence.atlassian.com/bitbucket/configure-multiple-ssh-identities-for-gitbash-mac-osx-linux-271943168.html"&gt;https://confluence.atlassian.com/bitbucket/configure-multiple-ssh-identities-for-gitbash-mac-osx-linux-271943168.html&lt;/a&gt;&lt;/p&gt;
</content><category term="ssh"></category><category term="keys"></category></entry><entry><title>Managing passwords with pass</title><link href="http://mfactor.sdf.org/blog/2017_07_31_manage_pass.html" rel="alternate"></link><published>2016-07-31T09:25:00-03:00</published><updated>2016-07-31T09:25:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-07-31:/blog/2017_07_31_manage_pass.html</id><summary type="html">&lt;p class="first last"&gt;How I stopped using LastPass and love&amp;nbsp;pass&lt;/p&gt;
</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been thinking about dumping LastPass for a while now, especially after it was bought by
some company whatever. But the way that LastPass is useful is quite&amp;nbsp;awesome:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;can generate&amp;nbsp;passwords&lt;/li&gt;
&lt;li&gt;stores all&amp;nbsp;passwords&lt;/li&gt;
&lt;li&gt;fill login forms automatically (the best feature for&amp;nbsp;me)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So how can I replace it with something with at least similar functionalities but
under my&amp;nbsp;control?&lt;/p&gt;
&lt;p&gt;The answer to that is &lt;a class="reference external" href="https://www.passwordstore.org/"&gt;pass&lt;/a&gt;. It stores the
passwords as encrypted text with &lt;a class="reference external" href="https://www.gnupg.org/"&gt;&lt;span class="caps"&gt;GPG&lt;/span&gt;&lt;/a&gt; on the local filesystem.
The feedback was so good that other people started using it and developed more
resources for it, as a &lt;a class="reference external" href="https://qtpass.org/"&gt;&lt;span class="caps"&gt;GUI&lt;/span&gt;&lt;/a&gt; and a &lt;cite&gt;Firefox extension &amp;lt;https://github.com/jvenant/passff#&amp;gt;_&lt;/cite&gt;.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll describe how I managed to set it&amp;nbsp;up.&lt;/p&gt;
&lt;div class="section" id="id1"&gt;
&lt;h2&gt;&lt;span class="caps"&gt;GPG&lt;/span&gt;&lt;/h2&gt;
&lt;p&gt;First, let&amp;#8217;s set up the &lt;span class="caps"&gt;GPG&lt;/span&gt;&amp;nbsp;key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
sudo apt-get install gpgv2
&lt;/pre&gt;
&lt;p&gt;and generate a&amp;nbsp;key:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
gpg --gen-key
&lt;/pre&gt;
&lt;p&gt;If the key process takes it too long because of the entropy&amp;nbsp;generation,&lt;/p&gt;
&lt;blockquote&gt;
&lt;strong&gt;We need to generate a lot of random bytes. It is a good idea to perform
some other action (type on the keyboard, move the mouse, utilize the
disks) during the prime generation; this gives the random number
generator a better chance to gain enough entropy.
Not enough random bytes available.  Please do some other work to give
the &lt;span class="caps"&gt;OS&lt;/span&gt; a chance to collect more entropy! (Need 210 more bytes)&lt;/strong&gt;&lt;/blockquote&gt;
&lt;p&gt;install the &lt;cite&gt;rng-tools&lt;/cite&gt;:&lt;/p&gt;
&lt;blockquote&gt;
sudo apt-get install rng-tools&lt;/blockquote&gt;
&lt;p&gt;and generate entropy using the &lt;a class="reference external" href="http://serverfault.com/questions/214605/gpg-not-enough-entropy"&gt;command&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
sudo rngd -r /dev/urandom&lt;/blockquote&gt;
&lt;p&gt;to generate enough entropy for &lt;span class="caps"&gt;GPG&lt;/span&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="id2"&gt;
&lt;h2&gt;pass&lt;/h2&gt;
&lt;p&gt;So now let&amp;#8217;s install &lt;cite&gt;pass&lt;/cite&gt;:&lt;/p&gt;
&lt;blockquote&gt;
sudo apt-get instal pass&lt;/blockquote&gt;
&lt;p&gt;and create a password&amp;nbsp;store:&lt;/p&gt;
&lt;blockquote&gt;
pass init &amp;lt;email used to generate the &lt;span class="caps"&gt;GPG&lt;/span&gt; key&amp;gt;&lt;/blockquote&gt;
&lt;p&gt;You can now start adding passwords. As I said, I used LassPass heavily, so I had tons of
passwords stored. To convert them I exported on LastPass my passwords to a &lt;span class="caps"&gt;CSV&lt;/span&gt; and used
&lt;a class="reference external" href="https://git.zx2c4.com/password-store/tree/contrib/importers/lastpass2pass.rb"&gt;this tool&lt;/a&gt;
to import the passwords to pass. I now could access all my passwords from the command&amp;nbsp;line.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="pass-with-git"&gt;
&lt;h2&gt;pass with&amp;nbsp;git&lt;/h2&gt;
&lt;p&gt;But one of the nicest things about Lastpass is be able to synchronize the passwords over the web.
pass can manage the passwords as a git repository, so that&amp;#8217;s the route I chose. After importing
the passwords I initialized the password store as a git&amp;nbsp;repository:&lt;/p&gt;
&lt;blockquote&gt;
pass git init&lt;/blockquote&gt;
&lt;p&gt;Now the changes on the password file would be automatically commited. Using my &lt;a class="reference external" href="http://sdf.org/?tutorials/metaarray"&gt;meta array&lt;/a&gt;
account on &lt;a class="reference external" href="http://sdf.org"&gt;&lt;span class="caps"&gt;SDF&lt;/span&gt;&lt;/a&gt;, I created a bare remote repository on it (git init &amp;#8212;bare) and added as a remote repository
on my pass&amp;nbsp;folder:&lt;/p&gt;
&lt;blockquote&gt;
pass git remote add origin ma.sdf.org:~/git/pass&lt;/blockquote&gt;
&lt;p&gt;where the bare git repository is at &lt;cite&gt;~/git/pass&lt;/cite&gt;. After that a&amp;nbsp;simple&lt;/p&gt;
&lt;blockquote&gt;
pass git push -u &amp;#8212;all&lt;/blockquote&gt;
&lt;p&gt;commited all passwords to the&amp;nbsp;repo.&lt;/p&gt;
&lt;/div&gt;
&lt;div class="section" id="alternatives-to-access-the-passwords"&gt;
&lt;h2&gt;Alternatives to access the&amp;nbsp;passwords&lt;/h2&gt;
&lt;p&gt;There is a Firefox &lt;a class="reference external" href="https://addons.mozilla.org/pt-BR/firefox/addon/passff/"&gt;extension&lt;/a&gt; that can access
the stored passwords. It&amp;#8217;s almost as good as Lastpass, but only for&amp;nbsp;Firefox.&lt;/p&gt;
&lt;/div&gt;
</content><category term="security"></category><category term="passwords"></category></entry><entry><title>Proper way to run PySpark on a Jupyter Notebook</title><link href="http://mfactor.sdf.org/blog/2016_06_27_jupyter_pyspark.html" rel="alternate"></link><published>2016-06-27T00:00:00-03:00</published><updated>2016-06-27T00:00:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-06-27:/blog/2016_06_27_jupyter_pyspark.html</id><summary type="html">&lt;p&gt;How to proper start PySpark with a Jupyter&amp;nbsp;Notebook&lt;/p&gt;</summary><content type="html">&lt;p&gt;Using &lt;a href="jupyter.org"&gt;Jupyter Notebooks&lt;/a&gt; with PySpark is the savior combination of all data scientists around the world. The interesting bit about it is that the way that I&amp;#8217;ve saw in the internet to start a PySpark kernel with Jupyter&amp;nbsp;is &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;IPYTHON_OPTS=&amp;quot;notebook --ip 0.0.0.0&amp;quot; ./pyspark 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;if you want to set the notebook open to the world (careful with that!). But if you launch with this command, you will get this&amp;nbsp;message:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;[TerminalIPythonApp] WARNING | Subcommand `ipython notebook` is deprecated and will be removed in future versions.
[TerminalIPythonApp] WARNING | You likely want to use `jupyter notebook` in the future
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This &amp;#8220;future&amp;#8221; will be probably &lt;a href="https://github.com/apache/spark/blob/master/bin/pyspark#L30"&gt;version 2.0&lt;/a&gt;, but the proper way to do it already works with&amp;nbsp;1.6.1: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;PYSPARK_DRIVER_PYTHON_OPTS=&amp;#39;notebook --ip 0.0.0.0&amp;#39; ./pyspark
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;and&amp;nbsp;done. &lt;/p&gt;</content><category term="environment"></category><category term="data science"></category><category term="pyspark"></category><category term="jupyter"></category></entry><entry><title>Address normalization with Python and NLTK</title><link href="http://mfactor.sdf.org/blog/2016_05_10_python_nltk_address.html" rel="alternate"></link><published>2016-05-10T00:00:00-03:00</published><updated>2016-05-10T00:00:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-05-10:/blog/2016_05_10_python_nltk_address.html</id><summary type="html">&lt;p&gt;Address normalization and&amp;nbsp;match&lt;/p&gt;</summary><content type="html">&lt;p&gt;Addresses in databases, especially ones that are inserted by human operators, are prone to a wide range of forms and errors.
To be able to correctly identify a location from a address and to compare two entities we need to normalize them.
(We&amp;#8217;re calling normalization both the entire process and one of the processing&amp;nbsp;steps.)&lt;/p&gt;
&lt;p&gt;Two problems: first is to identify address on a string by field, with errors; second is to match with existing address database to remove&amp;nbsp;uncertanty.&lt;/p&gt;
&lt;h2&gt;Preparation&amp;nbsp;steps&lt;/h2&gt;
&lt;p&gt;To start tackling the problem we have first to prepare the data. The usual steps for that&amp;nbsp;are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;normalization&lt;/li&gt;
&lt;li&gt;stemming&lt;/li&gt;
&lt;li&gt;lemmatization&lt;/li&gt;
&lt;li&gt;segmentation&amp;nbsp;(tokenization)&lt;/li&gt;
&lt;li&gt;text&amp;nbsp;rebuild&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Normalization&lt;/h3&gt;
&lt;p&gt;Normalization consists on transforming the text to a canonical form (equal to all entries) so they can be compared.
The usual steps&amp;nbsp;are&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;standardize&amp;nbsp;encoding&lt;/li&gt;
&lt;li&gt;remove&amp;nbsp;punctuation&lt;/li&gt;
&lt;li&gt;transform to&amp;nbsp;lowercase&lt;/li&gt;
&lt;li&gt;remove stopwords and punctuation (with&amp;nbsp;care!)&lt;/li&gt;
&lt;li&gt;separate prefixes and suffixes that doesn&amp;#8217;t contain&amp;nbsp;information&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Stemming&lt;/h3&gt;
&lt;p&gt;Stemming is the process of reducing words in different forms (conjugated verbs, plural) to a radical form.
This step is not useful for addresses because most of the addresses are not in different forms.
Proper names, for example, are very common in addresses and don&amp;#8217;t benefit a lot from&amp;nbsp;stemming.&lt;/p&gt;
&lt;h2&gt;Lemmatization&lt;/h2&gt;
&lt;p&gt;As we&amp;#8217;re not going to stem the words, we also don&amp;#8217;t need to lemmatizate them.
Lemmatization is the process of grouping together the flexionated forms of the words so they can be analysed&amp;nbsp;together.&lt;/p&gt;
&lt;h3&gt;Segmentation&lt;/h3&gt;
&lt;p&gt;Segmentation is the task of breaking up the text into tokens, so each token can be analysed separately.
In our case, the tokenization can be done by address field: preffixes, location, complements and suffixes. For example, the&amp;nbsp;address&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Rua Nove de Julho, 2983 ap 33 bloco 1 CEP 00043-424 São Paulo SP&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;can be break up&amp;nbsp;into&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Preffix: &lt;code&gt;Rua&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Location: &lt;code&gt;Nove de Julho 2983&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Complements: &lt;code&gt;ap 33 bloco 1 CEP 00043-424&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Suffixes: &lt;code&gt;São Paulo SP&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is helpful because now we can match each part of the address with an existing canonical form without a lot of noise.
Each of the fields can be further processed to extract more information, like the postal code&amp;nbsp;number.&lt;/p&gt;
&lt;h3&gt;Parsing&lt;/h3&gt;
&lt;p&gt;The next step is to parse the address.
Parsing consists in break up the address string into fields that compose the address, the breaking up of the fields
mentioned above. To parse we have to assume a structure for the address, either by rules or by some techiques like
 Named Entity&amp;nbsp;Recognization.&lt;/p&gt;
&lt;h3&gt;Rebuild&amp;nbsp;text&lt;/h3&gt;
&lt;p&gt;This task consists in rebuild the normalized and annotated text to a final form. This will be done after the match&amp;nbsp;phase.&lt;/p&gt;
&lt;h2&gt;Identification and&amp;nbsp;Match&lt;/h2&gt;
&lt;p&gt;After cleaning up and normalizing the text we need to check if the value of the address exists in our canonical database. Two&amp;nbsp;approaches:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Match with existing&amp;nbsp;database&lt;/li&gt;
&lt;li&gt;Name Entity Recognition on&amp;nbsp;address&lt;/li&gt;
&lt;/ol&gt;
&lt;h3&gt;Match with canonical&amp;nbsp;database&lt;/h3&gt;
&lt;p&gt;If we have a canonical database with the data considered correct, our job is to match the target addresses with the ones
on this canonical database. This is a &lt;em&gt;match problem&lt;/em&gt;. We can attack this problem following these&amp;nbsp;steps:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;split address by field (prefix, location,&amp;nbsp;suffixes)&lt;/li&gt;
&lt;li&gt;retrieve match candidates (search&amp;nbsp;engine)&lt;/li&gt;
&lt;li&gt;Match address with candidates by&amp;nbsp;similarity&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For this approach we&amp;#8217;re going to work directly on the text patterns, without any kind of machine learning.
The canonical database is usually provided by the Post&amp;nbsp;Office.&lt;/p&gt;
&lt;p&gt;The match between two addresses is a way to check if two addresses are the same.
For example, let&amp;#8217;s say that we have in our canonical database the&amp;nbsp;entry&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;&lt;span class="caps"&gt;CEP&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;Location&lt;/th&gt;
&lt;th&gt;City&lt;/th&gt;
&lt;th&gt;State&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;00043243&lt;/td&gt;
&lt;td&gt;Nove de Julho&lt;/td&gt;
&lt;td&gt;São Paulo&lt;/td&gt;
&lt;td&gt;&lt;span class="caps"&gt;SP&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;00032312&lt;/td&gt;
&lt;td&gt;Nove de Setembro&lt;/td&gt;
&lt;td&gt;São Paulo&lt;/td&gt;
&lt;td&gt;&lt;span class="caps"&gt;SP&lt;/span&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;and we need to compare with the address above. Which one is the best match?
We could try to do an exact match: only the location strings that are exactly same are the same address.
But this would miss lots of entries that could have typing errors but are otherwise valid addresses,&amp;nbsp;like&lt;/p&gt;
&lt;p&gt;&lt;code&gt;Rua nov de Julho, 2938&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;So how do we compensate for these&amp;nbsp;errors?&lt;/p&gt;
&lt;h3&gt;Match&lt;/h3&gt;
&lt;p&gt;One approach is to retrieve candidates from the canonical database that are similar to the address we want to normalize. Search engines do that using different strategies. We&amp;#8217;re not going to detail this process, so let&amp;#8217;s just say that our search engine returned candidates to be&amp;nbsp;compared.&lt;/p&gt;
&lt;p&gt;For each of these candidates we do a comparison with our target address using some metric of similarity. There are several of such&amp;nbsp;metrics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Jaro&amp;nbsp;distance&lt;/li&gt;
&lt;li&gt;Jaro-Winkler&amp;nbsp;distance&lt;/li&gt;
&lt;li&gt;Cosine&amp;nbsp;distance&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;For now we&amp;#8217;re going to use Jaro-Winkler distance. We compare the target address with each of the candidates and rank by the similarity between&amp;nbsp;them.&lt;/p&gt;
&lt;h4&gt;Search&amp;nbsp;engines&lt;/h4&gt;
&lt;p&gt;Search engines usually already make the string similarity comparison to retrive the candidates, so it could, in principle, already compute the similarity score withou the need to program it by ourselves. But sometimes the search engine similarity algorithm cannot be tuned to the type of text, like addresses. We also have more information than only the Location string, like the postal code and suffixes. This could help in the decision&amp;nbsp;process.&lt;/p&gt;
&lt;h3&gt;&lt;span class="caps"&gt;NER&lt;/span&gt;&lt;/h3&gt;
&lt;p&gt;Instead of using regular expressions to break up the address text into components we could create a Named Entity Recognizer and let it separate the address by&amp;nbsp;fields.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;tag canonical database with relevant&amp;nbsp;tags&lt;/li&gt;
&lt;li&gt;train &lt;span class="caps"&gt;CRF&lt;/span&gt; with tagged&amp;nbsp;database&lt;/li&gt;
&lt;li&gt;classify each&amp;nbsp;address&lt;/li&gt;
&lt;li&gt;match classified entity with canonical&amp;nbsp;base&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Decision&amp;nbsp;process&lt;/h2&gt;
&lt;p&gt;After the text normalization and match we hopefully have a list of candidates with a similarity score between the target and a canonical address. How we decide if the address is indeed the correct address? We can set a score threshold, for example, based on our experience, and test the error rate. We also can create a classification model and train manually with some&amp;nbsp;entries.&lt;/p&gt;
&lt;h2&gt;In&amp;nbsp;Python&lt;/h2&gt;
&lt;p&gt;Let&amp;#8217;s show the steps above now with some Python and the Natural Language&amp;nbsp;Toolkit.&lt;/p&gt;</content><category term="data science"></category><category term="NLP"></category><category term="text mining"></category></entry><entry><title>Basic Python Setup for Data Science on Linux</title><link href="http://mfactor.sdf.org/blog/2016_03_17_basic_python_ds.html" rel="alternate"></link><published>2016-03-17T00:00:00-03:00</published><updated>2016-03-17T00:00:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-03-17:/blog/2016_03_17_basic_python_ds.html</id><summary type="html">&lt;p&gt;How to setup a basic data science environment with Python and&amp;nbsp;Linux&lt;/p&gt;</summary><content type="html">&lt;p&gt;Data scientists usually have a very diverse background and very different proficiency levels with some tools. This, as I usually say, is not negative, on the contrary! The best data science teams should have this diversity because the problems that they face are diverse by nature. 
As I said before, I&amp;#8217;ve been trying to set a system for data science with the tenets of reproducible research (&lt;span class="caps"&gt;RR&lt;/span&gt;). 
To do that, not only the project should be organized to support &lt;span class="caps"&gt;RR&lt;/span&gt;, but the work environment should support &lt;span class="caps"&gt;RR&lt;/span&gt;&amp;nbsp;too. &lt;/p&gt;
&lt;p&gt;So the idea of this post is to explain some basic concepts about Linux, linux shells, environment variables and how to glue everything together on a productive Python&amp;nbsp;environment. &lt;/p&gt;
&lt;h2&gt;Linux and Linux&amp;nbsp;shells&lt;/h2&gt;
&lt;h3&gt;Quick&amp;nbsp;detour&lt;/h3&gt;
&lt;p&gt;First, to get this out of the way: I really like the open source software philosophy and the software that the community writes, but sometimes you have to give and see that some battles are best fought elsewhere. &lt;em&gt;Linux&lt;/em&gt;, technically, is just the &lt;a href="https://en.wikipedia.org/wiki/Linux_kernel"&gt;kernel&lt;/a&gt; of a &lt;a href="https://en.wikipedia.org/wiki/Operating_system"&gt;operating system&lt;/a&gt;, usually composed of free and open source software, called &lt;a href="https://en.wikipedia.org/wiki/Linux_distribution"&gt;distribution&lt;/a&gt;. 
That&amp;#8217;s why sometimes you see &amp;#8220;Debian &lt;span class="caps"&gt;GNU&lt;/span&gt;/Linux&amp;#8221; distribution, because Debian, the Linux distribution, is composed of the &lt;a href="https://www.gnu.org/home.en.html"&gt;&lt;span class="caps"&gt;GNU&lt;/span&gt;&lt;/a&gt; tools and the Linux kernel. 
But the name &amp;#8220;Linux&amp;#8221; got very popular and usually means &lt;em&gt;both&lt;/em&gt; the kernel and the distribution. So don&amp;#8217;t worry if you say only Linux. I&amp;nbsp;don&amp;#8217;t. &lt;/p&gt;
&lt;h3&gt;Shell, terminal,&amp;nbsp;console&lt;/h3&gt;
&lt;p&gt;So, after this enormous rant, what is a shell? A &lt;a href="https://en.wikipedia.org/wiki/Unix_shell"&gt;shell&lt;/a&gt; command line interpreter that works as a user interface. 
A command line interpreter is exactly that, it interpretes and executes the commands given into instructions to the operating system. 
So shell is mostly just a program that reads commands typed into it! And best of all, it hides the details of the operating system. 
Shells can be used in an interactive fashion, where users type the commands, or in an automated way via &lt;em&gt;scripts&lt;/em&gt;. A script is a file with a series of commands to be executed. 
To be more specific, there are the interactive login, interactive non-login and script shells. 
Each has a different way to set environment variables and are called differently. The shell is also called &lt;em&gt;command line&lt;/em&gt; or &lt;em&gt;terminal&lt;/em&gt;. &lt;/p&gt;
&lt;h3&gt;Running a&amp;nbsp;command&lt;/h3&gt;
&lt;p&gt;Now let&amp;#8217;s see how a shell executes a command. Let&amp;#8217;s say we want to run &lt;code&gt;man ls&lt;/code&gt;, to get the manual page of the command &lt;code&gt;ls&lt;/code&gt;. 
There are two ways for the shell to call the executable &lt;code&gt;man&lt;/code&gt; with the argument &lt;code&gt;ls&lt;/code&gt;. 
The first one is to give the full path of the command to the&amp;nbsp;shell: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt;  /usr/bin/man
what manual page do you want?

&amp;gt; file /usr/bin/man
/usr/bin/man: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), 
dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, 
for GNU/Linux 2.6.32, BuildID[sha1]=ce062f3e946ea23a804345bc92b18983ab05c839, stripped
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So the shell will execute the command located on the directory &lt;code&gt;/usr/bin/man&lt;/code&gt;. 
The other one is how the shell stores information for each session: using one specific &lt;em&gt;environment variable&lt;/em&gt;. 
In this case, the shell searches the &lt;code&gt;PATH&lt;/code&gt; variable for the directories where it should seek the executable files. 
If the shell finds on one of the dirs, the program is called. If not it returns an&amp;nbsp;error:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;&amp;gt; echo &lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="x"&gt;&lt;/span&gt;
&lt;span class="x"&gt;/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So for our example, as the &lt;code&gt;man&lt;/code&gt; command is located on the &lt;code&gt;/usr/bin&lt;/code&gt; folder, calling only &lt;code&gt;man&lt;/code&gt; on the shell will execute&amp;nbsp;it:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; man
what manual page do you want?
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Let&amp;#8217;s see now what environment variables are. With them we can understand a bit better how Python finds its&amp;nbsp;packages.&lt;/p&gt;
&lt;h3&gt;Environment&amp;nbsp;Variables&lt;/h3&gt;
&lt;p&gt;Environment variables are &lt;a href="https://en.wikipedia.org/wiki/Environment_variable"&gt;&amp;#8220;a set of dynamic named values that can affect the way running processes will behave in a computer&amp;#8221;&lt;/a&gt;.
On a higher level, each program executed by the &lt;span class="caps"&gt;OS&lt;/span&gt; has its own set of environment variables. 
When a shell is started, it reads a predefined set of files and define the environment variables for that shell session. 
The files where the variables are defined and the order of the variable definitions depends on the shell and if the shell is interactive or script.
&lt;a href="https://shreevatsa.wordpress.com/2008/03/30/zshbash-startup-files-loading-order-bashrc-zshrc-etc/"&gt;This&lt;/a&gt; has the order for &lt;a href="http://www.zsh.org/"&gt;&lt;span class="caps"&gt;ZSH&lt;/span&gt;&lt;/a&gt; and &lt;a href="https://www.gnu.org/software/bash/"&gt;Bash&lt;/a&gt; files that are &lt;em&gt;sourced&lt;/em&gt;, defining the environment variables and executing the commands inside them.
(&lt;em&gt;Sourcing&lt;/em&gt; a file executes the lines of code inside that file as they were typed on the&amp;nbsp;shell.)&lt;/p&gt;
&lt;p&gt;Several variables are common to all &lt;a href="https://help.ubuntu.com/community/EnvironmentVariables"&gt;Unix&lt;/a&gt;. 
One of them is called &lt;code&gt;PATH&lt;/code&gt; and it tells which directories should be searched for programs to be executed. 
Another very common variable is called &lt;code&gt;HOME&lt;/code&gt; and identifies the path to the home folder for each user.
To understand what that means more pratically, we want to add a new folder in our &lt;code&gt;PATH&lt;/code&gt; variable, so the shell can find the executable without us having to type the entire file path. 
We are using &lt;code&gt;bash&lt;/code&gt; and we want to change only the user path, so we edit the &lt;code&gt;.bashrc&lt;/code&gt; file on his home folder, adding the&amp;nbsp;line&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;export PATH=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="x"&gt;:/home/user/bin/&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The &lt;code&gt;export&lt;/code&gt; means to attribute to the variable &lt;code&gt;PATH&lt;/code&gt; the value &lt;code&gt;/home/user/bin&lt;/code&gt;. 
The &lt;code&gt;$PATH&lt;/code&gt; part means to use the existing value of the variable &lt;code&gt;PATH&lt;/code&gt; and to append it with the path after it. 
Now, every time a new shell is created for this user, this new folder will be added to the &lt;code&gt;PATH&lt;/code&gt; variable, and the programs on this folder can be executed without having to type the entire file&amp;nbsp;path.&lt;/p&gt;
&lt;h2&gt;Python paths and&amp;nbsp;libraries&lt;/h2&gt;
&lt;p&gt;One of the great advantages of using Python for data science is the vast array of libraries available. 
This can be also a great pain when you have to manage different projects and different requirements. 
Virtualenvs does that by manipulating some environment variables. See where this is going?
The idea is to understand how Python works with some directories and paths and manipulate them for the Python interpreter and the libraries, in a way where each project can have its own dependecies and module&amp;nbsp;versions.&lt;/p&gt;
&lt;p&gt;Python uses environment variables defined at compile time and before execution.
The list of &lt;a href="https://docs.python.org/2/using/cmdline.html#environment-variables"&gt;environment variables&lt;/a&gt; defines some environment variables that can be changed before execution. 
To check inside Python which variables are defined, run inside a Python&amp;nbsp;shell&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt; &lt;span class="mi"&gt;2016&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;38&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                                                    
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;GCC&lt;/span&gt; &lt;span class="mf"&gt;5.3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;20160220&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;linux2&lt;/span&gt;                                                                                               
&lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;copyright&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;credits&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;license&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;information&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;                                                                                                           
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/plat-x86_64-linux-gnu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/lib-tk&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/lib-old&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/lib-dynload&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/usr/local/lib/python2.7/dist-packages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/dist-packages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/dist-packages/gtk-2.0&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/usr/lib/pymodules/python2.7&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;These are the paths where the Python intepreter will search for modules by&amp;nbsp;default. &lt;/p&gt;
&lt;h3&gt;Virtualenvs&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://virtualenv.pypa.io/en/latest/"&gt;Virtualenvs&lt;/a&gt; were created to isolate an environment, decoupling
the modules for each virtual environment and the system. 
We&amp;#8217;re going to use them to create our development environments. 
Virtualenv manipulates the paths and set to different directories than the standard ones. 
Let&amp;#8217;s create a virtualenv using &lt;a href="https://virtualenvwrapper.readthedocs.org/en/latest/"&gt;virtualenvwrapper&lt;/a&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&amp;gt; mkvirtualenv test
Running virtualenv with interpreter /usr/bin/python2
New python executable in test/bin/python2
Also creating executable in test/bin/python
Installing setuptools, pip...done.
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;With that the virtualenv is created and the variables have been changed to reflect the local&amp;nbsp;environment:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;python&lt;/span&gt;
&lt;span class="n"&gt;Python&lt;/span&gt; &lt;span class="mf"&gt;2.7&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;11&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;default&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;Feb&lt;/span&gt; &lt;span class="mi"&gt;22&lt;/span&gt; &lt;span class="mi"&gt;2016&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="mi"&gt;16&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;38&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="mi"&gt;42&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; 
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;GCC&lt;/span&gt; &lt;span class="mf"&gt;5.3&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="mi"&gt;20160220&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;on&lt;/span&gt; &lt;span class="n"&gt;linux2&lt;/span&gt;
&lt;span class="n"&gt;Type&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;help&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;copyright&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;credits&amp;quot;&lt;/span&gt; &lt;span class="ow"&gt;or&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;license&amp;quot;&lt;/span&gt; &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;more&lt;/span&gt; &lt;span class="n"&gt;information&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="o"&gt;&amp;gt;&amp;gt;&amp;gt;&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;path&lt;/span&gt;
&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/lib/python2.7&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/lib/python2.7/plat-x86_64-linux-gnu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/lib/python2.7/lib-tk&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/lib/python2.7/lib-old&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/lib/python2.7/lib-dynload&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/plat-x86_64-linux-gnu&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/usr/lib/python2.7/lib-tk&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/local/lib/python2.7/site-packages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="s1"&gt;&amp;#39;/home/user/.virtualenvs/test/lib/python2.7/site-packages&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Notice now that new paths are added for packages to be searched and used, so new packages are installed on these folders.
The virtualenv directory can be changed, from the default &lt;code&gt;~/.virtualenvs&lt;/code&gt; to any other folder where the user has&amp;nbsp;access.&lt;/p&gt;
&lt;p&gt;This structure allows to manage several different virtualenvs, each with its own packages and&amp;nbsp;configurations.&lt;/p&gt;
&lt;h3&gt;Changing the path to the Python&amp;nbsp;executable&lt;/h3&gt;
&lt;p&gt;What if a new Python version should be compiled and used? Probably the system will have to keep its Python version,
as Linux distributions use Python for system operations. 
One way to to it is to compile the needed Python version and put the path to the Python executable on the &lt;code&gt;PATH&lt;/code&gt; variable. From there new virtualenvs can be created using this specific Python&amp;nbsp;version.&lt;/p&gt;
&lt;h3&gt;Project&amp;nbsp;structure&lt;/h3&gt;
&lt;p&gt;To keep packages, versions and dependencies separated, each project should have its own virtualenv. 
For each virtualenv the necessary packages are installed using &lt;a href="https://pypi.python.org/pypi/pip"&gt;pip&lt;/a&gt;. 
The virtualenv directory should also be set to a known location, like &lt;code&gt;~/bin/virtualenvs&lt;/code&gt;. 
It&amp;#8217;s also good practice to keep a &lt;a href="https://pip.pypa.io/en/stable/user_guide/"&gt;requirements.txt&lt;/a&gt; file on the git&amp;nbsp;repository.&lt;/p&gt;
&lt;h2&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;That was a lot, for sure! Hopefully this will make clear how to use virtualenvs and environment variables to keep the
development and data analysis easier to manage, reproduce and&amp;nbsp;deploy.&lt;/p&gt;</content><category term="datascience"></category><category term="python"></category></entry><entry><title>Too many tools, not enough carpenters (short version)</title><link href="http://mfactor.sdf.org/blog/2016_02_16_tools_carpenters.html" rel="alternate"></link><published>2016-02-16T00:00:00-02:00</published><updated>2016-02-16T00:00:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-02-16:/blog/2016_02_16_tools_carpenters.html</id><summary type="html">&lt;p&gt;This is a somewhat shorter version of a good article about data science and&amp;nbsp;tools.&lt;/p&gt;</summary><content type="html">&lt;p&gt;I came across a &lt;a href="https://ckmadvisors.com/b/160212.html"&gt;great article&lt;/a&gt; about tools in data science. The &lt;span class="caps"&gt;TL&lt;/span&gt;;&lt;span class="caps"&gt;DR&lt;/span&gt; of the article is, basically, tools will not solve your data problem, skills will. That&amp;#8217;s what the title is alluding: there are too many (some great, some mediocrer) tools, but not enough people skilled in really understanding the data and doing something useful or valuable with it. I will try to translate the article to a somewhat shorter version of the original, to make the point more&amp;nbsp;accessible.&lt;/p&gt;
&lt;p&gt;++++++++++++++&lt;/p&gt;
&lt;p&gt;Big corporations are full with data but soon discover that transforming this data into something useful or valuable is very hard. On the other hand, startups are built from the ground up with data science ingrained on the very core, with a qualified team of data scientists, mainly because this data is the source of&amp;nbsp;revenue.&lt;/p&gt;
&lt;p&gt;Consumers don&amp;#8217;t pay for software a long time ago, so if you want to make money with software, you have to sell it to the enterprise. Data science is very hot right now, so software for data science is a no-brainer, right? Wrong. Big corporations are not like your startup: data is spread out in hundreds or thousands of systems that don&amp;#8217;t communicate. Huge amounts of data is generated and stored but until recently nobody thought about accessing or even less analysing this data. And as these corporations don&amp;#8217;t have data scientists in-house, nobody is really sure how this data can be used or even what this data &lt;em&gt;is&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Big companies also tried to do &amp;#8216;data warehousing&amp;#8217;, but usually these projects turn into an inconsistent and incomplete datasets, so even if a magic analysing software existed, there would be nowhere to be&amp;nbsp;connected. &lt;/p&gt;
&lt;p&gt;Many fail to understand that the core issue is not a lack of tools but a lack of&amp;nbsp;carpenters.&lt;/p&gt;
&lt;p&gt;These software companies bring their plug-and-play tools to only discover that they don&amp;#8217;t have a clue about the data environment inside a big corporation. Worse, they wouldn&amp;#8217;t know if their product solved a real defined business problem. They usually say, just dump all your data in our magic (very expensive, licensed locked) platform. What the tool was really capable of doing or adding value to the business was not&amp;nbsp;relevant. &lt;/p&gt;
&lt;p&gt;More specifically, the enterprise&amp;nbsp;needs:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;Plumbers&lt;/em&gt; to make sure all the data flows to the right place where it can be integrated and&amp;nbsp;harvested&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Detectives/Designers&lt;/em&gt; with strong data science skills to identify leads in the data and build those out into actionable opportunities for value&amp;nbsp;generation&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Data driven leaders&lt;/em&gt; that can take these insights and elicit tangible change in large&amp;nbsp;organizations&lt;/li&gt;
&lt;li&gt;&lt;em&gt;A data centric culture&lt;/em&gt; which demands that business operations leverage all available factual information to drive efficiency and&amp;nbsp;effectiveness&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Companies early on the data science maturity curve are typically excited about tools. They buy a few &amp;#8216;new systems&amp;#8217; that will produce amazing results but are sorely disappointed that these tools didn&amp;#8217;t deliver anything of value. Then finally the company moves to the next level, investing in organization and&amp;nbsp;skills.&lt;/p&gt;
&lt;p&gt;The truth is that a top team of data scientists can achieve great results using the toolsets already in place within a large enterprise, supplemented with some free (or very inexpensive) open source tools. Proprietary tools won&amp;#8217;t replace skilled talent, and skilled talent doesn&amp;#8217;t typically need many proprietary&amp;nbsp;tools.&lt;/p&gt;
&lt;p&gt;An organization that lacks such data science talent could spend many millions on data analytics tools and still not come anywhere close to the same results. When someone asks me to show them “the tool” that created these results, I introduce them to our data scientists. For the large enterprise, the challenge is finding and developing that talent&amp;nbsp;base. &lt;/p&gt;
&lt;p&gt;The market is gradually evolving into a more mature data science environment, away from the idea of extracting value of data is equal to buying more software&amp;nbsp;licenses.&lt;/p&gt;
&lt;p&gt;++++++++++++++&lt;/p&gt;
&lt;p&gt;Hopefully these ideas can kickstart a healthy discussion about the place of tools and skill to be able to use the data that a company has to benefit&amp;nbsp;all.&lt;/p&gt;</content><category term="data science"></category><category term="tools"></category></entry><entry><title>From Maple to Spark</title><link href="http://mfactor.sdf.org/blog/2016_02_15_maple_spark.html" rel="alternate"></link><published>2016-02-15T00:00:00-02:00</published><updated>2016-02-15T00:00:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-02-15:/blog/2016_02_15_maple_spark.html</id><summary type="html">&lt;p&gt;Doing scientific computing and business projects, from Maple to&amp;nbsp;Spark&lt;/p&gt;</summary><content type="html">&lt;p&gt;All started with cleaning up my bin&amp;nbsp;folder.&lt;/p&gt;
&lt;p&gt;Describe the idea of first using Maple in Physics, then doing our own 
computer programs and simulations, the time it took to write them and 
the support that we had for it, to today environment of using more &amp;#8220;basic&amp;#8221; 
programming languages and environments, less complete, but more&amp;nbsp;efficient.&lt;/p&gt;
&lt;p&gt;Why Matlab and Mathematica are not used in business organizations, 
as they are supposedly more feature complete and simple to&amp;nbsp;use?&lt;/p&gt;</content><category term="tools"></category><category term="maple"></category><category term="scientific software"></category><category term="python"></category><category term="spark"></category></entry><entry><title>Why OS packages (.deb) are out of fashion and the rage is self-update</title><link href="http://mfactor.sdf.org/blog/2016_02_14_os_deb_update.html" rel="alternate"></link><published>2016-02-14T00:00:00-02:00</published><updated>2016-02-14T00:00:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-02-14:/blog/2016_02_14_os_deb_update.html</id><summary type="html">&lt;p&gt;Why several programs are not packaged in operating&amp;nbsp;systems&lt;/p&gt;</summary><content type="html">&lt;p&gt;anymore and everyone are doing self-updates, and how this can be dangerous
status:&amp;nbsp;draft&lt;/p&gt;
&lt;p&gt;Show my &lt;code&gt;bin&lt;/code&gt; folder, structure and commands. Number of sofwares 
that are not packaged by &lt;span class="caps"&gt;OS&lt;/span&gt; anymore, time to package, rapid fire versions and update channels. Why this can be dangerous (Mac update package platform, ars&amp;nbsp;technica).&lt;/p&gt;</content><category term="os"></category><category term="debian"></category><category term="deb"></category><category term="tools"></category></entry><entry><title>Data Science workflow with reproducible research - Jupyter notebooks</title><link href="http://mfactor.sdf.org/blog/2016_01_16_reproducible_ds_2.html" rel="alternate"></link><published>2016-01-16T00:00:00-02:00</published><updated>2016-01-16T21:07:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2016-01-16:/blog/2016_01_16_reproducible_ds_2.html</id><summary type="html">&lt;p&gt;Jupyter notebook for data analysis using the project&amp;nbsp;structure&lt;/p&gt;</summary><content type="html">&lt;p&gt;As a follow up of the &lt;a href="http://mfactor.sdf.org/blog/2015_12_08_reproducible_ds.html"&gt;previous post&lt;/a&gt;, 
here I present a &lt;a href="https://jupyter.org"&gt;Jupyter&lt;/a&gt; notebook that incorporates a few
things that makes easier to follow the ideias of the data project&amp;nbsp;structure. &lt;/p&gt;
&lt;p&gt;The notebook can be found 
&lt;a href="https://github.com/ispmarin/ds_workshop/blob/master/src/template_ds_workshop.ipynb"&gt;here&lt;/a&gt;. 
Using the idea of auto documentation of the notebooks, this notebook details the&amp;nbsp;ideas. &lt;/p&gt;</content><category term="data science"></category><category term="data"></category></entry><entry><title>Data Science workflow with reproducible research</title><link href="http://mfactor.sdf.org/blog/2015_12_08_reproducible_ds.html" rel="alternate"></link><published>2015-12-08T00:00:00-02:00</published><updated>2015-12-08T22:42:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-12-08:/blog/2015_12_08_reproducible_ds.html</id><summary type="html">&lt;p&gt;Organization of a data science workflow using &lt;span class="caps"&gt;CRISP&lt;/span&gt;-&lt;span class="caps"&gt;DM&lt;/span&gt; and Reproducible&amp;nbsp;Research&lt;/p&gt;</summary><content type="html">&lt;h1&gt;Data science&amp;nbsp;workflow&lt;/h1&gt;
&lt;p&gt;I&amp;#8217;ve been wondering and tinkering about how to structure my data science projects, thinking on the lines of &lt;a href="http://reproducibleresearch.net/"&gt;Reproducible Research&lt;/a&gt; and separation of information. There is a lot of talk about the &lt;span class="caps"&gt;CRISP&lt;/span&gt;-&lt;span class="caps"&gt;DM&lt;/span&gt; &lt;a href="https://en.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining"&gt;Cross Industry Standard Process for Data Mining&lt;/a&gt; and I believe that &lt;span class="caps"&gt;CRISP&lt;/span&gt;-&lt;span class="caps"&gt;DM&lt;/span&gt; is indeed a good approach. There are others like &lt;a href="https://en.wikipedia.org/wiki/SEMMA"&gt;&lt;span class="caps"&gt;SEMMA&lt;/span&gt;&lt;/a&gt; that are similar. But how these processes come down to a real project organization? Breaking down the steps, in a general overview, a data science project generally&amp;nbsp;has&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;data&lt;/code&gt;, either the datasets or samples, that will be worked&amp;nbsp;on&lt;/li&gt;
&lt;li&gt;&lt;code&gt;src&lt;/code&gt; (a code folder), for analysis, &lt;span class="caps"&gt;ETL&lt;/span&gt; and&amp;nbsp;modeling&lt;/li&gt;
&lt;li&gt;&lt;code&gt;documentation&lt;/code&gt; about the problem, business case, the data and the&amp;nbsp;solution&lt;/li&gt;
&lt;li&gt;&lt;code&gt;results&lt;/code&gt;, in form of processed data, a software deployment process or final documentation (including&amp;nbsp;presentation)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Of course your project will have other needs or either a more complex or more simple structure, also depending on how you think about &lt;span class="caps"&gt;CRISP&lt;/span&gt;-&lt;span class="caps"&gt;DM&lt;/span&gt; or your own approach. But so far this structure above has helped me to keep things organized and understandable based on &lt;span class="caps"&gt;CRISP&lt;/span&gt;-&lt;span class="caps"&gt;DM&lt;/span&gt;. I try to keep in line the ideas from both the process and reproducible&amp;nbsp;research.&lt;/p&gt;
&lt;p&gt;I also have a few other requirements for my&amp;nbsp;projects:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;all code must be&amp;nbsp;versioned&lt;/li&gt;
&lt;li&gt;all data must be identified by data and&amp;nbsp;local&lt;/li&gt;
&lt;li&gt;the documentation should also be versioned a preferably&amp;nbsp;autogenerated&lt;/li&gt;
&lt;li&gt;the results should be reproducible, without&amp;nbsp;intervention&lt;/li&gt;
&lt;li&gt;libraries should be isolated from the system and preferably portable to other&amp;nbsp;systems&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Requirements 1 and 3 are satisfied using &lt;code&gt;git&lt;/code&gt;. I usually set the root of the project as the &lt;code&gt;git&lt;/code&gt; base directory and exclude on the &lt;code&gt;.gitignore&lt;/code&gt; the data and results directories. I decided not to include the &lt;code&gt;results&lt;/code&gt; folder because of requirement 4 and also because they can be big. An exception can be made if there are presentations inside &lt;code&gt;results&lt;/code&gt; that are not autogenerated. Part of the autogeneration of the documentation is made writing it on the analysis code itself, a la &lt;code&gt;jupyter&lt;/code&gt; notebook&amp;nbsp;style.&lt;/p&gt;
&lt;p&gt;Requirement 2 is satisfied using a simple directory structure. Inside the &lt;code&gt;data&lt;/code&gt; folder I create a directory with the date as the name, like &lt;code&gt;20151207&lt;/code&gt; and include hour and minute if I&amp;#8217;m generating samples with this precision. If I need to generate a sample a &lt;code&gt;sample&lt;/code&gt; directory inside the dated directory suffices. Some people advise to save intermediate steps if there are a lot of data cleanup steps. I tend to do it if the cleanup step is too time consuming, otherwise I just recompute the cleanup step. I also tend to include the metadata with the data, outside the data file, with the same name as the data file but with a &lt;code&gt;.meta&lt;/code&gt; termination.&lt;/p&gt;
&lt;p&gt;The local part of the &lt;code&gt;data&lt;/code&gt; can be tricky when using a database as a source, for example. This is one of the points where reproducible research helps a bit: databases can change, so let&amp;#8217;s say you run today a model with data pulled from a database. You should be able to reproduce exactly the same results any time, but the database could have been updated in the meantime and your project is not reproducible anymore. I download the data to a local storage file (either csv or &lt;span class="caps"&gt;HDF5&lt;/span&gt; or other format at hand) and use this file to do my computations. There is a real problem if the data set is too large or the data is sensitive, but so far I&amp;#8217;ve managed to do it without serious&amp;nbsp;issues.&lt;/p&gt;
&lt;p&gt;I usually use &lt;code&gt;jupyter&lt;/code&gt; and &lt;code&gt;python&lt;/code&gt; to do my analysis and modeling, so to satisfy requirement 4 I tend to write my notebooks and code so they are idempotent and can be restarted from different points. That also means that the results would be overwritten everytime the code is run. This can be a problem if a experiment is being done with different inputs, so this should be taken into account when thinking on the structure of the &lt;code&gt;results&lt;/code&gt; folder (It can use the same dated approach from the &lt;code&gt;data&lt;/code&gt; directory).&lt;/p&gt;
&lt;p&gt;The last requirement depends on the language or languages that are being used in the project. This is a rather lengthy subject, so I will restrict myself to Python. I use &lt;code&gt;virtualenvs&lt;/code&gt; without site packages and keep them on the &lt;code&gt;src&lt;/code&gt; folder. Each project has its own virtualenv. Other requirements, like map data, is also included on the project structure, so the entire project folder can be moved without great impact. Virtualenvs are not that portable between systems and this has been a problem so far without solution, especially if the other system doesn&amp;#8217;t have internet&amp;nbsp;access.&lt;/p&gt;
&lt;h2&gt;Project&amp;nbsp;Example&lt;/h2&gt;
&lt;p&gt;As an example I have the &lt;code&gt;polls&lt;/code&gt; project, with the following directory&amp;nbsp;structure:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="na"&gt;.pools&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;data&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151206&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls.meta&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_1000.csv&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_200.csv&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151203&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_rs.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sample&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_rs_1000.csv&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;polls_sample_pe_200.csv&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151202&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;all_polls.hdf&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;all_polls.meta&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;src&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;analysis&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;pools.ipynb&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sampling&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;sampling.py&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;etl&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;extract_from_mongo.py&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;generate_results&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;do_models.py&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;generate_webpage.py&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;generate_approach_action.py&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;images&lt;/span&gt;
            &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;header.png&lt;/span&gt;
            &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;logo.svg&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;doc&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;business&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;use_case.md&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;algorithm&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;machine_learning.md&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;analysis_results.md&lt;/span&gt;
         &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;images&lt;/span&gt;
            &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;analysis_all.png&lt;/span&gt;
&lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;results&lt;/span&gt;
   &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="err"&gt;20151207&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;voters.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;control_group.csv&lt;/span&gt;
      &lt;span class="err"&gt;+--&lt;/span&gt; &lt;span class="nf"&gt;approach_and_action.md&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;One of the things that I also consider is the use of symbolic links from the &lt;code&gt;src&lt;/code&gt; folder to the &lt;code&gt;results&lt;/code&gt; folder or do a copy of a figure, from&amp;nbsp;example.&lt;/p&gt;
&lt;p&gt;On the next article I plan to show a pattern for &lt;code&gt;jupyter&lt;/code&gt; notebooks to handle this&amp;nbsp;structure.&lt;/p&gt;</content><category term="data science"></category><category term="data"></category></entry><entry><title>Using `conda` instead of `pip`</title><link href="http://mfactor.sdf.org/blog/2015_11_26_conda.html" rel="alternate"></link><published>2015-11-26T00:00:00-02:00</published><updated>2015-11-26T22:42:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-11-26:/blog/2015_11_26_conda.html</id><summary type="html">&lt;p&gt;Trying out conda for managing Python&amp;nbsp;environments&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been struggling with which environment use to develop on Python applications that 
are going to be moved around and run on different systems. There is Hadoop and Spark on the mix, so things are getting
more complicated, too. Thinking about my environment, I have the following&amp;nbsp;requisites:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Determine the level of isolation of the&amp;nbsp;application.&lt;/li&gt;
&lt;li&gt;Point to the &lt;code&gt;python&lt;/code&gt; binary that I&amp;nbsp;want.&lt;/li&gt;
&lt;li&gt;Can be moved&amp;nbsp;around &lt;/li&gt;
&lt;li&gt;Can be deployed and used in systems without&amp;nbsp;internet&lt;/li&gt;
&lt;li&gt;Can be deployed and used without root&amp;nbsp;access&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;So far I have two alternatives: &lt;code&gt;virtualenv&lt;/code&gt; and &lt;code&gt;Anaconda&lt;/code&gt;. I&amp;#8217;ve been using &lt;code&gt;virtualenv&lt;/code&gt; for a while so I know 
better the limitations. I tried, then, to use &lt;code&gt;Anaconda&lt;/code&gt; to see how it works. The installer is heavy but it comes
with several useful things (&lt;code&gt;pandas&lt;/code&gt;, for example), so that&amp;#8217;s ok. Things got a bit complicated using the environments,
though, with the &lt;code&gt;conda&lt;/code&gt; application. To keep point 2 I changed the recommended &lt;code&gt;PATH&lt;/code&gt; variable&amp;nbsp;to &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;export PATH=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;PATH&lt;/span&gt;&lt;span class="x"&gt;:/home/ispmarin/bin:/home/ispmarin/bin/anaconda3/bin&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;so I get the system &lt;code&gt;python&lt;/code&gt; executable but all the other tools from &lt;code&gt;Anaconda&lt;/code&gt;. Nice. Then I created and environment
and installed some stuff there. Also works as expected, although it points to the &lt;code&gt;python&lt;/code&gt; binary from inside &lt;code&gt;Anaconda&lt;/code&gt;.
Acceptable. Then I deactivated the environment, and to my surprise, the &lt;code&gt;python&lt;/code&gt; executable didn&amp;#8217;t change back to 
the system one! Damn, that&amp;#8217;s a problem right there. There 
&lt;a href="http://stackoverflow.com/questions/33955516/anaconda-activate-deactivate-cycle-messes-up-path"&gt;are&lt;/a&gt; 
&lt;a href="https://github.com/conda/conda/issues/1846"&gt;several&lt;/a&gt; 
&lt;a href="https://github.com/conda/conda/pull/1727"&gt;bug&lt;/a&gt; reports on the &lt;code&gt;conda&lt;/code&gt; github, but still no final solution. So &lt;code&gt;conda&lt;/code&gt; is
out for&amp;nbsp;now.&lt;/p&gt;</content><category term="python"></category><category term="pip"></category><category term="conda"></category></entry><entry><title>Desktop Files on Debian/Ubuntu and XDG</title><link href="http://mfactor.sdf.org/blog/2015_11_23_desktop-files.html" rel="alternate"></link><published>2015-11-23T00:00:00-02:00</published><updated>2015-11-23T21:57:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-11-23:/blog/2015_11_23_desktop-files.html</id><summary type="html">&lt;p&gt;Organizing custom launchers on Debian/Ubuntu &lt;span class="caps"&gt;XDG&lt;/span&gt;&amp;nbsp;compliant&lt;/p&gt;</summary><content type="html">&lt;p&gt;I&amp;#8217;ve been struggling for a while now with custom launchers. First, a bit of organizatoin on how the launchers are supposed to&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;A &lt;code&gt;desktop file&lt;/code&gt; is a file that describes a launcher for an application. This file will be indexed by a Window Manager, like &lt;span class="caps"&gt;KDE&lt;/span&gt; or &lt;span class="caps"&gt;XFCE&lt;/span&gt; and can be shown on the menus and etc. The &lt;a href="http://standards.freedesktop.org/desktop-entry-spec/latest/apa.html"&gt;standard form&lt;/a&gt; of a desktop file&amp;nbsp;is&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="k"&gt;[Desktop Entry]&lt;/span&gt;
&lt;span class="na"&gt;Version&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;1.0&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Application&lt;/span&gt;
&lt;span class="na"&gt;Name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Foo Viewer&lt;/span&gt;
&lt;span class="na"&gt;Comment&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;The best viewer for Foo objects available!&lt;/span&gt;
&lt;span class="na"&gt;Exec&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;fooview %F&lt;/span&gt;
&lt;span class="na"&gt;Icon&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;fooview&lt;/span&gt;
&lt;span class="na"&gt;Actions&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Gallery;Create;&lt;/span&gt;
&lt;span class="na"&gt;Categories&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Network&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This file should be put on a standard path in the system, like &lt;code&gt;~/.local/share/applications&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;And how to check if the file you wrote is valid? Just run &lt;code&gt;desktop-file-validate&lt;/code&gt; and it will point any errors that you&amp;nbsp;have. &lt;/p&gt;
&lt;h2&gt;&lt;span class="caps"&gt;KDE&lt;/span&gt;&amp;nbsp;blunder&lt;/h2&gt;
&lt;p&gt;After figuring it out how was the correct format for the file, my menus on &lt;span class="caps"&gt;KDE&lt;/span&gt; (and all actions, like changing the default application)was not changing anything. After searching for a long time, I found a solution: the context menu in Dolphin, to change the default application, was poiting to &lt;code&gt;.local/share/applications/mineapps.list&lt;/code&gt; and &lt;span class="caps"&gt;KDE&lt;/span&gt; 5 was reading the file on &lt;code&gt;.config/mimeapps.list&lt;/code&gt;. The solution? Exporting the default directory where &lt;span class="caps"&gt;KDE&lt;/span&gt; can find its icons. On my system, I changed .zshenv and&amp;nbsp;added&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="x"&gt;XDG_DATA_DIRS=&lt;/span&gt;&lt;span class="p"&gt;$&lt;/span&gt;&lt;span class="nv"&gt;XDG_DATA_DIRS&lt;/span&gt;&lt;span class="x"&gt;:/home/ispmarin/.local/share/applications&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;done!&lt;/p&gt;</content><category term="linux"></category><category term="desktop"></category></entry><entry><title>How to learn Physics (and Mathematics) with History</title><link href="http://mfactor.sdf.org/blog/2015_08_18_physics_mathematics_history.html" rel="alternate"></link><published>2015-08-18T19:26:00-03:00</published><updated>2015-08-18T19:26:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-08-18:/blog/2015_08_18_physics_mathematics_history.html</id><summary type="html">&lt;p&gt;Watching the new Cosmos series about Faraday I was struck by a very
simple thought: seeing how things evolved made simpler for me to
understand physical concepts. I don&amp;#8217;t know if I had that epiphany before
or if that&amp;#8217;s common, but for me it was a revelation. Very …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Watching the new Cosmos series about Faraday I was struck by a very
simple thought: seeing how things evolved made simpler for me to
understand physical concepts. I don&amp;#8217;t know if I had that epiphany before
or if that&amp;#8217;s common, but for me it was a revelation. Very simple things,
like magnetic fields, were way more clear after showing what Faraday was
trying to achieve and was thinking than any Electromagnetism A that I
did as an undergrad. And I believe that this might help my new endeavor:
understanding probability&amp;nbsp;deeply.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ve been reading Lady Luck, by Warren Weaver, and I&amp;#8217;m loving it. It has
a very unique balance between telling the history of probability with
showing the basic concepts in a very clear way. Another fantastic thing
about this book is that it doesn&amp;#8217;t save on words: Warren repeats and
repeats what it is and what is not, so it&amp;#8217;s perfectly clear on every
moment what he&amp;#8217;s talking about. That&amp;#8217;s uncommon for a math book: usually
the authors assume that everyone knows what he means and that a beginner
easily can understand everything that is going on when a formula or a
concept is demonstrated. The terror of physicists - &amp;#8220;it can be easily
demonstrated&amp;#8221; is avoided at all costs. The trade off is that sometimes
verbosity can be a little tiresome, but for me it has a clarity that I
wished all my undergrad textbooks had. And that&amp;#8217;s the connection between
the Cosmos episode and this book: both show the concepts from a basic
point of view, but they excel in going deep in the subject without being
condescending or jumping &amp;#8220;obvious&amp;#8221; steps, showing the history behind
that idea and how it came to&amp;nbsp;be.&lt;/p&gt;
&lt;p&gt;At least on my first years as a Physics undergrad, all students were
eager to experiment, to go hands on the physics labs or the observatory.
Two things were hammered down on us, one good and one bad. The good one
was that we had to have method: just poking things randomly would not
take us very far, as fun as it was. Teaching this method (called,
despite all controversy, the scientific method) was one of the best
things that I could have learned as an undergrad. The bad thing was that
we were buried in math courses without any kind of context. On the first
year alone we had an ordinary and partial differential equations course,
a analytical geometry course, two calculus courses and a basic
programming course, plus some optional advanced physics math courses. I
know that this is common on physics courses, but those were just dumped
on us. Some physics teachers tried to give us context, but it was more
on the ping-pong version (&amp;#8220;this you will see on your calculus course&amp;#8221;,
&amp;#8220;this you will see on your physics course&amp;#8221; and so on) and not very
helpful. This demotivated me and several other students. Why did we need
to learn all this calculus and geometry without any tangible reason?
(The &amp;#8220;you&amp;#8217;re going to need this to understand that&amp;#8221; is not very helpful,
at all. You don&amp;#8217;t know that yet!). Only after my first classical
mechanics course things started to make more sense, and got better with
a great electromagnetism teacher that showed how things were put
together by Maxwell and&amp;nbsp;Faraday.&lt;/p&gt;
&lt;p&gt;Maybe this is about the &amp;#8220;math first&amp;#8221;or &amp;#8220;physics first&amp;#8221; dilemma for a
Physics course. If you already know the math you can concentrate on the
Physics ideas and results. If you know the physics principles before,
the math is the best support for those ideas to flourish and be useful.
(On an aside, I don&amp;#8217;t agree with a teacher that I had that said &amp;#8220;all you
need is the physical intuition, the math is the easy part! Follow your
intuition!&amp;#8221; and every time we needed the math, he would fail.) I can see
both sides now and would propose a third option: teach the history
first. With the context things would be easier on both sides, the ideas
would permeate the ideas on both sides and maybe provide more support
for thought and understanding. This maybe would prevent the effect of
trusting only on the math, without reflecting what the math is telling
you. As another great teacher said, &amp;#8220;What is a sign? It&amp;#8217;s the difference
of sending the astronaut to the moon or killing&amp;nbsp;him!&amp;#8221;&lt;/p&gt;
</content><category term="learning"></category><category term="mathematics"></category><category term="physics"></category><category term="statistics"></category></entry><entry><title>A history of packages and libraries or: how Spark and Hadoop are doing the same mistake as BLAS and LAPACK</title><link href="http://mfactor.sdf.org/blog/2015_07_20_blas_lapack_spark.html" rel="alternate"></link><published>2015-07-20T09:33:00-03:00</published><updated>2015-07-20T09:33:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-07-20:/blog/2015_07_20_blas_lapack_spark.html</id><summary type="html">&lt;p&gt;A long time ago, on a land of big iron and &lt;span class="caps"&gt;MPI&lt;/span&gt;, there were some
libraries that were used everywhere. The libraries were fundamental to
most of the important computation that was done, they were open source
and all the cool kids on the block knew them. They also rarely …&lt;/p&gt;</summary><content type="html">&lt;p&gt;A long time ago, on a land of big iron and &lt;span class="caps"&gt;MPI&lt;/span&gt;, there were some
libraries that were used everywhere. The libraries were fundamental to
most of the important computation that was done, they were open source
and all the cool kids on the block knew them. They also rarely were
distributed by the Linux distributions, and several versions needed to
coexist to support all the high performance software that needed to be
run. They needed to be compiled, and different versions of compilers and
libraries and binaries kept spiralling out of control. Keeping them
working was already a huge task, and working well was even harder. And
yes, I&amp;#8217;m talking about &lt;span class="caps"&gt;BLAS&lt;/span&gt; and &lt;span class="caps"&gt;LAPACK&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www.netlib.org/blas/"&gt;&lt;span class="caps"&gt;BLAS&lt;/span&gt;&lt;/a&gt; (Basic Linear Algebra Suprograms)
and &lt;a class="reference external" href="http://www.netlib.org/lapack/"&gt;&lt;span class="caps"&gt;LAPACK&lt;/span&gt;&lt;/a&gt; (Linear Algebra PACKAge),
from &lt;a class="reference external" href="http://www.netlib.org/"&gt;Netlib&lt;/a&gt;, were fundamental on the &lt;span class="caps"&gt;HPC&lt;/span&gt;
era as the backbone of inumerous projects. The stack on those days had
one flavour or another of
&lt;a class="reference external" href="https://en.wikipedia.org/wiki/Message_Passing_Interface"&gt;&lt;span class="caps"&gt;MPI&lt;/span&gt;&lt;/a&gt; to run
the parallel jobs in huge clusters, together with
&lt;a class="reference external" href="http://www.netlib.org/scalapack/"&gt;ScaLAPACK&lt;/a&gt;. And the job of keeping
these libraries working with several different compilers (mainly
&lt;a class="reference external" href="https://gcc.gnu.org/"&gt;&lt;span class="caps"&gt;GCC&lt;/span&gt;&lt;/a&gt;,
&lt;a class="reference external" href="https://software.intel.com/en-us/intel-compilers"&gt;Intel&lt;/a&gt; and
&lt;a class="reference external" href="http://www.pgroup.com/"&gt;Portland Group&lt;/a&gt; compilers ) and linking
binaries objects were the nightmare of any sysadmin. Written mainly in
Fortran, with wrappers for C and C++, a sysadmin had to keep the entire
stack compiled with the right version of compilers and linked with the
right libraries. Projects like &lt;a class="reference external" href="http://www.netlib.org/atlas/"&gt;&lt;span class="caps"&gt;ATLAS&lt;/span&gt;&lt;/a&gt;
tried to help a bit on the side of performance optimization, while
vendors had their own binary distribution, tuned to their processors
(&lt;a class="reference external" href="https://software.intel.com/en-us/intel-mkl"&gt;&lt;span class="caps"&gt;MKL&lt;/span&gt;&lt;/a&gt; for Intel and
&lt;a class="reference external" href="http://developer.amd.com/tools-and-sdks/cpu-development/amd-core-math-library-acml/"&gt;&lt;span class="caps"&gt;ACML&lt;/span&gt;&lt;/a&gt;
for &lt;span class="caps"&gt;AMD&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;A sysadmin on the &lt;span class="caps"&gt;HPC&lt;/span&gt; world had to know all these libraries, how to
deploy them to the users that wanted to compile their own programs, and
how to make all of them play nice with each other on the same cluster.
It was hard to keep track of what was breaking, with lots of non
standard paths and binary objects, name mangling, and users trying to do
things that you never imagined possible. The &lt;span class="caps"&gt;HPC&lt;/span&gt; sysadmin also needed to
know the underlying architecture very well, including the network and
storage structures, the physical layout of the cables, so he or she
could have a chance to know what was breaking or lagging.&amp;nbsp; Slowly, these
tools started to be better organized, with practices like module loading
and the linux distributions creating packages to the basic libraries,
even if the performance was not the best possible. And then the Cloud&amp;nbsp;happened.&lt;/p&gt;
&lt;p&gt;(I&amp;#8217;m not going to dwelve on the &lt;span class="caps"&gt;HPC&lt;/span&gt; vs Cloud debate, not even try to
touch the Big Data vs &lt;span class="caps"&gt;BI&lt;/span&gt; vs computing debates, and try to focus on the
tools that make all these acronyms possible, otherwise this would be a
very long&amp;nbsp;post.)&lt;/p&gt;
&lt;p&gt;I have some time now on my hands and decided to check how the deployment
and configuration of a Spark cluster is being done on
&lt;a class="reference external" href="https://spark.apache.org/docs/latest/"&gt;Debian&lt;/a&gt;. And boy, &lt;a class="reference external" href="http://spark.apache.org/docs/latest/building-spark.html"&gt;what a
surprise&lt;/a&gt;.
I&amp;#8217;ve been seeing several posts from sysadmins complaining about the
dockerization of applications and the mirage of the devops, but was
taken aback with the state of how Spark is suposed to be deployed on a
Debian (&lt;a class="reference external" href="http://bigtop.apache.org/book/apache-bigtop-user-guide/apache-bigtop-user-guide.html"&gt;or any other
linux&lt;/a&gt;)
installation. There are several binaries spread out, with
interdependencies, depending on the compiler version or library version,
without standard paths, and users making a even larger mess&amp;#8230; where did
I hear about it&amp;nbsp;before?&lt;/p&gt;
&lt;p&gt;I expected that with the amout of resources that are being poured on the
cloud projects, some form of organization or standardization would have
happened. But no luck: all is still downloading binaries and compiling
tons of disconnected but interdependent libraries, only with more levels
of abstraction. Yes, the abstraction levels help the user, as he doesn&amp;#8217;t
need anymore to know about if the processor has &lt;span class="caps"&gt;SSE3&lt;/span&gt; or &lt;span class="caps"&gt;SSE4&lt;/span&gt;.2. Yes, now
devops can be both programmers and sysadmins. Yes, you don&amp;#8217;t have to buy
new machines, install them, plug the cables - you can just go to the &lt;span class="caps"&gt;AWS&lt;/span&gt;
console and click moar instances. But someone, on the end, has to move
all this to production, keep it working, plan on how this will grow, and
fix it when it breaks - and it will break, trust&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;Oh, but there&amp;#8217;s &lt;a class="reference external" href="https://www.openstack.org/"&gt;OpenStack&lt;/a&gt;to the
rescue! Well, not really. I&amp;#8217;m also not going to go deep into OpenStack,
but suffice to say that OpenStack is more an orchestration service than
what I&amp;#8217;m looking into&amp;nbsp;here.&lt;/p&gt;
&lt;p&gt;And oh, there&amp;#8217;s Docker/Vagrant/CoreOS/etc containers! Well, that&amp;#8217;s also
an issue that I think is not the focus of this discussion. During the
&lt;span class="caps"&gt;HPC&lt;/span&gt; era, usually the application deployment consisted of: configuring
the computing nodes to communicate, share the data using a dedicated
network connected to a &lt;span class="caps"&gt;RAID&lt;/span&gt; server and running a binary on a &lt;span class="caps"&gt;NFS&lt;/span&gt; share.
Things got way more complicated because they are more complicated:
connection to several databases, web services, what not. But in the end
the problem is the same: how to deploy an environment that you can
maintain and fix? These technologies help immensely on empowering the
developer to create more complex solutions and abstract more, especially
parallel computations, but they actually make the maitain and fix part
way more complicated, from the sysadmin perspective. That&amp;#8217;s why I&amp;#8217;m not
trying to address again these tools: they solve another problem, and
anyway, you have to configure these containers with the same binaries
and libraries, that need to be compiled, going back to the initial&amp;nbsp;problem!&lt;/p&gt;
&lt;p&gt;So, is there a way to solve this mess? Unfortunately, I don&amp;#8217;t know. I&amp;#8217;ve
been sidelining all these issues on the day to day at work, adding
binaries and virtualenvs when needed, but this will explode soon or
later. I just think that this problem is not being looked with much
care, especially on the startup world, or just being pushed to the new
&lt;a class="reference external" href="https://anotherlifeform.files.wordpress.com/2015/07/7d267-11359006_420191058182770_2015412754_n.jpg"&gt;shiny new
thing&lt;/a&gt;that
will solve everything with more abstraction. What to do? Maybe to think
about these points when deploying your cluster, playing better with the
basic distributions and contributing more, and the distros trying not to
suffer from &lt;span class="caps"&gt;NIH&lt;/span&gt; syndrome would&amp;nbsp;help.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;m all ears for&amp;nbsp;suggestions!&lt;/p&gt;
</content><category term="beowulf"></category><category term="big data"></category><category term="debian"></category><category term="haddop"></category><category term="openstack"></category><category term="spark"></category></entry><entry><title>Python reads on data understanding and web development</title><link href="http://mfactor.sdf.org/blog/2015_07_08_python-reads.html" rel="alternate"></link><published>2015-07-08T04:45:00-03:00</published><updated>2015-07-08T04:45:00-03:00</updated><author><name>I M</name></author><id>tag:mfactor.sdf.org,2015-07-08:/blog/2015_07_08_python-reads.html</id><summary type="html">&lt;p&gt;I´ve been overwhelmed by the number of good publications, workbooks and
other material on Python and Data Science on the web. I tried to keep
track and read everything, but my time on the job has been limited for
that. I decided to keep a list of the sources …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I´ve been overwhelmed by the number of good publications, workbooks and
other material on Python and Data Science on the web. I tried to keep
track and read everything, but my time on the job has been limited for
that. I decided to keep a list of the sources that I´m reading or want
to read here. They are, in no&amp;nbsp;order:&lt;/p&gt;
&lt;ul class="simple"&gt;
&lt;li&gt;&lt;a class="reference external" href="http://www.fullstackpython.com/"&gt;http://www.fullstackpython.com/&lt;/a&gt; Awesome resource for Python web&amp;nbsp;development.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://plot.ly/ipython-notebooks/survival-analysis-r-vs-python/"&gt;https://plot.ly/ipython-notebooks/survival-analysis-r-vs-python/&lt;/a&gt;
Survival analysis in R and Python. Excellent resource to combine
ipython notebooks with R. (The entire plotly notebooks collection is
awesome. I would love if plotly was open source or at least&amp;nbsp;free.)&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/donnemartin/data-science-ipython-notebooks"&gt;https://github.com/donnemartin/data-science-ipython-notebooks&lt;/a&gt; This is
an awesome collection of notebooks with all the parts of a good data
stack on Python. Still no time to review them all, but so far, very
good and detailed. &lt;a class="reference external" href="http://nbviewer.ipython.org/github/donnemartin/data-science-ipython-notebooks/blob/master/scipy/effect_size.ipynb"&gt;This is
one&lt;/a&gt;
of the best on the statistical&amp;nbsp;side.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="http://people.duke.edu/~ccc14/sta-663/"&gt;http://people.duke.edu/~ccc14/sta-663/&lt;/a&gt; This one is very through, even
if sometimes a bit rough on the edges. Very good reference material.
There are other materials from the folks at Duke that are very good,
like &lt;a class="reference external" href="http://people.duke.edu/~ccc14/pcfb/"&gt;this&lt;/a&gt; one, a bit more&amp;nbsp;biological.&lt;/li&gt;
&lt;li&gt;&lt;a class="reference external" href="https://github.com/josephmisiti/awesome-machine-learning"&gt;https://github.com/josephmisiti/awesome-machine-learning&lt;/a&gt; More on the
line of Machine Learning, this collection is also quite good, if a
bit extensive. The objective is more to list all resources and
libraries on several languages about Machine Learning than just
Python, but nonetheless the Python section is&amp;nbsp;good.&lt;/li&gt;
&lt;li&gt;Keeping the more generalist vibe,&lt;a class="reference external" href="http://www.wzchen.com/data-science-books"&gt;this
list&lt;/a&gt;of free books
about Data Science has the basic stuff for the&amp;nbsp;job.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I will keep things updated here as the list grows. Please send me
suggestions of good resources that you want to see on this&amp;nbsp;list!&lt;/p&gt;
</content><category term="data science"></category><category term="Python"></category><category term="web development"></category></entry><entry><title>Finally, Python 3!</title><link href="http://mfactor.sdf.org/blog/2015_06_27_finally_python_3.html" rel="alternate"></link><published>2015-06-27T09:39:00-03:00</published><updated>2015-06-27T09:39:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-06-27:/blog/2015_06_27_finally_python_3.html</id><summary type="html">&lt;p&gt;It&amp;#8217;s 2015 and it&amp;#8217;s the first time that I&amp;#8217;m using Python 3
professionally. And I have to admit, if I knew that all my scripts were
going to work so easily with 3, I would have changed way before. There
were a few hurdles with the Python …&lt;/p&gt;</summary><content type="html">&lt;p&gt;It&amp;#8217;s 2015 and it&amp;#8217;s the first time that I&amp;#8217;m using Python 3
professionally. And I have to admit, if I knew that all my scripts were
going to work so easily with 3, I would have changed way before. There
were a few hurdles with the Python 3 version of some libraries - patsy,
I&amp;#8217;m looking at you - but so far the transition was painless. The things
that I had to change were expected, like the print function and some
dict operations, and xrange. I know it&amp;#8217;s for the best now, so let&amp;#8217;s&amp;nbsp;roll.&lt;/p&gt;
&lt;p&gt;First of all, I switched from WinPython to Anaconda. Having to work on a
constrained Windows installation, Anaconda provides better support for
installing packages than pip alone. And as so far using virtualenv has
not been a success on Windows, I&amp;#8217;m going to try the conda environment
for my&amp;nbsp;projects.&lt;/p&gt;
&lt;p&gt;On the version control front, I finally got access to a git shell on
Windows, and now I can keep my sanity working with code. There&amp;#8217;s even a
Team Foundation Server plugin for it, and the client is not that bad -
actually, it&amp;#8217;s useful and keeps the git terminology, helping immensely
someone that was used to git on the command line. Not bad, Microsoft.
Git-cola is still better and is several times smaller than &lt;span class="caps"&gt;TFS&lt;/span&gt;, but hey,
sometimes we have to use what we got. So my working environment now&amp;nbsp;is&lt;/p&gt;
&lt;p&gt;* Anaconda 2.2.0, Python 3&amp;nbsp;version&lt;/p&gt;
&lt;p&gt;*&amp;nbsp;Packages:&lt;/p&gt;
&lt;p&gt;-pandas, sklearn, matplotlib, calendar, sqlalchemy with Oracle plugin,
seaborn (mostly for styles),&amp;nbsp;statsmodels.&lt;/p&gt;
&lt;p&gt;*&amp;nbsp;Editor:&lt;/p&gt;
&lt;p&gt;Vim and ipython notebook (depending on the type of&amp;nbsp;work)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="https://msysgit.github.io/"&gt;Git for&amp;nbsp;Windows&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;and Tableau for some&amp;nbsp;visualizations.&lt;/p&gt;
</content><category term="python"></category><category term="python3"></category></entry><entry><title>Gnome 3.16 on Debian Unstable: New adventures on the Window Manager lands</title><link href="http://mfactor.sdf.org/blog/2015_05_24_gnome-3-16-on-debian-unstable.html" rel="alternate"></link><published>2015-05-24T15:49:00-03:00</published><updated>2015-05-24T15:49:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-05-24:/blog/2015_05_24_gnome-3-16-on-debian-unstable.html</id><summary type="html">&lt;p&gt;I finally got my hands on a decent monitor, the &lt;a class="reference external" href="http://accessories.la.dell.com/sna/productdetail.aspx?c=br&amp;amp;l=pt&amp;amp;s=dhs&amp;amp;cs=brdhs1&amp;amp;sku=480-ACXS"&gt;Dell
&lt;span class="caps"&gt;U2515H&lt;/span&gt;&lt;/a&gt;.
It has been, so far, an awesome monitor. But that showed a few issues
with my standard Debian installation, with &lt;span class="caps"&gt;KDE&lt;/span&gt; 4.14 on Debian Unstable.
It seemed that every &lt;span class="caps"&gt;GTK&lt;/span&gt; application decided to throw a fit together …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I finally got my hands on a decent monitor, the &lt;a class="reference external" href="http://accessories.la.dell.com/sna/productdetail.aspx?c=br&amp;amp;l=pt&amp;amp;s=dhs&amp;amp;cs=brdhs1&amp;amp;sku=480-ACXS"&gt;Dell
&lt;span class="caps"&gt;U2515H&lt;/span&gt;&lt;/a&gt;.
It has been, so far, an awesome monitor. But that showed a few issues
with my standard Debian installation, with &lt;span class="caps"&gt;KDE&lt;/span&gt; 4.14 on Debian Unstable.
It seemed that every &lt;span class="caps"&gt;GTK&lt;/span&gt; application decided to throw a fit together and
nothing worked. I tried to adjust a lot of stuff on gtk-qt to fix it to
no avail but as it was &lt;span class="caps"&gt;GTK&lt;/span&gt; that was giving me headaches, maybe
installing Gnome things would be better on &lt;span class="caps"&gt;KDE&lt;/span&gt; side. So after a really
long time I decided to test a new window manager while at it, and now
I&amp;#8217;m running Gnome 3.16 on Debian Unstable. (Also, it is a good change of
pace while I wait for &lt;span class="caps"&gt;KDE&lt;/span&gt; 5 hit&amp;nbsp;Unstable.)&lt;/p&gt;
&lt;p&gt;But, as every transition&amp;#8230; things got a little rough. The &lt;a class="reference external" href="https://plus.google.com/+LinusTorvalds/posts/UkoAaLDpF4i"&gt;famous
rant&lt;/a&gt; by
Linus Torvalds rings very true: they simplified so much that it&amp;#8217;s dumb
(even if Linus is &lt;a class="reference external" href="https://plus.google.com/115250422803614415116/posts/KygiWsQc4Wm"&gt;using it
again&lt;/a&gt;).
There are some things that I found to be incredible as design decisions,
and Gnome Extensions is one of&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;C&amp;#8217;mon, how am I supposed to keep different systems updated, with the
same extensions? How do I know that they will work before I install
them? Who makes them? There are a few packaged in Debian, but not
enough. And to see how this is crazy, I had to install extensions to
show a suspend button, wicd-gtk on a tray, and I still can&amp;#8217;t find one to
easily lock my screen or close the session! So both things that
shouldn&amp;#8217;t be broken, standard desktop stuff and extensions, are broken
in one&amp;nbsp;go.&lt;/p&gt;
&lt;p&gt;Also, there is no easy way to change the system fonts, colors or
everything else. I had to use gnome-tweak-tool to do all this, a
non-standard tool, and still there are a ton of stuff that I should be
able to configure and it is removed. Even in more lighter environments,
like &lt;span class="caps"&gt;LXDE&lt;/span&gt;, I stil can change the icons or set a random image as my
wallpaper, as a user. I don&amp;#8217;t want to copy stuff to /usr or other system
directories, I should be able to override the system paths with folders
on my home directory, preferably under .local or .config. (And if you&amp;#8217;re
thinking that I must go to the image, right-click it to set as wallpaper
as the only way to do it, no, that is no proper behavior.) The fact that
even if I do the right-click thing, now I have a folder called
Wallpapers on my home folder buggers me. I didn&amp;#8217;t ask for a wallpaper
folder, just use any path that I gave you! &lt;span class="caps"&gt;ME&lt;/span&gt;, not Gnome programmers,
know were my files should&amp;nbsp;go.&lt;/p&gt;
&lt;p&gt;Also, I can&amp;#8217;t lock my screen if &lt;span class="caps"&gt;GDM&lt;/span&gt; is not running. This is now really
bad, not just annoyances like before. They hand-wave this away saying
that this will be solved with Wayland, but Wayland has been in
development for a while and it&amp;#8217;s not shipping as production ready for
another not known time, so I would have to wait for it to lock my
screen? I don&amp;#8217;t want to run &lt;span class="caps"&gt;GDM&lt;/span&gt;, I should be able to run whatever login
manager I want and be able to lock my screen in the &lt;span class="caps"&gt;WM&lt;/span&gt;. If Gnome keeps
following this &amp;#8220;Windows&amp;#8221; path all the complaints in the last years would
be true. The dependency on their own backyard instead of keeping things
interchangeable is a very troubling sign, and like the systemd debacle,
it just keeps getting&amp;nbsp;worse.&lt;/p&gt;
&lt;p&gt;I understand the need for standards, and &lt;span class="caps"&gt;XDG&lt;/span&gt; directives are ok, but
instead of thinking that the users are dumb, please at least let us
choose. I know this is kinda of a old rant against Gnome, and it can get
very ugly if I start mentioning Gnome 2, but from a fresh start, Gnome
right now is bad. Yadda yadda use another window manager, I get it. I
will, as soon I can get my hands on &lt;span class="caps"&gt;KDE&lt;/span&gt; 5. But for now, maybe another
voice trying to show what is broken, from an outside perspective, can
help a bit into steering things on a better&amp;nbsp;path.&lt;/p&gt;
</content></entry><entry><title>Analytics in a locked world</title><link href="http://mfactor.sdf.org/blog/2015_04_21_analytics-in-a-locked-world.html" rel="alternate"></link><published>2015-04-21T19:25:00-03:00</published><updated>2015-04-21T19:25:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2015-04-21:/blog/2015_04_21_analytics-in-a-locked-world.html</id><summary type="html">&lt;p&gt;As a data scientist, I have to deal with data from several different
sources. This begs for a wide range of tools and great flexibility of
using these tools, otherwise manipulating the data can be almost
impossible. And then your employer says that you can only use Windows,
without admin …&lt;/p&gt;</summary><content type="html">&lt;p&gt;As a data scientist, I have to deal with data from several different
sources. This begs for a wide range of tools and great flexibility of
using these tools, otherwise manipulating the data can be almost
impossible. And then your employer says that you can only use Windows,
without admin rights, and you can only install software from a very
restrict pre-approved list. What do you do? Go to a corner and&amp;nbsp;cry?&lt;/p&gt;
&lt;p&gt;Almost. But then, you find a breach, a sliver of hope. You can install
python on your machine. And in this moment, you smile, asking if you&amp;#8217;re
up to the challenge. (Dramatic,&amp;nbsp;no?)&lt;/p&gt;
&lt;p&gt;With one of the best Python installations for Windows is
&lt;a class="reference external" href="https://winpython.github.io/"&gt;WinPython&lt;/a&gt;, that comes prepackaged
with &lt;a class="reference external" href="https://github.com/winpython/winpython/issues/56"&gt;Numpy, Scipy and
Pandas&lt;/a&gt; and other
neat stuff, you can start really working. The second best part is that
you can install on your user folder, so you don&amp;#8217;t need admin rights.
Ufta! And the savior for sane workflows in this setting is
&lt;a class="reference external" href="https://jupyter.org/"&gt;Jupyter&lt;/a&gt;, the new IPython shell. It is awesome
for the data and modelling&amp;nbsp;workflow.&lt;/p&gt;
&lt;p&gt;My workflow now consists&amp;nbsp;of:&lt;/p&gt;
&lt;p&gt;1. Getting all raw data in one place, be excel spreadsheets (don&amp;#8217;t ask),
&lt;span class="caps"&gt;CSV&lt;/span&gt; files, word files (I said don&amp;#8217;t ask!), and some data banks. Most of
my data are time&amp;nbsp;series.&lt;/p&gt;
&lt;p&gt;2. Importing the data or connecting the services on a jupyter python
notebook. I have to connect to an oracle &lt;span class="caps"&gt;BD&lt;/span&gt;, so
&lt;a class="reference external" href="http://cx-oracle.sourceforge.net/"&gt;cx_Oracle&lt;/a&gt; is the&amp;nbsp;connector.&lt;/p&gt;
&lt;p&gt;3. Parsing the data with
&lt;a class="reference external" href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.io.excel.ExcelFile.parse.html"&gt;ExcelFile&lt;/a&gt;
from &lt;a class="reference external" href="http://pandas.pydata.org/"&gt;pandas&lt;/a&gt;. It can be tricky. As each
sheet is different, I use a &lt;span class="caps"&gt;JSON&lt;/span&gt; file with the starting line, starting
and ending columns, number of lines to be read and headers. That way I
can process it automatically, and if the file changes is quite easy to&amp;nbsp;adjust.&lt;/p&gt;
&lt;p&gt;4. Ok, clear the data! This is usually the most problematic part. One of
the things that I had to do was to convert zero values to NaNs. The
reason is that zero is a valid value on my data, but not a real one, so
it would skew all statistics. Pandas can handle NaNs in the&lt;a class="reference external" href="http://pandas.pydata.org/pandas-docs/version/0.16.0/gotchas.html"&gt;Right
Way&lt;/a&gt;,
so you would be better off. But beware, there are a few problems with
&lt;a class="reference external" href="http://stackoverflow.com/questions/29747850/error-using-bootstrap-plot-in-pandas-if-values-have-nan"&gt;some
functions&lt;/a&gt;,
so you have to be careful&amp;nbsp;anyway.&lt;/p&gt;
&lt;p&gt;5. With the data in a proper format, (&lt;a class="reference external" href="www.jstatsoft.org/v59/i10/paper"&gt;tidy
format&lt;/a&gt;, NaNs for invalid values,
all values with proper references), I start doing some exploratory
analysis on the data. For now, basic stuff like line graphs, boxplots,
averages by year and month, autocorrelation and some rolling means, and
scatter&amp;nbsp;plots.&lt;/p&gt;
&lt;p&gt;6. With that things start to get more interesting. I decided to use
&lt;a class="reference external" href="http://scikit-learn.org/stable/"&gt;Scikit-Learn&lt;/a&gt; to do the regressions
instead of statsmodels because of the next step, prediction. You have to
transform the data again so scikit can understand it, but it&amp;#8217;s&lt;a class="reference external" href="http://stackoverflow.com/questions/29748717/use-scikit-learn-to-do-linear-regression-on-a-time-series-pandas-data-frame"&gt;not
that
hard&lt;/a&gt;,
and worth the while. Now I do some stardard Linear Squares to get the
trend and a &lt;span class="caps"&gt;RANSAC&lt;/span&gt; to get more specific&amp;nbsp;results.&lt;/p&gt;
&lt;p&gt;And all this inside a ipython notebook! Pretty awesome, right? Next
steps, do a full
&lt;a class="reference external" href="http://en.wikipedia.org/wiki/Box%E2%80%93Jenkins"&gt;Box-Jenkins&lt;/a&gt; on
the&amp;nbsp;results.&lt;/p&gt;
</content><category term="pandas"></category><category term="Python"></category></entry><entry><title>Development with Python on Linux is turning into Windows</title><link href="http://mfactor.sdf.org/blog/2015_03_15_dev_python_linux_windows.html" rel="alternate"></link><published>2015-03-15T06:05:00-03:00</published><updated>2015-03-15T06:05:00-03:00</updated><author><name>ispmarin</name></author><id>tag:mfactor.sdf.org,2015-03-15:/blog/2015_03_15_dev_python_linux_windows.html</id><summary type="html">&lt;p&gt;Yes, the title is a flamebait, but please bear with&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image0" src="https://dxprience.files.wordpress.com/2014/08/bear-with-me.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;As I said in the last post, I installed Debian on my Chromebook using
&lt;a class="reference external" href="https://github.com/dnschneid/crouton"&gt;crouton&lt;/a&gt;. It worked quite
easily, &lt;span class="caps"&gt;KDE&lt;/span&gt; installed. But then I started building my dev environment,
using Python. But first, a quick&amp;nbsp;digression.&lt;/p&gt;
&lt;p&gt;I have to …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Yes, the title is a flamebait, but please bear with&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;&lt;img alt="image0" src="https://dxprience.files.wordpress.com/2014/08/bear-with-me.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;As I said in the last post, I installed Debian on my Chromebook using
&lt;a class="reference external" href="https://github.com/dnschneid/crouton"&gt;crouton&lt;/a&gt;. It worked quite
easily, &lt;span class="caps"&gt;KDE&lt;/span&gt; installed. But then I started building my dev environment,
using Python. But first, a quick&amp;nbsp;digression.&lt;/p&gt;
&lt;p&gt;I have to use Windows at work now. I know, I know, but there&amp;#8217;s no way
around it. Setting up a dev environment on Windows is very very tricky
and not very funny, especially if you don&amp;#8217;t have admin rights on your
own machine. I managed to get the basics working, but it was not easy.
The loop search internet-&amp;gt;download-&amp;gt;install-&amp;gt;internet was not fun at all
after all these years with&amp;nbsp;apt-get.&lt;/p&gt;
&lt;p&gt;So, when I started setting up my environment on the Debian on the
chromebook it struck me. &lt;em&gt;I&amp;#8217;m doing exactly as I done in Windows.&lt;/em&gt; How
so? First, I installed Python 2.7.9 via apt-get. Nothing funny so far.
Then I decided to use a virtualenv. Ops. To install it I can use the
Debian package or download a newer version directly. Ok, ok&amp;#8230; but then
it comes virtualenvwrapper. Ok, I still can install it using the Debian
repos, but it&amp;#8217;s an old version. After I set up my virtualenv, I start
using pip. Pip is ok, but now I have to download all packages from
different places. I know that this is one of the features of pip, but
nonetheless is divorced from the operating system, there is no search to
speak about inside pip, there is no update all, etc etc. Ok, but there
is still hope, right? Next thing, PyCharm. Bam, gotta go back to the
internet, download it, install&amp;#8230; Windows&amp;nbsp;again!&lt;/p&gt;
&lt;p&gt;You can argue that I chose to use these packages, that there are several
in the Debian repos that can satisfy my needs. That this is just a rant
that &amp;#8220;package A or B is not in the repos!&amp;#8221;, and I tend to agree with
you. But I didn&amp;#8217;t have to do nothing like this when I was developing in
C, C++ or Fortran, including libraries, so I started thinking that maybe
the Python tools integration with Debian or any other Linux distro is
not as good as it could be. What can we do to make it easier? So far I
don&amp;#8217;t know. Any&amp;nbsp;suggestions?&lt;/p&gt;
</content><category term="debian"></category><category term="pip"></category><category term="PyCharm"></category><category term="Python"></category></entry><entry><title>New adventures in Lenovo territory: Ideapad Y500</title><link href="http://mfactor.sdf.org/blog/2013_05_14_lenovo-debian-ideapad-y500.html" rel="alternate"></link><published>2013-05-14T16:31:00-03:00</published><updated>2013-05-14T16:31:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2013-05-14:/blog/2013_05_14_lenovo-debian-ideapad-y500.html</id><summary type="html">&lt;p&gt;After a long struggle of finding a new laptop and deciding to let my
trusted &lt;span class="caps"&gt;XPS&lt;/span&gt; 15 go, finally I got a Lenovo Ideapad Y500, an awesome
configuration for the price. So this is going to be my journal of the
process of getting this machine to&amp;nbsp;work!&lt;/p&gt;
&lt;p&gt;2013-05-14, 12 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;After a long struggle of finding a new laptop and deciding to let my
trusted &lt;span class="caps"&gt;XPS&lt;/span&gt; 15 go, finally I got a Lenovo Ideapad Y500, an awesome
configuration for the price. So this is going to be my journal of the
process of getting this machine to&amp;nbsp;work!&lt;/p&gt;
&lt;p&gt;2013-05-14, 12:35:00 The note arrives. The lenovo people didn&amp;#8217;t put the
number of my apartment on my order, so I had to lurk and wait the &lt;span class="caps"&gt;UPS&lt;/span&gt;
girl on my door. Good thing I have good ears! She was very nice, and
more importantly, she asked for a piece of &lt;span class="caps"&gt;ID&lt;/span&gt; before handling the&amp;nbsp;notebook.&lt;/p&gt;
&lt;p&gt;2013-05-14, 12:40:00 Unpacked! The packaging is very spartan, only the
most basic stuff came. Quite nice, though, no&amp;nbsp;frills.&lt;/p&gt;
&lt;p&gt;2013-05-14, 12:42:00 Turned it on, checked it, did the entire Windows 8
login process. The screen is marvelous, quite impressed with the&amp;nbsp;quality.&lt;/p&gt;
&lt;p&gt;2013-05-14, 12:43:00 And removed all partitions that came with the note,
including the recovery and the other stuff! Gone! Gone now! Bye bye
Windows 8! Hello Windows 7! I had to disable Secure Boot and &lt;span class="caps"&gt;UEFI&lt;/span&gt;, set
the boot mode to legacy and legacy first devices, removed _all_
partitions, and plug a Windows 7 installation from a &lt;span class="caps"&gt;USB&lt;/span&gt; key. The boot
menu button is on the left side, just next to the power plug. Shutdown
the note and press the button. Booted, ran,&amp;nbsp;ok.&lt;/p&gt;
&lt;p&gt;2013-05-14, 12:48:00 Finished the installation, here it comes the first
boot. Decided to use &lt;span class="caps"&gt;250GB&lt;/span&gt; for windows, gonna use around 60 for Debian,
and the rest is going to be /home. The only reason why the windows
partition is that big is because of the games. C&amp;#8217;mon, it has a friggin
Nvidia 750M on&amp;nbsp;it!&lt;/p&gt;
&lt;p&gt;2013-05-14, 13:00:00 The Windows 7 installation finished, but of course
there are no drivers. I&amp;#8217;m downloading the drivers from the lenovo
website to an external drive to be able to install&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;2013-05-14, 13:25:00 After installing all drivers, one by one, I
realized that Nvidia stable driver can&amp;#8217;t handle the &lt;span class="caps"&gt;GT&lt;/span&gt; 750M, so I had to
go back to the lenovo site to get the driver from them, and realize that
is just the beta driver from Nvidia&amp;#8230; Rebooted (3 times now), and &lt;span class="caps"&gt;OMFG&lt;/span&gt;
the screen is nice. Fuck, it is nice. Still tons of stuff to install in
Windows, but now is time to install Debian! Copied the netinst image
(using dd, dd if=&amp;lt;image&amp;gt; of=/dev/sdc bs=4m; sync) from debian netinst,
clicked the button on the side, plugged, and it booted. Installing&amp;nbsp;now!&lt;/p&gt;
&lt;p&gt;2013-05-14, 13:33:00 Hit my first snag with Debian. It asked the
firmware for the wireless card, so I had to go to
&lt;a class="reference external" href="http://wireless.kernel.org/en/users/Drivers/iwlwifi/?n=downloads#Firmware"&gt;here&lt;/a&gt;
and copied to the external drive. It didn&amp;#8217;t find the firmware, even if
it was in the folder. Had to copy the .tgz to make it work, not only the
ucode. Trying to read it&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;2013-05-14, 13:43:00 It didn&amp;#8217;t work, so I had to proceed with the
installation without the firmware for the wifi. Gonna have to copy the
.deb later. And now this is tempting: The debian installer is allowing
me to install it on the internal &lt;span class="caps"&gt;SSD&lt;/span&gt;! But when I tried, it failed. It
also failed to see the &lt;span class="caps"&gt;GPT&lt;/span&gt; Windows partitions, so I had to hit the webs
to find how to do it. Had to go to the &amp;#8220;expert install&amp;#8221;. The expert
install also allowed me to choose the &lt;span class="caps"&gt;NTFS&lt;/span&gt; partition handler, so maybe
that was the problem with the external harddrive. I&amp;#8217;m already
downloading an Ubuntu 13.04&amp;nbsp;image&amp;#8230;&lt;/p&gt;
&lt;p&gt;2013-05-14, 14:05:00 And Debian refuses to see the &lt;span class="caps"&gt;GPT&lt;/span&gt; partition table.
Gonna have to reset everything, reinstall windows with a &lt;span class="caps"&gt;MBR&lt;/span&gt; partition,
and then reinstall the rest.&amp;nbsp;Damn.&lt;/p&gt;
&lt;p&gt;2013-05-14, 14:47:00 Had lunch - not really important, but good to know
that I didn&amp;#8217;t take that amout of time :-) So now reinstalling windows.
This time I&amp;#8217;ll try to install Debian before installing everything in&amp;nbsp;windows.&lt;/p&gt;
&lt;p&gt;2013-05-14, 15:08:00 Finally! Debian found all partitions and now is
hapilly installing. No luck with the wifi, though, gonna have to do it
after installing the&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;2013-05-14, 15:26:00 After finishing the Debian installation &lt;span class="caps"&gt;GRUB&lt;/span&gt; only
booted windows. I said a big no to Debian and went Ubuntu. Not because I
can&amp;#8217;t install Debian, but because I don&amp;#8217;t have the time. Ubuntu booted
and already connected to my wireless network. And it failed to write to
the hard disk. Linux on this machine is getting more and more
frustrating to install. Downloading a new Ubuntu image and checking the
&lt;span class="caps"&gt;MD5&lt;/span&gt;, just to be&amp;nbsp;sure.&lt;/p&gt;
&lt;p&gt;2013-05-14, 16:10:00 Image checksummed, copied and booted. Ubuntu
installation is almost finished, still&amp;nbsp;running.&lt;/p&gt;
&lt;p&gt;2013-05-14, 16:30:00 Ubuntu installation finished! There is now a
problem with the Windows install. The Windows install put it on the &lt;span class="caps"&gt;SSD&lt;/span&gt;,
and I only got grub working after removing the Windows partition from
the &lt;span class="caps"&gt;SSD&lt;/span&gt;. Ubuntu boots, but windows dont&amp;#8230; So here we go again get a
Windows live usb to boot and fix the mbr _one more time_. If I knew
that before I could have kept Debian. But, alas&amp;#8230; Installing &lt;span class="caps"&gt;KDE&lt;/span&gt;&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;2013-05-14, 18:00:00 &lt;span class="caps"&gt;KDE&lt;/span&gt; installed, Ubuntu system ready to rock. But for
some reason the Windows partittion, although is intact, can&amp;#8217;t be found
to boot, and can&amp;#8217;t boot windows from the &lt;span class="caps"&gt;USB&lt;/span&gt; key. Finishing burning an
old fashioned &lt;span class="caps"&gt;DVD&lt;/span&gt; with the Windows 7 image and will try to recover. If
it works, great; if it doesn&amp;#8217;t, so sorry, gonna move to the new computer
and Windows will be installed&amp;nbsp;later.&lt;/p&gt;
&lt;p&gt;2013-05-14, 18:09:00 Windows booted from the &lt;span class="caps"&gt;DVD&lt;/span&gt;, gonna try to fix it
from the recovery menu. Ran &amp;nbsp;the automatic repair, and it fixed the
windows&amp;nbsp;installation.&lt;/p&gt;
&lt;p&gt;2013-05-14, 18:30:00 Booted on Ubuntu again, after Windows was running,
did the usual installations steps for repairing grub, e voilá! Both
systems are ok! But it should be noted that I had to do a grub-install
/dev/sda, the mSATA, &lt;span class="caps"&gt;NOT&lt;/span&gt; the sda disk. What a&amp;nbsp;mess!&lt;/p&gt;
&lt;p&gt;Now is copying all files to the new note&amp;nbsp;:-)&lt;/p&gt;
</content><category term="debian"></category><category term="ideapad"></category><category term="ideapad y500"></category><category term="lenovo"></category><category term="linux"></category><category term="ubuntu"></category><category term="windows"></category><category term="windows 7"></category><category term="windows 8"></category></entry><entry><title>TODO and documentation in markdown and pandoc</title><link href="http://mfactor.sdf.org/blog/2013_02_28_todo-and-documentation-in-markdown-and-pandoc.html" rel="alternate"></link><published>2013-02-28T11:27:00-03:00</published><updated>2013-02-28T11:27:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2013-02-28:/blog/2013_02_28_todo-and-documentation-in-markdown-and-pandoc.html</id><summary type="html">&lt;p&gt;Hi&amp;nbsp;all,&lt;/p&gt;
&lt;p&gt;Writing a &lt;span class="caps"&gt;TODO&lt;/span&gt; and some documentation for a code under development can
be a bit jarring at the beginning, especially when there&amp;#8217;s more than one
developer working on the same code. Things get even more interesting
when the other developer is not using any kind of &lt;span class="caps"&gt;VCS …&lt;/span&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hi&amp;nbsp;all,&lt;/p&gt;
&lt;p&gt;Writing a &lt;span class="caps"&gt;TODO&lt;/span&gt; and some documentation for a code under development can
be a bit jarring at the beginning, especially when there&amp;#8217;s more than one
developer working on the same code. Things get even more interesting
when the other developer is not using any kind of &lt;span class="caps"&gt;VCS&lt;/span&gt; and we have to use
the good old fashioned code-by-email-what-changed-by-phone. After
working with git for a while, doing that can feel a little bit&amp;#8230;
retrograde, but these are the conditions, and sometimes is best if we
don&amp;#8217;t change&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;So I thought for a long time how to keep track of the changes in this
scenario. Another detail: the code in question is not open source, so I
wouldn&amp;#8217;t be able to rely on github or other tools. So I decided to
use&lt;a class="reference external" href="http://daringfireball.net/projects/markdown/syntax"&gt;markdown&lt;/a&gt;
to write the changes and
&lt;a class="reference external" href="http://johnmacfarlane.net/pandoc/demos.html"&gt;pandoc&lt;/a&gt; to generate a
&lt;span class="caps"&gt;PDF&lt;/span&gt; out of it. markdown syntax is quite simple, and pandoc can generate
very good PDFs out of them, so now is more important to concentrate on
writing the &lt;span class="caps"&gt;TODO&lt;/span&gt; than refining the&amp;nbsp;tools.&lt;/p&gt;
&lt;p&gt;The conversion from markdown to &lt;span class="caps"&gt;PDF&lt;/span&gt; is a breeze with&amp;nbsp;pandoc:&lt;/p&gt;
&lt;blockquote&gt;
pandoc &lt;span class="caps"&gt;README&lt;/span&gt; -o readme.pdf&lt;/blockquote&gt;
&lt;p&gt;Done! What if we have some code in it, and want to highlight it? No
problem. Add a block code delimiter in&amp;nbsp;markdown:&lt;/p&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&amp;#8220;` {.fortran .numberLines}&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;call madfunction(i-1, 1, 1.0/dt, c)&lt;/div&gt;
&lt;div class="line"&gt;write(6,*) &amp;#8220;Running madfunction&amp;#8221;&lt;/div&gt;
&lt;div class="line"&gt;&amp;#8220;`&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;And convert it with&amp;nbsp;pandoc:&lt;/p&gt;
&lt;blockquote&gt;
pandoc &lt;span class="caps"&gt;TODO&lt;/span&gt;.md &amp;nbsp;&amp;#8212;highlight-style pygments -o &lt;span class="caps"&gt;TODO&lt;/span&gt;.pdf&lt;/blockquote&gt;
&lt;p&gt;And voilá! Code with syntax highlight in the &lt;span class="caps"&gt;PDF&lt;/span&gt;. Very, very, very
helpful. You can also change the syntax colors changing the option
&amp;lt;pygments&amp;gt; and use several different ones, as kate, zenburn, expresso,&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;Keeping the doc in markdown will also help when the code, or at least
parts of it, are uploaded to github or any other tracker. In the future,
if the documentation of the code itself is done in doxygen, for example,
the markdown can be included in the doxygen generation file.&amp;nbsp;Neat.&lt;/p&gt;
</content><category term="code"></category><category term="conversion pdf"></category><category term="doxygen"></category><category term="markdown"></category><category term="pandoc"></category><category term="syntax highlight"></category><category term="todo"></category></entry><entry><title>Using Virtual Machines and Ubuntu to Keep a Sane Development Environment</title><link href="http://mfactor.sdf.org/blog/2012_12_11_vm_ubuntu.html" rel="alternate"></link><published>2012-12-11T15:06:00-02:00</published><updated>2012-12-11T15:06:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2012-12-11:/blog/2012_12_11_vm_ubuntu.html</id><summary type="html">&lt;p&gt;I tried. I swear I tried. But it&amp;#8217;s plain and simple painful to develop
in Fortran in Windows. There, I said it. Is it &lt;em&gt;possible&lt;/em&gt;? Yes. Is it
easy? Not a chance in&amp;nbsp;Hell.&lt;/p&gt;
&lt;p&gt;First of all, there aren&amp;#8217;t a lot of options for Fortran Compilers for
the …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I tried. I swear I tried. But it&amp;#8217;s plain and simple painful to develop
in Fortran in Windows. There, I said it. Is it &lt;em&gt;possible&lt;/em&gt;? Yes. Is it
easy? Not a chance in&amp;nbsp;Hell.&lt;/p&gt;
&lt;p&gt;First of all, there aren&amp;#8217;t a lot of options for Fortran Compilers for
the Microsoft Windows Platform (and I&amp;#8217;m talking about Windows 7, I would
imagine that Windows 8 would be worse.). The most sane one, Intel
Fortran, is even now Intel Visual Fortran Compiler for Windows (&lt;a class="reference external" href="http://software.intel.com/en-us/forums/intel-visual-fortran-compiler-for-windows"&gt;I kid
you
not&lt;/a&gt;.).
And then there&amp;#8217;s the interfaces. Microsoft provides for free the
&lt;a class="reference external" href="http://www.microsoft.com/visualstudio/eng/products/visual-studio-express-products"&gt;Express&lt;/a&gt;
suit, so things are not that bad, right? No. The Express suit can&amp;#8217;t use
Intel Visual Fortran Compiler for Windows support, so you&amp;#8217;re out of luck
unless you buy the full Visual Studio Suite, and which one I dunno -
never understood the Ultimate/Professional/Premium/Alien/KitchenCleaning
version confusion. Eclipse &lt;span class="caps"&gt;CDT&lt;/span&gt;/Photran would be a good one instead,
right? No. Intel Visual Fortran Compiler for Windows also doesn&amp;#8217;t
support Eclipse &lt;span class="caps"&gt;CDT&lt;/span&gt;/Photran. Where to&amp;nbsp;run?&lt;/p&gt;
&lt;p&gt;Maybe MinGW could help us? Yes, maybe. Both Intel Visual Fortran
Compiler for Windows and MinGW can compile a Fortran source file from
the command line, but we&amp;#8217;re in friggin Windows, right? Also, for large
projects, code completion and syntax errors are a must. I didn&amp;#8217;t try the
&lt;span class="caps"&gt;LLVM&lt;/span&gt;/dragonegg and mingw-fortran combination, but as I wouldn&amp;#8217;t get the
advantages that I&amp;#8217;m looking for, I decided that if I have to use a
Windows machine, no one would prevent to use a sane, decent Linux
environment &lt;em&gt;inside&lt;/em&gt; that Windows machine. Ubuntu plus VirtualBox it&amp;nbsp;is!&lt;/p&gt;
&lt;p&gt;Downloaded 12.10-amd64, installed in a &lt;span class="caps"&gt;VDI&lt;/span&gt; image, all with standard
options. Of course Ubuntu would give me some headaches: had to uninstall
that creepy shopping lens, install Google Chrome. Google Chrome
installation was interesting: the Software Center gave me an &amp;#8220;This
package is of low quality. Don&amp;#8217;t install it.&amp;#8221; Just hit ignore and
install it anyway. And Ubuntu froze. Unity recomposed itself, but I
figured that there is something funky going on between X and VirtualBox,
so I went back to VirtualBox settings and disabled the 3D video, what
made things a bit better - but still no changing resolution with
changing the size of the &lt;span class="caps"&gt;VM&lt;/span&gt; window. Strange. Will probably install &lt;span class="caps"&gt;KDE&lt;/span&gt;
anyway&amp;#8230; so I plugged my external drive to copy all the files to the
&lt;span class="caps"&gt;VM&lt;/span&gt;. And then, Compiz hanged again. Definitely annoying. So while I
waited to see what the 12.10 would do (keep freezed, it seems), decided
to use my &lt;span class="caps"&gt;12GB&lt;/span&gt; of &lt;span class="caps"&gt;RAM&lt;/span&gt; and my Core i7 and hit an 12.04 installation. It
started to be a little ironic that I was running away from one platform
that is impossible to program to another one that refuses to work to
begin with. I decided to keep going, nonetheless, and see where I would&amp;nbsp;get.&lt;/p&gt;
&lt;p&gt;I still kept my hopes that things would be easier after I got an Ubuntu
running. My plan was to use the &lt;span class="caps"&gt;VM&lt;/span&gt; as a full development environment
that I could transport easily to different computers. I thought about
keeping a git repository of the important stuff, but the multiplatform
problems that I detailed above with Fortran made this a no-go. 12.04 was
much better than 12.10, and while 12.10 was still frozen, I managed to
install 12.04, update it, install the required dkms modules for
VirtualBox. Also downloaded Eclipse &lt;span class="caps"&gt;CDT&lt;/span&gt;, &lt;a class="reference external" href="http://eclipsecolorthemes.org/"&gt;Eclipse Colour
Plugin&lt;/a&gt;,
&lt;a class="reference external" href="http://pydev.org/"&gt;Pydev&lt;/a&gt; and
&lt;a class="reference external" href="http://www.eclipse.org/photran/"&gt;Photran&lt;/a&gt;,
&lt;a class="reference external" href="http://openjdk.java.net/"&gt;OpenJDK&lt;/a&gt;, everything running ok! Copied
from my external drive all the source files, all beautiful. Decided not
to use 12.10 and stick with 12.04. So now, the next step: moving the &lt;span class="caps"&gt;VM&lt;/span&gt;
to the external&amp;nbsp;drive.&lt;/p&gt;
&lt;p&gt;After copying the entire &lt;span class="caps"&gt;VB&lt;/span&gt; folder to the external drive, I would have
to test it and see if there&amp;#8217;s anything missing. And it works! Now doing
some backups on external hard drives and transporting happily my virtual
machines around. It&amp;#8217;s cumbersome to transport &lt;span class="caps"&gt;20GB&lt;/span&gt; up and down an
external drive every time, but it&amp;#8217;s better than use Windows to program,
that&amp;#8217;s for&amp;nbsp;sure!&lt;/p&gt;
&lt;p&gt;One last trick: to share a folder between the Ubuntu guest and Windows
host and be able to create soft symlinks, I had to issue this command in
the Windows&amp;nbsp;host:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
VBoxManage setextradata VM_NAME VBoxInternal2/SharedFoldersEnableSymlinksCreate/SHARE_NAME 1


Where VM_NAME is your virtual machine name. Done!
&lt;/pre&gt;
</content><category term="fortran"></category><category term="symlink"></category><category term="ubuntu"></category><category term="virtualbox"></category><category term="windows"></category></entry><entry><title>And who said it… back to Eclipse</title><link href="http://mfactor.sdf.org/blog/2012_10_22_fortran_eclipse.html" rel="alternate"></link><published>2012-10-22T20:29:00-02:00</published><updated>2012-10-22T20:29:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2012-10-22:/blog/2012_10_22_fortran_eclipse.html</id><summary type="html">&lt;p&gt;Hey&amp;nbsp;all,&lt;/p&gt;
&lt;p&gt;I should have warned everyone: sometimes what seems to be the best is
not, and old habits die hard. Or, in a more direct way, after all the
fuss with Vim, I&amp;#8217;m back to Eclipse. I know, I&amp;nbsp;know&amp;#8230;&lt;/p&gt;
&lt;p&gt;Vim is great. Really, vim is great. But …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Hey&amp;nbsp;all,&lt;/p&gt;
&lt;p&gt;I should have warned everyone: sometimes what seems to be the best is
not, and old habits die hard. Or, in a more direct way, after all the
fuss with Vim, I&amp;#8217;m back to Eclipse. I know, I&amp;nbsp;know&amp;#8230;&lt;/p&gt;
&lt;p&gt;Vim is great. Really, vim is great. But it&amp;#8217;s just not what I need right
now. I programmed in vim in python and &lt;span class="caps"&gt;FORTRAN&lt;/span&gt;. I wrote makefiles again.
I even made a rep with vim rc scripts in github. But no dice. I&amp;#8217;m a very
visual guy, and not being able to see what I was doing, where I was
going, was a dealbreaker. It seems that if I don&amp;#8217;t have a clear picture
in my head on what&amp;#8217;s going on, as I have with Linux systems in general
and as I don&amp;#8217;t have when I&amp;#8217;m writing new code, not being able to see
what files are part of the project, autocompletion out of the box, so on
and so forth, is not good. After I got all in my head, vim is very
productive, as I don&amp;#8217;t have to reach for the mouse and I code all from
memory. But to prototype, to create new code, Eclipse so far is
superior. I know it sounds counterintuitive, but autocompletion is one
of the several examples. Just being able to press &lt;span class="caps"&gt;CTRL&lt;/span&gt; + Space and the
function definition is filled saves me a lot of time in two ways: first,
I don&amp;#8217;t have to go to that piece of code to see what the interface is,
and second, as I keep my variable names consistent, sometimes just
putting the definition of the function is enough, not having to type
anything&amp;nbsp;else.&lt;/p&gt;
&lt;p&gt;Vanilla Eclipse Juno &lt;span class="caps"&gt;CDT&lt;/span&gt;, Pydev, Photran, and Eclipse Colours, and
that&amp;#8217;s it. Juno now supports git out of the box too. Other trick that is
saving me a lot of headaches is to keep several workspaces, one for each
kind of project. Right now I have pywork for Python code and lavalwork
for some code from&amp;nbsp;Laval.&lt;/p&gt;
&lt;p&gt;So here it is. I&amp;#8217;m back, Eclipse! Just don&amp;#8217;t throw me under the bus with
those ugly java exceptions&amp;#8230;&amp;nbsp;:-)&lt;/p&gt;
</content><category term="eclipse"></category><category term="eclipse cdt"></category><category term="programming"></category><category term="vim"></category></entry><entry><title>Fiddling with Makefiles, for the last time</title><link href="http://mfactor.sdf.org/blog/2012_09_18_makefiles.html" rel="alternate"></link><published>2012-09-18T16:11:00-03:00</published><updated>2012-09-18T16:11:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2012-09-18:/blog/2012_09_18_makefiles.html</id><summary type="html">&lt;p&gt;I was struggling with writing another makefile in my life, but it seems
that if you want to automate some tasks in vim, you have to write one.
I&amp;#8217;ll also use several compilers to check interoperability of the new
code that I&amp;#8217;ll be working, so creating a makefile …&lt;/p&gt;</summary><content type="html">&lt;p&gt;I was struggling with writing another makefile in my life, but it seems
that if you want to automate some tasks in vim, you have to write one.
I&amp;#8217;ll also use several compilers to check interoperability of the new
code that I&amp;#8217;ll be working, so creating a makefile, even if just for one
file, is worthwhile. But of course I never properly learned how to write
one by myself, so here is my post. First, automatic variables, directly
from the
&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Automatic-Variables"&gt;manual&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;$&amp;#64;&lt;/tt&gt;The file name of the target of the rule. If the target is an
archive member, then ‘$&amp;#64;’ is the name of the archive file. In a pattern
rule that has multiple targets (see&amp;nbsp;&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Pattern-Intro"&gt;Introduction to Pattern
Rules&lt;/a&gt;),
‘$&amp;#64;’ is the name of whichever target caused the rule&amp;#8217;s recipe to be&amp;nbsp;run.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;$%&lt;/tt&gt;The target member name, when the target is an archive member.
See&amp;nbsp;&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Archives"&gt;Archives&lt;/a&gt;.
For example, if the target is&amp;nbsp;foo.a(bar.o)&amp;nbsp;then ‘$%’ is&amp;nbsp;bar.o&amp;nbsp;and ‘$&amp;#64;’
is&amp;nbsp;foo.a. ‘$%’ is empty when the target is not an archive&amp;nbsp;member.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;$&amp;lt;&lt;/tt&gt;The name of the first prerequisite. If the target got its recipe
from an implicit rule, this will be the first prerequisite added by the
implicit rule (see&amp;nbsp;&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Implicit-Rules"&gt;Implicit
Rules&lt;/a&gt;).&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;tt class="docutils literal"&gt;$?&lt;/tt&gt;The names of all the prerequisites that are newer than the
target, with spaces between them. For prerequisites which are archive
members, only the named member is used
(see&amp;nbsp;&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Archives"&gt;Archives&lt;/a&gt;).&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;tt class="docutils literal"&gt;$^&lt;/tt&gt;The names of all the prerequisites, with spaces between them.
For prerequisites which are archive members, only the named member is
used
(see&amp;nbsp;&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Archives"&gt;Archives&lt;/a&gt;).
A target has only one prerequisite on each other file it depends on,
no matter how many times each file is listed as a prerequisite. So if
you list a prerequisite more than once for a target, the value
of&amp;nbsp;&lt;tt class="docutils literal"&gt;$^&lt;/tt&gt;&amp;nbsp;contains just one copy of the name. This list
does&amp;nbsp;&lt;strong&gt;not&lt;/strong&gt;&amp;nbsp;contain any of the order-only prerequisites; for those
see the ‘$|’ variable, below.&lt;/div&gt;
&lt;div class="line"&gt;&lt;tt class="docutils literal"&gt;$+&lt;/tt&gt;This is like ‘$^’, but prerequisites listed more than once
are duplicated in the order they were listed in the makefile. This is
primarily useful for use in linking commands where it is meaningful to
repeat library file names in a particular order.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;$|&lt;/tt&gt;The names of all the order-only prerequisites, with spaces
between&amp;nbsp;them.&lt;/p&gt;
&lt;p&gt;&lt;tt class="docutils literal"&gt;$*&lt;/tt&gt;The stem with which an implicit rule matches (see&amp;nbsp;&lt;a class="reference external" href="http://www.gnu.org/software/make/manual/make.html#Pattern-Match"&gt;How Patterns
Match&lt;/a&gt;).
If the target is&amp;nbsp;dir/a.foo.b&amp;nbsp;and the target pattern is&amp;nbsp;a.%.b&amp;nbsp;then the
stem is&amp;nbsp;dir/foo. The stem is useful for constructing names of related
files.&amp;nbsp;In a static pattern rule, the stem is part of the file name that
matched the ‘%’ in the target&amp;nbsp;pattern.&lt;/p&gt;
&lt;p&gt;So the most used ones in the makefiles that I&amp;#8217;ve seen are $&amp;#64;, $&amp;gt; and $^.
So, $&amp;#64; means the name of the compilation rule, $^ means the source
files. For&amp;nbsp;example,&lt;/p&gt;
&lt;pre class="literal-block"&gt;
FC = gfortran
FCFLAGS = -g -fbounds-check
FCFLAGS = -O2
IFC = ifort
IFCFLAGS = -g
#FCFLAGS += -I/usr/include
#LDFLAGS =
SRC = bio-f.f
bio-gfortran: $(SRC)
 $(FC) $(FCFLAGS) -o $&amp;#64; $^ $(LDFLAGS)
bio-ifort: $(SRC)
 $(IFC) $(IFCFLAGS) -o $&amp;#64; $^ $(IFCFLAGS)
gf: bio-gfortran
ifort: bio-ifort
# Utility targets
.PHONY: clean veryclean
clean:
 rm -f *.o *.mod *.MOD
&lt;/pre&gt;
&lt;p&gt;What I&amp;#8217;m doing basically is to tell to compile in this fashion: for the
rule bionapl-gfortran, $&amp;#64; means this name and $^ means the source files.
So this&amp;nbsp;line,&lt;/p&gt;
&lt;p&gt;$(&lt;span class="caps"&gt;FC&lt;/span&gt;) $(&lt;span class="caps"&gt;FCFLAGS&lt;/span&gt;) -o $&amp;#64; $^ $(&lt;span class="caps"&gt;LDFLAGS&lt;/span&gt;)&lt;/p&gt;
&lt;p&gt;is use the compiler defined by &lt;span class="caps"&gt;FC&lt;/span&gt; with the compiler flags &lt;span class="caps"&gt;FCFLAGS&lt;/span&gt; using
the output name (-o $&amp;#64;) bio-gfortran and the source file ($^) that &lt;span class="caps"&gt;SRC&lt;/span&gt;
tells you to use. The line below is the same&amp;nbsp;thing.&lt;/p&gt;
&lt;p&gt;Note the line gf: bio-gfortran and the one below. This is just a
convenient renaming: instead of&amp;nbsp;calling&lt;/p&gt;
&lt;p&gt;make&amp;nbsp;bio-gfortran&lt;/p&gt;
&lt;p&gt;I can call and&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;make&amp;nbsp;gf&lt;/p&gt;
&lt;p&gt;The meaning for the $&amp;#64; and $^ can be a little more complicated with
build dependencies, but this is enough for now. I&amp;#8217;m sure the programmers
on standby will provide better options and how to save changing the name
for each compilation, etc. Feel free to&amp;nbsp;contribute!&lt;/p&gt;
</content><category term="compilation"></category><category term="computational physics"></category><category term="science"></category></entry><entry><title>Installing PostGis 1.5.5 on Debian Squeeze</title><link href="http://mfactor.sdf.org/blog/2012_08_10_installing-postgis-debian-squeeze.html" rel="alternate"></link><published>2012-08-10T13:17:00-03:00</published><updated>2012-08-10T13:17:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2012-08-10:/blog/2012_08_10_installing-postgis-debian-squeeze.html</id><summary type="html">&lt;p&gt;On the ongoing projects here at my
&lt;a class="reference external" href="http://albatroz.shs.eesc.usp.br"&gt;lab&lt;/a&gt;, a new student here at my lab
needed to perform again the installation for PostgreSQL 9.1 and PostGIS,
to spacially enable the database. But, for now, there is no PostGIS
package for Debian Squeeze! Despair, oh my! The usual solutions, like …&lt;/p&gt;</summary><content type="html">&lt;p&gt;On the ongoing projects here at my
&lt;a class="reference external" href="http://albatroz.shs.eesc.usp.br"&gt;lab&lt;/a&gt;, a new student here at my lab
needed to perform again the installation for PostgreSQL 9.1 and PostGIS,
to spacially enable the database. But, for now, there is no PostGIS
package for Debian Squeeze! Despair, oh my! The usual solutions, like
pulling from Wheezy (the present Testing) also didn&amp;#8217;t work, as for some
reason the package that we want, postgresql-9.1-postgis, tries to pull
an infinitude of packages from wheezy (even gtk packages!), so we need
to go the old school fashion: ./configure. What are the dependencies?
Here we&amp;nbsp;go:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;libgeos-dev&lt;/p&gt;
&lt;p&gt;grass&lt;/p&gt;
&lt;p&gt;libproj-dev&lt;/p&gt;
&lt;p&gt;libgdal-grass&lt;/p&gt;
&lt;p&gt;python-pyproj&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So a standard apt-get install should suffice - and of course,
considering that both posgresql-9.1 and posgresql-server-9.1-dev are&amp;nbsp;installed:&lt;/p&gt;
&lt;blockquote&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;a class="reference external" href="mailto:root&amp;#64;rohan"&gt;root&amp;#64;rohan&lt;/a&gt;:~/postgis-1.5.5# dpkg -l | grep postgre&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;ii postgresql-9.1 9.1.4-2~bpo60+1 object-relational &lt;span class="caps"&gt;SQL&lt;/span&gt; database,
version 9.1 server&lt;/div&gt;
&lt;div class="line"&gt;ii postgresql-client-9.1 9.1.4-2~bpo60+1 front-end programs for
PostgreSQL 9.1&lt;/div&gt;
&lt;div class="line"&gt;ii postgresql-client-common 130~bpo60+2 manager for multiple
PostgreSQL client versions&lt;/div&gt;
&lt;div class="line"&gt;ii postgresql-common 130~bpo60+2 PostgreSQL database-cluster
manager&lt;/div&gt;
&lt;div class="line"&gt;ii postgresql-contrib-9.1 9.1.4-2~bpo60+1 additional facilities
for PostgreSQL&lt;/div&gt;
&lt;div class="line"&gt;ii postgresql-plpython-9.1 9.1.4-2~bpo60+1 &lt;span class="caps"&gt;PL&lt;/span&gt;/Python procedural
language for PostgreSQL 9.1&lt;/div&gt;
&lt;div class="line"&gt;ii postgresql-server-dev-9.1 9.1.4-2~bpo60+1 development files
for PostgreSQL 9.1 server-side programming&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;p&gt;Done! The rest is a simple ./configure, make, make install.&amp;nbsp;Voilà!&lt;/p&gt;
&lt;p&gt;So, if you&amp;#8217;re starting from scratch, let&amp;#8217;s recapitulate: first enable
&lt;a class="reference external" href="http://backports-master.debian.org/Instructions/"&gt;Debian Backports&lt;/a&gt;,
them install the needed&amp;nbsp;packages:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;apt-get install -t squeeze-backports&amp;nbsp;posgresql-9.1&amp;nbsp;postgresql-client-9.1&amp;nbsp;postgresql-client-common&amp;nbsp;postgresql-common&amp;nbsp;postgresql-contrib-9.1&amp;nbsp;postgresql-plpython-9.1&amp;nbsp;postgresql-server-dev-9.1&lt;/p&gt;
&lt;p&gt;apt-get install libgeos-dev&amp;nbsp;grass libproj-dev&amp;nbsp;libgdal-grass&amp;nbsp;python-pyproj&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;And finally download PostGIS from
&lt;a class="reference external" href="http://postgis.refractions.net/documentation/manual-1.5/ch02.html#id2608330"&gt;here&lt;/a&gt;,
unpack it, and&amp;nbsp;run&lt;/p&gt;
&lt;blockquote&gt;
./configure; make; make install&lt;/blockquote&gt;
&lt;p&gt;That should do the&amp;nbsp;trick!&lt;/p&gt;
</content><category term="client versions"></category><category term="cluster manager"></category><category term="database cluster"></category><category term="debian"></category><category term="debian backports"></category><category term="debian gis"></category><category term="gis"></category><category term="howto"></category><category term="postgis"></category><category term="postgre"></category><category term="postgresql"></category><category term="postgresql server"></category></entry><entry><title>From scratch and testing ideas: DebianGIS with Postgresql, Drupal and OpenLayers</title><link href="http://mfactor.sdf.org/blog/2011_11_27_debiangis-with-postgresql-drupal-and-openlayers.html" rel="alternate"></link><published>2011-11-27T12:49:00-02:00</published><updated>2011-11-27T12:49:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2011-11-27:/blog/2011_11_27_debiangis-with-postgresql-drupal-and-openlayers.html</id><summary type="html">&lt;p&gt;Here we go again to try to build a server for &lt;span class="caps"&gt;GIS&lt;/span&gt; using&amp;nbsp;Debian.&lt;/p&gt;
&lt;p&gt;Downloaded the image&amp;nbsp;from&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://cdimage.debian.org/debian-cd/6.0.3/amd64/iso-cd/debian-6.0.3-amd64-netinst.iso"&gt;http://cdimage.debian.org/debian-cd/6.0.3/amd64/iso-cd/debian-6.0.3-amd64-netinst.iso&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the basic install (I&amp;#8217;ll be doing the install in a &lt;span class="caps"&gt;VM&lt;/span&gt;). Language:
Portuguese Brazilian. All other …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Here we go again to try to build a server for &lt;span class="caps"&gt;GIS&lt;/span&gt; using&amp;nbsp;Debian.&lt;/p&gt;
&lt;p&gt;Downloaded the image&amp;nbsp;from&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://cdimage.debian.org/debian-cd/6.0.3/amd64/iso-cd/debian-6.0.3-amd64-netinst.iso"&gt;http://cdimage.debian.org/debian-cd/6.0.3/amd64/iso-cd/debian-6.0.3-amd64-netinst.iso&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the basic install (I&amp;#8217;ll be doing the install in a &lt;span class="caps"&gt;VM&lt;/span&gt;). Language:
Portuguese Brazilian. All other options were kept as the defaults,
choosing single filesystem and all mount points on the same partition.
Other change: ext4 instead of ext3, and removed the option of the
Desktop. The installation was over under 15&amp;nbsp;min.&lt;/p&gt;
&lt;p&gt;Now, configuring the backport repositories: From
&lt;a class="reference external" href="http://backports-master.debian.org/Instructions/"&gt;here&lt;/a&gt;[debian
backports], add this line to the&amp;nbsp;/etc/apt/sources.list:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
deb http://backports.debian.org/debian-backports squeeze-backports main
&lt;/pre&gt;
&lt;p&gt;Do an apt-get update, and install the necessary packages. First, from
main&amp;nbsp;reps:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
apt-get --no-install-recommends install vim make build-essential gcc g++ gfortran ssh
&lt;/pre&gt;
&lt;p&gt;Done. Time to start installing the web&amp;nbsp;packages:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
apt-get --no-install-recommends -t squeeze-backports install apache2 postgresql-9.1 postgis php5-pgsql php5 php5-cgi php5-gd vsftpd
&lt;/pre&gt;
&lt;p&gt;That&amp;#8217;s why I _love_ Debian. Let&amp;#8217;s proceed: now it&amp;#8217;s time to configure
the basic database for the next step, installing drupal. Following this
&lt;a class="reference external" href="http://drupal.org/node/284991"&gt;drupal&amp;nbsp;documentation,&amp;nbsp;&lt;/a&gt;&lt;/p&gt;
&lt;pre class="literal-block"&gt;
su - postgres
createuser --pwprompt --encrypted --no-adduser --no-createdb drupal
createdb --encoding=UNICODE --owner=drupal drupaldb
&lt;/pre&gt;
&lt;p&gt;Done! User and database for drupal created. Now it&amp;#8217;s time to dowload
drupal itself. I chose to download drupal 7 from the website than from
the debian repositories because of some debian particularities, like
versioning. I downloaded the latest version from
&lt;a class="reference external" href="http://drupal.org/project/drupal"&gt;here&lt;/a&gt;[drupal.org]:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
wget http://ftp.drupal.org/files/projects/drupal-7.9.tar.gz
&lt;/pre&gt;
&lt;p&gt;And downloaded to /var/www. As I&amp;#8217;m planning this server to be run
exclusively as a &lt;span class="caps"&gt;GIS&lt;/span&gt; server, I extracted all drupal files to /var/www,
and _not_ inside the directory drupal-7.9. After redirecting the ports
from Virtualbox, we&amp;#8217;re ready to start the drupal installation. First,
changing the permission for the files to 775, user and group to
www-data, and following &lt;a class="reference external" href="http://drupal.org/documentation/install/developers"&gt;drupal installation
instructions&lt;/a&gt;[drupal.org]:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
cp sites/default/default.settings.php sites/default/settings.php
&lt;/pre&gt;
&lt;p&gt;Just remember that if there is an error with php, you have to restart
apache and close your browser: google chrome kept insisting in
downloading install.php instead of running it, even if phpinfo() was
running ok. So let&amp;#8217;s continue: Standard installation, English, and use
the database name (drupaldb) and user (drupal) with the password that
was configured before, and drupal should install. The ftp server that
drupal uses for update (we installed the vsftpd) should be also
configured: in the file /etc/vsftpd.conf, the local users option must be&amp;nbsp;enabled:&lt;/p&gt;
&lt;pre class="literal-block"&gt;
Uncomment this to allow local users to log in.
local_enable = YES
&lt;/pre&gt;
&lt;p&gt;Drupal should be running! Time to install new modules, the ones that
&lt;a class="reference external" href="http://drupal.org/node/627816"&gt;OpenLayers&lt;/a&gt;&amp;nbsp;[drupal.org]&amp;nbsp;requests:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://drupal.org/project/views"&gt;Views:&lt;/a&gt;&amp;nbsp;&lt;a class="reference external" href="http://ftp.drupal.org/files/projects/views-7.x-3.0-rc3.tar.gz"&gt;http://ftp.drupal.org/files/projects/views-7.x-3.0-rc3.tar.gz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://drupal.org/project/openlayers"&gt;OpenLayers&lt;/a&gt;:&amp;nbsp;&lt;a class="reference external" href="http://ftp.drupal.org/files/projects/openlayers-7.x-2.0-beta1.tar.gz"&gt;http://ftp.drupal.org/files/projects/openlayers-7.x-2.0-beta1.tar.gz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://drupal.org/project/ctools"&gt;Chaos
Tools:&lt;/a&gt;&amp;nbsp;&lt;a class="reference external" href="http://ftp.drupal.org/files/projects/ctools-7.x-1.0-rc1.tar.gz"&gt;http://ftp.drupal.org/files/projects/ctools-7.x-1.0-rc1.tar.gz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;And went to the Modules administration in drupal to enable the new
modules. That&amp;#8217;s it! The webserver is working with all the necessary&amp;nbsp;modules!&lt;/p&gt;
&lt;p&gt;There is another tool that seems to be very useful in this context:
&lt;a class="reference external" href="http://drupal.org/project/drush"&gt;drush&lt;/a&gt;. To make it work, php-pear
must be installed.&amp;nbsp;Now,&lt;/p&gt;
&lt;pre class="literal-block"&gt;
pear channel-discovery pear.drush.org
pear install drush/drush
&lt;/pre&gt;
&lt;p&gt;After that, another module will be integrated:
&lt;a class="reference external" href="http://drupal.org/project/geofield"&gt;geofield&lt;/a&gt;, for the geographical
data manipulation. Drush didn&amp;#8217;t help, so I had to install by hand drupal&amp;nbsp;libraries&lt;/p&gt;
&lt;pre class="literal-block"&gt;
http://ftp.drupal.org/files/projects/libraries-7.x-1.0.tar.gz
&lt;/pre&gt;
&lt;p&gt;And after enabling it, installed the geofield&amp;nbsp;module:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://drupal.org/project/geofield"&gt;Geofield:&lt;/a&gt;&amp;nbsp;&lt;a class="reference external" href="http://ftp.drupal.org/files/projects/geofield-7.x-1.0-beta2.tar.gz"&gt;http://ftp.drupal.org/files/projects/geofield-7.x-1.0-beta2.tar.gz&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Enabled it, and it&amp;#8217;s working! Server up and fully loaded. Now it&amp;#8217;s time
to start writing&amp;nbsp;code&amp;#8230;&lt;/p&gt;
&lt;p&gt;* &lt;span class="caps"&gt;NOTE&lt;/span&gt; * I didn&amp;#8217;t take &lt;span class="caps"&gt;ANY&lt;/span&gt; security measures to secure the server.
There are several things that should be changed to secure apache,
drupal, ssh,&amp;nbsp;ftp&amp;#8230;&lt;/p&gt;
</content><category term="debian"></category><category term="debiangis"></category><category term="gis"></category></entry><entry><title>Reconfiguring the keyboard configuration on console - Debian</title><link href="http://mfactor.sdf.org/blog/2011_11_03_keyboard-console-debian.html" rel="alternate"></link><published>2011-11-03T07:23:00-02:00</published><updated>2011-11-03T07:23:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2011-11-03:/blog/2011_11_03_keyboard-console-debian.html</id><summary type="html">&lt;p&gt;dpkg-reconfigure&amp;nbsp;keyboard-configuration.&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s it. No non-sense, no fuss, and no c with&amp;nbsp;accent.&lt;/p&gt;
</summary><content type="html">&lt;p&gt;dpkg-reconfigure&amp;nbsp;keyboard-configuration.&lt;/p&gt;
&lt;p&gt;That&amp;#8217;s it. No non-sense, no fuss, and no c with&amp;nbsp;accent.&lt;/p&gt;
</content><category term="configuration"></category><category term="debian"></category><category term="server"></category></entry><entry><title>Diferenças entre Debian e Ubuntu, em Português</title><link href="http://mfactor.sdf.org/blog/2009_07_09_diff_debian_ubuntu_ptbr.html" rel="alternate"></link><published>2009-07-09T17:00:00-03:00</published><updated>2009-07-09T17:00:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-07-09:/blog/2009_07_09_diff_debian_ubuntu_ptbr.html</id><summary type="html">&lt;p&gt;Como prometido, aqui está a tradução em Português to texto do AndyC. Ele
educadamente permitiu que fosse traduzido. Qualquer erro ou omissão é de
minha inteira&amp;nbsp;responsabilidade!&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Muitas diferenças: algumas grandes, algumas pequenas, mas todas podem
ser significantes. Eu _NÃO_ estou falando com direito oficial pelo
projeto Debian, ou mesmo …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Como prometido, aqui está a tradução em Português to texto do AndyC. Ele
educadamente permitiu que fosse traduzido. Qualquer erro ou omissão é de
minha inteira&amp;nbsp;responsabilidade!&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Muitas diferenças: algumas grandes, algumas pequenas, mas todas podem
ser significantes. Eu _NÃO_ estou falando com direito oficial pelo
projeto Debian, ou mesmo o Ubuntu, de qual projeto eu também sou&amp;nbsp;contribuinte.&lt;/p&gt;
&lt;p&gt;Quando o Ubuntu começou, um de seus desenvolvedores disse para mim &amp;#8220;se
pudéssemos ter chamado de Debian para desktops, nós o teríamos feito.&amp;#8221;
Este era o foco deles naquela época; desde então ele aumentou
significativamente. Mas o foco principal do Ubuntu continua sendo a
experiência do usuário e um pequeno núcleo de&amp;nbsp;aplicações.&lt;/p&gt;
&lt;p&gt;Grandemente subjetivo, feito o mais distanciado quanto eu posso!&amp;nbsp;:)&lt;/p&gt;
&lt;p&gt;++Razões/Objetivos de&amp;nbsp;Projeto++&lt;/p&gt;
&lt;p&gt;Pacotes no Ubuntu main são altamentes polidos (trabalhados)[ed], muito
bem mantidos e a Canonical/Ubuntu fazem um esforço ímpar em garantir que
a experiência seja fácil para o usuário. Isto proporciona um ou mais dos
seguintes&amp;nbsp;custos:&lt;/p&gt;
&lt;p&gt;++Escolha++&lt;/p&gt;
&lt;p&gt;Falta de escolha - você ganha um cliente de email ao invés de uma
escolha de vários &amp;#8220;out of the box&amp;#8221;, por exemplo. Escolhas são feitas
para você - é um problema de suportabilidade. Debian fornece uma maior
flexibilidade pelo preço de maior complexidade ou a vontade de suportar
suas próprias&amp;nbsp;decisões.&lt;/p&gt;
&lt;p&gt;++Arquiteturas++&lt;/p&gt;
&lt;p&gt;Falta de arquiteturas: se você não estiver usando Intel/&lt;span class="caps"&gt;AMD64&lt;/span&gt; or,
possivelmente, &lt;span class="caps"&gt;ARM&lt;/span&gt;/Sparc/&lt;span class="caps"&gt;PPC&lt;/span&gt; (dependendo do release) - você não pode
rodar Ubuntu.&amp;nbsp; O Debian rodar em mais ou menos 11 arquiteturas significa
que a) o processo às vezes é lento b) o código é debugado c) é feito de
forma portável/consertos são contribuídos&amp;nbsp;upstream.&lt;/p&gt;
&lt;p&gt;++Relação&amp;nbsp;Desenvolvedores/Usuários++&lt;/p&gt;
&lt;p&gt;Canonical tem relativamente poucos desenvolvedores pagos, uma comunidade
de desenvolvedores voluntários altamente motivada, uma comunidade de
divulgação e um orçamento de propaganda e um número vasto de novos
usuários. Isto significa que seus desenvolvedores estão em uma
desvantagem numérica massiva com relação aos usuários e portanto
prioridades devem ser escolhidas. Pacotes no universe/multiverse podem
portanto receber menos atenção que aqueles no main do&amp;nbsp;Ubuntu.&lt;/p&gt;
&lt;p&gt;Na teoria, pelo menos, cada pacote Debian é igual e tem um mantenedor
conhecido e denomeado que tem interesse :) Isto significa que o Debian
faz o trabalho pesado de empacotar e suporte inicial para pacotes não
tão comuns - isto também significa que, se eu quero suporte para o R ou
&lt;span class="caps"&gt;CRAN&lt;/span&gt;, por exemplo, eu iria diretamente para o Debian por quê o
mantenedor tem um interesse pessoal ou profissional em vê-lo funcionar
bem como um sistema&amp;nbsp;integrado.&lt;/p&gt;
&lt;p&gt;++ Ciclos de&amp;nbsp;Release++&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Nós demandamos áreas rigidamente definidas de dúvida e incertezas&amp;#8221; -
Canonical tem estas áreas porque solta releases a cada seis meses. Esta
consistência tem um preço: usuários esperam novas features
(características, coisas)[ed] brilhantes e superbacanas a cada release e
o ciclo de desenvolvimento é bem curto mesmo. As edições com Suporte de
Longa Vida (Long Term Support, &lt;span class="caps"&gt;LTS&lt;/span&gt;)[ed] são lançadas a cada 18 meses e
são suportadas por três anos no desktop e cinco nas de servidor. Isto é
difícil. É _muito_ difícil suportar novo hardware com as edições de
longa vida. Releases &amp;#8220;normais&amp;#8221; podem misturar pacotes do Debian estável
com o testing, instável ou até mesmo experimental (características
superbacanas) mas ganham um tempo de teste bem&amp;nbsp;curto.&lt;/p&gt;
&lt;p&gt;Debian &amp;#8220;lança quando pronto&amp;#8221; mas depois suporta esta release até um ano
após o lançamento do _próximo_ release. 22 meses para lançar o Etch,
22 meses para lançar o Lenny + 12 meses = 56 meses. Progresso lento
através do testing até o release, com atualizações regulares com
consertos de&amp;nbsp;segurança.&lt;/p&gt;
&lt;p&gt;++Liberdade vs.&amp;nbsp;Pragmatismo++&lt;/p&gt;
&lt;p&gt;O Ubuntu às vezes toma uma atitude pragmática para o &amp;#8220;software que
funciona&amp;#8221; para os usuários. Eles também tem a habilidade, que o Debian
não tem, de entrar em acordos comerciais com outras companhias por ex.
Oracle/VMWare. [&lt;span class="caps"&gt;DFSG&lt;/span&gt; - não &amp;#8220;licença apenas para o Debian&amp;#8221;]. A Canonical
se beneficia do idealismo do Debian, mas o fluxo não pode escoar no
outro sentido&amp;nbsp;:(&lt;/p&gt;
&lt;p&gt;++Atualizações entre&amp;nbsp;releases++&lt;/p&gt;
&lt;p&gt;Você pode escutar muitas visões sobre isso. OPINIÃO &lt;span class="caps"&gt;SUBJETIVA&lt;/span&gt; A &lt;span class="caps"&gt;SEGUIR&lt;/span&gt;:
&lt;span class="caps"&gt;SENTIMENTO&lt;/span&gt; &lt;span class="caps"&gt;DE&lt;/span&gt; &lt;span class="caps"&gt;DENTRO&lt;/span&gt; E EXPERIÊNCIA &lt;span class="caps"&gt;EM&lt;/span&gt; &lt;span class="caps"&gt;PARTES&lt;/span&gt; &lt;span class="caps"&gt;IGUAIS&lt;/span&gt;. Ubuntu é mais
difícil de se atualizar limpamente entre as releases e pode ser na
verdade mais rápido se reinstalar. Você certamente pode pular uma
release portanto você não precisaria ir do 8.04, 8.10, 9.04, 9.10 (por
exemplo). Isto é parcialmente uma consequência do ciclo de
desenvolvimento curto visto acima. O Debian é _muito_ mais polido aqui
/&lt;span class="caps"&gt;SUBJETIVO&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;++Sumário++&lt;/p&gt;
&lt;p&gt;Tudo isto é bem explicado no The Official Ubuntu Book e na entrevista
deMark Shuttleworth para a revista &amp;#8220;Linux Format&amp;#8221;. Também vale a pena
ler newsgroups/fora e o planet.debian.org/planet.ubuntu.com para se
apreciar melhor as abordagens semelhantes e diferentes. Debian e Ubuntu
ambos tem pontos positivos: sua (algumas vezes complicada) simbiose -
ambas as distribuições compartilham desenvolvedores, por exemplo, mas
não necessariamente objetivos - mas o Debian ganha tanto quanto o Ubuntu
se eles conseguirem consertar o maldito bug #1&amp;nbsp;:)&lt;/p&gt;
&lt;p&gt;Espero que&amp;nbsp;ajude,&lt;/p&gt;
&lt;p&gt;AndyC&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;E aí está. Os comentários em parêntesis com um [ed] depois foram termos
que acrescentei para tentar fazer um entendimento melhor. Mantive alguns
termos em inglês pelo uso corrente deles na área, ou para facilitar
mesmo (como o termo&amp;nbsp;release).&lt;/p&gt;
&lt;p&gt;Por favor, enviem correções/omissões/barbaridades que eu tenha&amp;nbsp;feito!&lt;/p&gt;
</content><category term="debian"></category><category term="tradução"></category><category term="translation"></category><category term="ubuntu"></category></entry><entry><title>Diferenças entre Ubuntu e Debian</title><link href="http://mfactor.sdf.org/blog/2009_07_09_diff_debian_ubuntu.html" rel="alternate"></link><published>2009-07-09T12:05:00-03:00</published><updated>2009-07-09T12:05:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-07-09:/blog/2009_07_09_diff_debian_ubuntu.html</id><summary type="html">&lt;p&gt;Lendo a lista de usuários Debian (debian-user), vi uma discussão que
achei muito interessante, sobre as principais diferenças entre o Debian
e o Ubuntu. O autor, AndyC, liberou o artigo para ser postado no
wiki.debian.org, então reproduzo aqui o post. Leitura muito
interessante, que vou tentar depois traduzir …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Lendo a lista de usuários Debian (debian-user), vi uma discussão que
achei muito interessante, sobre as principais diferenças entre o Debian
e o Ubuntu. O autor, AndyC, liberou o artigo para ser postado no
wiki.debian.org, então reproduzo aqui o post. Leitura muito
interessante, que vou tentar depois traduzir para o&amp;nbsp;Português.&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Post deAndrew Carter,&amp;nbsp;debian-user&amp;#64;&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Lots of differences: some big, some small but all may be significant.
I&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;am _NOT_speaking in an official capacity for the Debian project or,&lt;/div&gt;
&lt;div class="line"&gt;indeed, for Ubuntu to whom I&amp;#8217;m also a contributor.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;When Ubuntu first started, one of their developers said to me &amp;#8220;If we&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;could have called it Debian for desktops, we would have done&amp;#8221;. That
was&lt;/div&gt;
&lt;div class="line"&gt;their focus then: it has widened significantly now. But the core
focus&lt;/div&gt;
&lt;div class="line"&gt;for Ubuntu remains the user experience and a small core of
applications.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Largely subjectively, from as far to the outside as I can get&amp;nbsp;:)&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Rationale/design goals&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;======================&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Packages in Ubuntu main are very highly polished, very well maintained&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;and Canonical/Ubuntu go the extra mile to make the experience easy
for&lt;/div&gt;
&lt;div class="line"&gt;the user. That comes at one or more of several costs:&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Choice&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;======&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Lack of choice - you get one mail client rather than a choice of&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;several &amp;#8220;out of the box&amp;#8221;, for example. Choices are made for you - its
an&lt;/div&gt;
&lt;div class="line"&gt;issue of supportability. Debian offers you more flexibility at the
price&lt;/div&gt;
&lt;div class="line"&gt;of complexity or being willing to support your choices.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Architectures&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;=============&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Lack of architectures: if you&amp;#8217;re not on Intel/&lt;span class="caps"&gt;AMD64&lt;/span&gt; or, possibly,&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;span class="caps"&gt;ARM&lt;/span&gt;/Sparc/&lt;span class="caps"&gt;PPC&lt;/span&gt; (depending on release) - you can&amp;#8217;t run Ubuntu. Debian&lt;/div&gt;
&lt;div class="line"&gt;running on 11 or so architectures does mean that a) the process is&lt;/div&gt;
&lt;div class="line"&gt;sometimes slow b) the code gets debugged c) is made portable/fixes
are&lt;/div&gt;
&lt;div class="line"&gt;contributed upstream.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Developer/user ratio&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;====================&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Canonical has relatively few paid developers, a highly motivated&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;volunteeer developer community, a much larger community advocacy and&lt;/div&gt;
&lt;div class="line"&gt;marketing budget and a vast number of new users. This does&lt;/div&gt;
&lt;div class="line"&gt;mean that their developers are massively outnumbered by their users
and&lt;/div&gt;
&lt;div class="line"&gt;priorities have to be set. Packages in universe/multiverse may
therefore&lt;/div&gt;
&lt;div class="line"&gt;receive less attention than those in main in Ubuntu.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;At least in theory, every package in Debian is equal and has a known
named&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;maintainer who takes an interest :) It does mean that Debian does
much of&lt;/div&gt;
&lt;div class="line"&gt;the heavy lifting of packaging and initial support for out of the way&lt;/div&gt;
&lt;div class="line"&gt;packages - it also means that, if I want support for R and &lt;span class="caps"&gt;CRAN&lt;/span&gt;, for
example,&lt;/div&gt;
&lt;div class="line"&gt;I&amp;#8217;d go straight to Debian because the maintainer has a personal and&lt;/div&gt;
&lt;div class="line"&gt;professional interest for seeing it work well as an integrated
system.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Release cycles&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;==============&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&amp;#8220;We demand rigidly defined areas of doubt and uncertainty&amp;#8221; - Canonical&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;has those because it releases once every six months. This consistency&lt;/div&gt;
&lt;div class="line"&gt;comes at a price: users expect new whizzy features with each release
and&lt;/div&gt;
&lt;div class="line"&gt;the development cycle is very short indeed. Long term support
releases&lt;/div&gt;
&lt;div class="line"&gt;happen every 18 months and are supported for three years on the&lt;/div&gt;
&lt;div class="line"&gt;desktop/five years on the server. That&amp;#8217;s hard. It&amp;#8217;s _very_ hard to&lt;/div&gt;
&lt;div class="line"&gt;support new hardware with long term releases. &amp;#8220;Normal&amp;#8221; releases may
mix&lt;/div&gt;
&lt;div class="line"&gt;packages from Debian stable with testing, unstable or even
experimental&lt;/div&gt;
&lt;div class="line"&gt;(whizzy features) but get only a short testing time.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Debian &amp;#8220;releases when ready&amp;#8221; but then supports that release until
about&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;a year after the _next_ release. 22 months to release Etch, 22
months to&lt;/div&gt;
&lt;div class="line"&gt;release Lenny + 12 months = 56 months. Slow moving progress through&lt;/div&gt;
&lt;div class="line"&gt;testing to release, regular point updates with security fixes.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Freeness vs. pragmatism&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;=======================&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Ubuntu may sometimes take a pragmatic attitude for &amp;#8220;software that
works&amp;#8221;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;for users. They also have the ability, which Debian does not, to
enter&lt;/div&gt;
&lt;div class="line"&gt;into commercial agreements for third party apps e.g. Oracle/VMWare.&lt;/div&gt;
&lt;div class="line"&gt;[&lt;span class="caps"&gt;DFSG&lt;/span&gt; - not &amp;#8220;licence just for Debian&amp;#8221;]. Canonical benefits from
Debian&lt;/div&gt;
&lt;div class="line"&gt;idealism but it can&amp;#8217;t flow the other way :(&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Upgrades between releases&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;=========================&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;You&amp;#8217;ll hear lots of views on this. &lt;span class="caps"&gt;SUBJECTIVE&lt;/span&gt; &lt;span class="caps"&gt;OPINION&lt;/span&gt; &lt;span class="caps"&gt;FOLLOWS&lt;/span&gt;:&lt;span class="caps"&gt;GUT&lt;/span&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;span class="caps"&gt;FEELING&lt;/span&gt; &lt;span class="caps"&gt;AND&lt;/span&gt; &lt;span class="caps"&gt;EXPERIENCE&lt;/span&gt; &lt;span class="caps"&gt;IN&lt;/span&gt; &lt;span class="caps"&gt;EQUAL&lt;/span&gt; &lt;span class="caps"&gt;PARTS&lt;/span&gt;. Ubuntu is harder to upgrade&lt;/div&gt;
&lt;div class="line"&gt;cleanly between releases and it may actually be quicker to reinstall.&lt;/div&gt;
&lt;div class="line"&gt;You certainly can&amp;#8217;t skip a release so you&amp;#8217;d need to do 8.04, 8.10,&lt;/div&gt;
&lt;div class="line"&gt;9.04, 9.10 (for example). This is partly a consequence of short
release&lt;/div&gt;
&lt;div class="line"&gt;cycles above. Debian is _far_ more polished here /&lt;span class="caps"&gt;SUBJECTIVE&lt;/span&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Summary&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;=======&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;All of this is very well explained by The Official Ubuntu Book and
Mark&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Shuttleworth&amp;#8217;s latest interview for ?? Linux Format ?? magazine.&lt;/div&gt;
&lt;div class="line"&gt;Its also worth reading newsgroups/fora and planet.debian.org /&lt;/div&gt;
&lt;div class="line"&gt;planet.ubuntu.com to get a better appreciation of the similarities
and&lt;/div&gt;
&lt;div class="line"&gt;differences in approach. Debian and Ubuntu each have strengths: its a&lt;/div&gt;
&lt;div class="line"&gt;(sometimes uneasy) symbiosis - both distributions share many of the
same&lt;/div&gt;
&lt;div class="line"&gt;developers, for example, but not necessarily end goals - but Debian&lt;/div&gt;
&lt;div class="line"&gt;gains as much as Ubuntu if they&amp;#8217;ll just fix their bloody bug #1 :)&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Hope this&amp;nbsp;helps,&lt;/p&gt;
&lt;p&gt;AndyC&lt;/p&gt;
</content><category term="debian"></category><category term="development"></category><category term="open source"></category><category term="ubuntu"></category></entry><entry><title>sudoers file with restricted permissions</title><link href="http://mfactor.sdf.org/blog/2009_05_13_sudoers_perm.html" rel="alternate"></link><published>2009-05-13T18:10:00-03:00</published><updated>2009-05-13T18:10:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-05-13:/blog/2009_05_13_sudoers_perm.html</id><summary type="html">&lt;p&gt;O acesso ao sudo é uma ferramenta bem poderosa no linux, mas que
geralmente é mal usada, permitindo que qualquer comando possa ser feito
com sudo, o que é um risco de segurança. O ideal é que os usuários
tenham acesso root a nada, ou a somente os comandos &lt;em&gt;realmente …&lt;/em&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;O acesso ao sudo é uma ferramenta bem poderosa no linux, mas que
geralmente é mal usada, permitindo que qualquer comando possa ser feito
com sudo, o que é um risco de segurança. O ideal é que os usuários
tenham acesso root a nada, ou a somente os comandos &lt;em&gt;realmente&lt;/em&gt;
necessários. Aqui no &lt;span class="caps"&gt;LHC&lt;/span&gt; temos um novo aluno que está montando a
plataforma web dos dados de campo. Ele vai precisar acesso ao apache2 e
ao mysql. Para isso, o /etc/sudoers foi configurado da seguinte forma:#&amp;nbsp;/etc/sudoers&lt;/p&gt;
&lt;pre class="literal-block"&gt;
#
# This file MUST be edited with the 'visudo' command as root.
#
# See the man page for details on how to write a sudoers file.
#

Defaults&amp;nbsp;&amp;nbsp; &amp;nbsp;env_reset

# Host alias specification

# User alias specification

# Cmnd alias specification
Cmnd_Alias APACHE_START = /etc/init.d/apache2 start
Cmnd_Alias APACHE_STOP = /etc/init.d/apache2 stop
Cmnd_Alias APACHE_RESTART = /etc/init.d/apache2 restart
Cmnd_Alias MYSQL = /usr/bin/mysql
# User privilege specification
root&amp;nbsp;&amp;nbsp; &amp;nbsp;ALL=(ALL) ALL
ispmarin ALL=(ALL) NOPASSWD:ALL
pucciarelli ALL=APACHE_START, APACHE_STOP,APACHE_RESTART,MYSQL
# Uncomment to allow members of group sudo to not need a password
# (Note that later entries override this, so you might need to move
# it further down)
# %sudo ALL=NOPASSWD: ALL
&lt;/pre&gt;
&lt;p&gt;O que permite que o usuário só acesse esses comandos,&amp;nbsp; o que é&amp;nbsp;excelente.&lt;/p&gt;
&lt;p&gt;Edit 23/05: está funcionando a contento. O usuário está conseguindo
trabalhar corretamente com o Drupal na isengard sem precisar de mais
acesso ao sistema, o que é ótimo, pois a isengard é a minha máquina de
trabalho diário e meu servidor de&amp;nbsp;arquivos.&lt;/p&gt;
</content><category term="config"></category><category term="debian"></category><category term="sudo"></category></entry><entry><title>InfoAbril</title><link href="http://mfactor.sdf.org/blog/2009_04_15_infoabril.html" rel="alternate"></link><published>2009-04-15T18:09:00-03:00</published><updated>2009-04-15T18:09:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-15:/blog/2009_04_15_infoabril.html</id><summary type="html">&lt;p&gt;Acabou de sair uma notícia na revista Info sobre o ataque do&amp;nbsp;Virtua:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://info.abril.com.br/noticias/tecnologia-pessoal/cracker-invade-virtua-e-muda-dns-do-bradesco-15042009-36.shl"&gt;http://info.abril.com.br/noticias/tecnologia-pessoal/cracker-invade-virtua-e-muda-dns-do-bradesco-15042009-36.shl&lt;/a&gt;&lt;/p&gt;
</summary><content type="html">&lt;p&gt;Acabou de sair uma notícia na revista Info sobre o ataque do&amp;nbsp;Virtua:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://info.abril.com.br/noticias/tecnologia-pessoal/cracker-invade-virtua-e-muda-dns-do-bradesco-15042009-36.shl"&gt;http://info.abril.com.br/noticias/tecnologia-pessoal/cracker-invade-virtua-e-muda-dns-do-bradesco-15042009-36.shl&lt;/a&gt;&lt;/p&gt;
</content><category term="press"></category><category term="network"></category><category term="security"></category><category term="dns"></category></entry><entry><title>Histórico de ataques a DNS - 7</title><link href="http://mfactor.sdf.org/blog/2009_04_15_dns_attack_history.html" rel="alternate"></link><published>2009-04-15T17:19:00-03:00</published><updated>2009-04-15T17:19:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-15:/blog/2009_04_15_dns_attack_history.html</id><summary type="html">&lt;p&gt;O Gustavo acabou de relatar um post em um fórum
(&lt;a class="reference external" href="http://macmagazine.com.br/forum/index.php?showtopic=10070"&gt;http://macmagazine.com.br/forum/index.php?showtopic=10070&lt;/a&gt;) dizendo que
aconteceu antes. Mesmo comportamento do que ocorreu agora, troca direta
do &lt;span class="caps"&gt;DNS&lt;/span&gt;. E com o Virtua, mas agora com outro &lt;span class="caps"&gt;DNS&lt;/span&gt;, os 201.6.0.112 ou
201.6 …&lt;/p&gt;</summary><content type="html">&lt;p&gt;O Gustavo acabou de relatar um post em um fórum
(&lt;a class="reference external" href="http://macmagazine.com.br/forum/index.php?showtopic=10070"&gt;http://macmagazine.com.br/forum/index.php?showtopic=10070&lt;/a&gt;) dizendo que
aconteceu antes. Mesmo comportamento do que ocorreu agora, troca direta
do &lt;span class="caps"&gt;DNS&lt;/span&gt;. E com o Virtua, mas agora com outro &lt;span class="caps"&gt;DNS&lt;/span&gt;, os 201.6.0.112 ou
201.6.0.113. O post é de novembro do ano passado. O Rafael, que tem
acesso aos &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua por estar em &lt;span class="caps"&gt;SP&lt;/span&gt;, acabou de testar tanto
www.bradesco.com.br quanto www.bradescoprime.com.br no 112 e 113 e disse
que está ok. Mas o&amp;nbsp;43&amp;#8230;&lt;/p&gt;
&lt;p&gt;17:12 o Rafael constatou que o .43 está retornando &lt;span class="caps"&gt;SERVER&lt;/span&gt; &lt;span class="caps"&gt;FAIL&lt;/span&gt; para&amp;nbsp;www.bradesco.com.br:&lt;/p&gt;
&lt;p&gt;&amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.5.0-P2 &amp;lt;&amp;lt;&amp;gt;&amp;gt; &amp;#64;201.6.0.43
&lt;a class="reference external" href="http://www.bradesco.com.br/"&gt;http://www.bradesco.com.br&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;; (1 server&amp;nbsp;found)&lt;/p&gt;
&lt;p&gt;;; global options:&amp;nbsp;printcmd&lt;/p&gt;
&lt;p&gt;;; Got&amp;nbsp;answer:&lt;/p&gt;
&lt;p&gt;;; -&amp;gt;&amp;gt;&lt;span class="caps"&gt;HEADER&lt;/span&gt;&amp;lt;&amp;lt;- opcode: &lt;span class="caps"&gt;QUERY&lt;/span&gt;, status: &lt;span class="caps"&gt;SERVFAIL&lt;/span&gt;, id:&amp;nbsp;30233&lt;/p&gt;
&lt;p&gt;;; flags: qr rd ra; &lt;span class="caps"&gt;QUERY&lt;/span&gt;: 1, &lt;span class="caps"&gt;ANSWER&lt;/span&gt;: 0, &lt;span class="caps"&gt;AUTHORITY&lt;/span&gt;: 0, &lt;span class="caps"&gt;ADDITIONAL&lt;/span&gt;:&amp;nbsp;0&lt;/p&gt;
&lt;p&gt;;; &lt;span class="caps"&gt;QUESTION&lt;/span&gt; &lt;span class="caps"&gt;SECTION&lt;/span&gt;:&lt;/p&gt;
&lt;p&gt;;www.bradesco.com.br. &lt;span class="caps"&gt;IN&lt;/span&gt;&amp;nbsp;A&lt;/p&gt;
&lt;p&gt;;; Query time: 45&amp;nbsp;msec&lt;/p&gt;
&lt;p&gt;;; &lt;span class="caps"&gt;SERVER&lt;/span&gt;:&amp;nbsp;201.6.0.43#53(201.6.0.43)&lt;/p&gt;
&lt;p&gt;;; &lt;span class="caps"&gt;WHEN&lt;/span&gt;: Wed Apr 15 17:11:07&amp;nbsp;2009&lt;/p&gt;
&lt;p&gt;;; &lt;span class="caps"&gt;MSG&lt;/span&gt; &lt;span class="caps"&gt;SIZE&lt;/span&gt; rcvd:&amp;nbsp;37&lt;/p&gt;
&lt;p&gt;bradescoprime.com.br no 112 e 113 e disse que está ok. Mas o 43&amp;#8230; o
www.bradesco.com.br não está sendo retornado agora, 17:16, ou seja,
estão removendo a entrada e colocando o novo. Mas estão consertando a
falha de segurança que está permitindo&amp;nbsp;isso?&lt;/p&gt;
</content><category term="fail"></category><category term="net"></category><category term="security"></category><category term="dns"></category></entry><entry><title>Teste de DNS via Kamdinsky</title><link href="http://mfactor.sdf.org/blog/2009_04_15_dns_test.html" rel="alternate"></link><published>2009-04-15T12:46:00-03:00</published><updated>2009-04-15T12:46:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-15:/blog/2009_04_15_dns_test.html</id><summary type="html">&lt;p&gt;O cara que descobriu o &lt;span class="caps"&gt;DNS&lt;/span&gt; Poisoning (lembrando que não sabemos o que
está acontecendo no servidor &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua, pode ser isso ou não!!), Dan
Kamdinsky, tem um teste para um server &lt;span class="caps"&gt;DNS&lt;/span&gt;, sobre a aleatoriedade das
portas de resposta. Testem&amp;nbsp;com&lt;/p&gt;
&lt;p&gt;dig +short &amp;#64;&lt;a class="reference external" href="http://201.6.0.43/"&gt;201.6.0.43&lt;/a&gt;
&lt;a class="reference external" href="http://porttest.dns-oarc.net/"&gt;porttest …&lt;/a&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;O cara que descobriu o &lt;span class="caps"&gt;DNS&lt;/span&gt; Poisoning (lembrando que não sabemos o que
está acontecendo no servidor &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua, pode ser isso ou não!!), Dan
Kamdinsky, tem um teste para um server &lt;span class="caps"&gt;DNS&lt;/span&gt;, sobre a aleatoriedade das
portas de resposta. Testem&amp;nbsp;com&lt;/p&gt;
&lt;p&gt;dig +short &amp;#64;&lt;a class="reference external" href="http://201.6.0.43/"&gt;201.6.0.43&lt;/a&gt;
&lt;a class="reference external" href="http://porttest.dns-oarc.net/"&gt;porttest.dns-oarc.net&lt;/a&gt; &lt;span class="caps"&gt;TXT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;e veja se o resultado é o quê. Postem aqui para&amp;nbsp;discutirmos.&lt;/p&gt;
&lt;p&gt;O Rafael acabou de testar o server do&amp;nbsp;Virtua:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://porttest.y.x.w.v.u.t.s.r.q.p.o.n.m.l.k.j.i.h.g.f.e.d.c.b.a.pt.dns-oarc.net/"&gt;porttest.y.x.w.v.u.t.s.r.q.p.o.n.m.l.k.j.i.h.g.f.e.d.c.b.a.pt.dns-oarc.net&lt;/a&gt;
&amp;#8220;201.6.0.43 is &lt;span class="caps"&gt;GREAT&lt;/span&gt;: 26 queries in 4.8 seconds from 26 ports with std dev&amp;nbsp;20760&amp;#8221;&lt;/p&gt;
&lt;p&gt;Ou seja, parece que a aleatoriedade das portas deste servidor é boa.
Mais investigação é necessária. Assim que tiver tempo junto mais
informações sobre esse&amp;nbsp;teste.&lt;/p&gt;
</content><category term="net"></category><category term="security"></category><category term="segurança"></category></entry><entry><title>DNS poisoning ainda acontecendo - 8</title><link href="http://mfactor.sdf.org/blog/2009_04_15_dns_poisoning_still.html" rel="alternate"></link><published>2009-04-15T11:51:00-03:00</published><updated>2009-04-15T11:51:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-15:/blog/2009_04_15_dns_poisoning_still.html</id><summary type="html">&lt;p&gt;Um user no blog do Rafael percebeu de novo que o &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua foi
comprometido (&lt;a class="reference external" href="http://stoa.usp.br/calsaverini/weblog/47528.html"&gt;http://stoa.usp.br/calsaverini/weblog/47528.html&lt;/a&gt;). Olha o&amp;nbsp;comentário:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://stoa.usp.br/walrus/"&gt;Aivuk (&lt;span class="caps"&gt;AKA&lt;/span&gt; Walrus)&lt;/a&gt;&amp;nbsp;escreveu:&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Pelo vistoo pessoal da Net não resolveu o problema ainda de forma
definitiva. Olha a resposta do fatídico servidor …&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;Um user no blog do Rafael percebeu de novo que o &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua foi
comprometido (&lt;a class="reference external" href="http://stoa.usp.br/calsaverini/weblog/47528.html"&gt;http://stoa.usp.br/calsaverini/weblog/47528.html&lt;/a&gt;). Olha o&amp;nbsp;comentário:&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://stoa.usp.br/walrus/"&gt;Aivuk (&lt;span class="caps"&gt;AKA&lt;/span&gt; Walrus)&lt;/a&gt;&amp;nbsp;escreveu:&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Pelo vistoo pessoal da Net não resolveu o problema ainda de forma
definitiva. Olha a resposta do fatídico servidor &lt;span class="caps"&gt;DNS&lt;/span&gt; às 21:00 de
terça:&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;[/home/walrus] dig &amp;#64;201.6.0.43 www.bradesco.com.br&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;; &amp;lt;&amp;lt;&amp;gt;&amp;gt; DiG 9.6.0-P1 &amp;lt;&amp;lt;&amp;gt;&amp;gt; &amp;#64;201.6.0.43 www.bradesco.com.br&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;; (1 server found)&lt;/div&gt;
&lt;div class="line"&gt;;; global options: +cmd&lt;/div&gt;
&lt;div class="line"&gt;;; Got answer:&lt;/div&gt;
&lt;div class="line"&gt;;; -&amp;gt;&amp;gt;&lt;span class="caps"&gt;HEADER&lt;/span&gt;&amp;lt;&amp;lt;- opcode: &lt;span class="caps"&gt;QUERY&lt;/span&gt;, status: &lt;span class="caps"&gt;NOERROR&lt;/span&gt;, id: 55339&lt;/div&gt;
&lt;div class="line"&gt;;; flags: qr aa rd ra; &lt;span class="caps"&gt;QUERY&lt;/span&gt;: 1, &lt;span class="caps"&gt;ANSWER&lt;/span&gt;: 1, &lt;span class="caps"&gt;AUTHORITY&lt;/span&gt;: 1, &lt;span class="caps"&gt;ADDITIONAL&lt;/span&gt;:
1&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;QUESTION&lt;/span&gt; &lt;span class="caps"&gt;SECTION&lt;/span&gt;:&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;www.bradesco.com.br.&amp;nbsp;&amp;nbsp;&amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;IN&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; A&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;ANSWER&lt;/span&gt; &lt;span class="caps"&gt;SECTION&lt;/span&gt;:&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;www.bradesco.com.br.&amp;nbsp;&amp;nbsp;&amp;nbsp; 5&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;IN&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; A&amp;nbsp;&amp;nbsp;&amp;nbsp; 210.205.6.46&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;AUTHORITY&lt;/span&gt; &lt;span class="caps"&gt;SECTION&lt;/span&gt;:&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;bradesco.com.br.&amp;nbsp;&amp;nbsp;&amp;nbsp; 5&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;IN&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;NS&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; dns1.virtua.com.br.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;ADDITIONAL&lt;/span&gt; &lt;span class="caps"&gt;SECTION&lt;/span&gt;:&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;dns1.virtua.com.br.&amp;nbsp;&amp;nbsp;&amp;nbsp; 2417&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;IN&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; A&amp;nbsp;&amp;nbsp;&amp;nbsp; 201.6.0.100&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;; Query time: 18 msec&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;SERVER&lt;/span&gt;: 201.6.0.43#53(201.6.0.43)&lt;/div&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;WHEN&lt;/span&gt;: Tue Apr 14 18:01:34 2009&lt;/div&gt;
&lt;div class="line"&gt;;; &lt;span class="caps"&gt;MSG&lt;/span&gt; &lt;span class="caps"&gt;SIZE&lt;/span&gt;&amp;nbsp; rcvd: 95&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Ou seja, tem um novo &lt;span class="caps"&gt;IP&lt;/span&gt;, do mesmo &lt;span class="caps"&gt;ISP&lt;/span&gt; sul coreano, comprometido. E o &lt;span class="caps"&gt;DNS&lt;/span&gt;
do Virtua (201.6.0.43) foi de novo&amp;nbsp;comprometido.&lt;/p&gt;
&lt;p&gt;# &lt;span class="caps"&gt;ENGLISH&lt;/span&gt;&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;span class="caps"&gt;KRNIC&lt;/span&gt; is not an &lt;span class="caps"&gt;ISP&lt;/span&gt; but a National Internet Registry similar to &lt;span class="caps"&gt;APNIC&lt;/span&gt;.&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;The IPv4 address is allocated and still held by the following &lt;span class="caps"&gt;ISP&lt;/span&gt;,&lt;/div&gt;
&lt;div class="line"&gt;or its Whois information is not updated after assigned to end users.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Please contact following &lt;span class="caps"&gt;ISP&lt;/span&gt; for further&amp;nbsp;information.&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;[ &lt;span class="caps"&gt;ISP&lt;/span&gt; Organization Information ]&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Org Name&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : &lt;span class="caps"&gt;SK&lt;/span&gt; Broadband Co Ltd&lt;/div&gt;
&lt;div class="line"&gt;Service Name&amp;nbsp; : broadNnet&lt;/div&gt;
&lt;div class="line"&gt;Org Address&amp;nbsp;&amp;nbsp; : &lt;span class="caps"&gt;SK&lt;/span&gt; NamsanGreen Bldg. Jung-gu Namdaemunno 5(o)-ga
Seoul&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;[ &lt;span class="caps"&gt;ISP&lt;/span&gt; IPv4 Admin Contact Information ]&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Name&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : &lt;span class="caps"&gt;IP&lt;/span&gt; manager&lt;/div&gt;
&lt;div class="line"&gt;Phone&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : +82-2-106-2&lt;/div&gt;
&lt;div class="line"&gt;E-Mail&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : &lt;a class="reference external" href="mailto:ip-adm&amp;#64;skbroadband.com"&gt;ip-adm&amp;#64;skbroadband.com&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;[ &lt;span class="caps"&gt;ISP&lt;/span&gt; IPv4 Tech Contact Information ]&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Name&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : &lt;span class="caps"&gt;IP&lt;/span&gt; manager&lt;/div&gt;
&lt;div class="line"&gt;Phone&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : +82-2-106-2&lt;/div&gt;
&lt;div class="line"&gt;E-mail&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : &lt;a class="reference external" href="mailto:ip-adm&amp;#64;skbroadband.com"&gt;ip-adm&amp;#64;skbroadband.com&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;[ &lt;span class="caps"&gt;ISP&lt;/span&gt; Network Abuse Contact Information ]&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Name&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : manager&lt;/div&gt;
&lt;div class="line"&gt;Phone&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : +82-2-106-2&lt;/div&gt;
&lt;div class="line"&gt;E-mail&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; : &lt;a class="reference external" href="mailto:abuse&amp;#64;skbroadband.com"&gt;abuse&amp;#64;skbroadband.com&lt;/a&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Estou tentando conseguir acesso a uma máquina no range de IPs do Virtua
em &lt;span class="caps"&gt;SP&lt;/span&gt;, com o Rafael, para testar esse &lt;span class="caps"&gt;DNS&lt;/span&gt;. E vou enviar mais uma vez um
relatório para o &lt;span class="caps"&gt;CAIS&lt;/span&gt;&amp;#8230;&lt;/p&gt;
</content><category term="net"></category><category term="security"></category><category term="dns"></category></entry><entry><title>Novidades do DNS poisoning do Virtua - 5</title><link href="http://mfactor.sdf.org/blog/2009_04_14_aftermath.html" rel="alternate"></link><published>2009-04-14T20:47:00-03:00</published><updated>2009-04-14T20:47:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-14:/blog/2009_04_14_aftermath.html</id><summary type="html">&lt;p&gt;Acabou de sair um artigo na Folha Online sobre o ataque no &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua
(o que vem sendo postado aqui no&amp;nbsp;anotherlifeform:)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www1.folha.uol.com.br/folha/informatica/ult124u550572.shtml"&gt;http://www1.folha.uol.com.br/folha/informatica/ult124u550572.shtml&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;A reportagem teve acesso a um e-mail no qual os ataques são confirmados
pela equipe de segurança …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Acabou de sair um artigo na Folha Online sobre o ataque no &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua
(o que vem sendo postado aqui no&amp;nbsp;anotherlifeform:)&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="http://www1.folha.uol.com.br/folha/informatica/ult124u550572.shtml"&gt;http://www1.folha.uol.com.br/folha/informatica/ult124u550572.shtml&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;A reportagem teve acesso a um e-mail no qual os ataques são confirmados
pela equipe de segurança do banco. &amp;#8220;Temos recebido relatos desse mesmo
problema de usuários do Vírtua que o sistema desse provedor está sendo
abusado [sic] para ataque a nossa instituição. Já acionamos nossos
colegas da &lt;span class="caps"&gt;NET&lt;/span&gt; para que solucionem o problema o quanto&amp;nbsp;antes.&amp;#8221;&amp;#8220;&lt;/p&gt;
&lt;p&gt;Por que isso não foi informado aos usuários, tanto da &lt;span class="caps"&gt;NET&lt;/span&gt; quanto do
Bradesco? Porque não pudemos falar diretamente com o pessoal do banco ou
da &lt;span class="caps"&gt;NET&lt;/span&gt;, ou pelo menos informados que eles sabiam? E quanto tempo isso
levou? Outro dado interessante: quantos usuários Virtua usam esse &lt;span class="caps"&gt;DNS&lt;/span&gt; em
São&amp;nbsp;Paulo?&lt;/p&gt;
&lt;p&gt;Se você quiser checar, dê uma olhada na sua conexão com o Virtua e veja
qual é o &lt;span class="caps"&gt;DNS&lt;/span&gt; que você usa. No linux é fácil:&amp;nbsp; no terminal&amp;nbsp;digite&lt;/p&gt;
&lt;p&gt;cat&amp;nbsp;/etc/resolv.conf&lt;/p&gt;
&lt;p&gt;deve aparecer algo&amp;nbsp;como&lt;/p&gt;
&lt;p&gt;nameserver&amp;nbsp;200.202.17.1&lt;/p&gt;
&lt;p&gt;veja se este número acima bate com o servidor &lt;span class="caps"&gt;DNS&lt;/span&gt; afetado: 201.6.0.43.
Se bater, você estava usando este servidor de &lt;span class="caps"&gt;DNS&lt;/span&gt;. No Windows, clique em
Propriedades de Rede-&amp;gt; Conexão (alguma coisa)-&amp;gt; &lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt; -&amp;gt; E veja o &lt;span class="caps"&gt;DNS&lt;/span&gt;.
Segundo a reportagem da Folha, a falha já foi corrigida. Mas afinal,
qual foi a falha? O Virtua atualizou seus servidores de &lt;span class="caps"&gt;DNS&lt;/span&gt; com os
updates do &lt;span class="caps"&gt;BIND&lt;/span&gt;, se é que eles usam &lt;span class="caps"&gt;BIND&lt;/span&gt;? (na noite de domingo, o Daniel
fez um nmap e descobriu que os servidores &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua rodam Windows&amp;nbsp;Server&amp;#8230;&amp;#8230;&amp;#8230;..)&lt;/p&gt;
&lt;p&gt;Como já postado aqui também, a Telefônica foi alvo de ataque em seus
&lt;span class="caps"&gt;DNS&lt;/span&gt;. Mas enquanto o ataque na Telefônica foi um provável &lt;span class="caps"&gt;DOS&lt;/span&gt; (Denial Of
Service), que os usuários podem sentir diretamente, o ataque no servidor
&lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua é muito mais sutil. Há quanto tempo ele estava
comprometido? Há alguma&amp;nbsp;relação?&lt;/p&gt;
</content><category term="dns"></category><category term="net"></category><category term="security"></category><category term="segurança"></category></entry><entry><title>Atendentes no incidente de poisoning do NET Virtua - 6</title><link href="http://mfactor.sdf.org/blog/2009_04_14_operators.html" rel="alternate"></link><published>2009-04-14T00:12:00-03:00</published><updated>2009-04-14T00:12:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-14:/blog/2009_04_14_operators.html</id><summary type="html">&lt;p&gt;Uma das coisas mais incríveis do evento de ontem à noite (O &lt;span class="caps"&gt;DNS&lt;/span&gt;
Poisoning) do Virtua foi o tipo de resposta que obtive das atendentes
dos SACs. A primeira atitute, como pode ser visto abaixo no sitrep, foi
tentar descobrir e confirmar o que estava ocorrendo, e tentar ver se …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Uma das coisas mais incríveis do evento de ontem à noite (O &lt;span class="caps"&gt;DNS&lt;/span&gt;
Poisoning) do Virtua foi o tipo de resposta que obtive das atendentes
dos SACs. A primeira atitute, como pode ser visto abaixo no sitrep, foi
tentar descobrir e confirmar o que estava ocorrendo, e tentar ver se
algo mais estava afetado. Após isso, comecei a ligar para os serviços de
atendimento. Primeiro foi o email para a &lt;span class="caps"&gt;RNP&lt;/span&gt;, confirmando o incidente de
segurança e enviando os logs produzidos por mim e pelo Rafael Walrus.
Esse é o procedimento padrão nesses casos, já que fica meio difícil
enviar um log via&amp;nbsp;telefone.&lt;/p&gt;
&lt;p&gt;Logo após isso, comecei, junto com o Walrus, a procurar um telefone para
entrar em contato com o Bradesco. Afinal, era o site deles que estava
sendo clonado&amp;#8230; consegui depois de uma ligação falar com uma atendente.
Ela não pareceu surpresa, mas não sabia sobre o que eu estava falando.
Ela conseguiu entender que tinha a ver com o site do netbanking, e
tentou me transferir para o setor, mas este só funciona de segunda a
sábado. Como assim? Um incidente de segurança desse nível, não um spam
qualquer de clique aqui, mas um nome legítimo sendo desviado,&amp;nbsp; e não
havia ninguém que poderia me entender? Deixei, no final, meu nome e
todas as informações que consegui passar para ela. Ela disse que iria
encaminhar para o departamento responsável.&amp;nbsp;Hum.&lt;/p&gt;
&lt;p&gt;Em seguida, começou a novela da &lt;span class="caps"&gt;NET&lt;/span&gt;. Imagina-se que uma empresa
prestadora de serviços de internet tenha um setor responsável pela
segurança da rede. E afinal, era o servidor de &lt;span class="caps"&gt;DNS&lt;/span&gt; &lt;em&gt;deles&lt;/em&gt; que estava
comprometido. A primeira mulher que me atendeu não acreditava no que eu
estava falando. Ela ria, sem saber o que estava acontecendo. Eu tentava
falar para ela que queria ser transferido para o setor de segurança, de
incidentes de segurança, no desespero apelei até para me transferir para
o setor de pirataria, mas nada. Ela simplesmente não conseguia entender
o que eu estava falando, coisas como &lt;span class="caps"&gt;DNS&lt;/span&gt;, página clonada. E eles são
&lt;em&gt;provedores de internet&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;A segunda ligação para a &lt;span class="caps"&gt;NET&lt;/span&gt; foi um pouco pior: depois da mulher não
entender mais uma vez o que eu estava falando, ela disse que ia falar
com o superior e desligou na minha cara. Simples assim.&amp;nbsp;Desligou.&lt;/p&gt;
&lt;p&gt;Na terceira vez eu consegui falar com o setor técnico. A moça pareceu me
entender melhor o que estava ocorrendo, mas mesmo assim, não sabia
direito. Foi perguntar para o supervisor, e voltou, depois de alguns
minutos, dizendo que as providências já estavam sendo tomadas.&amp;nbsp;Ufa.&lt;/p&gt;
&lt;p&gt;Logo após isso, o Walrus testou mais uma vez o dig no &lt;span class="caps"&gt;DNS&lt;/span&gt; deles, e ele
ainda estava de pé, &lt;em&gt;com o endereço errado de ip ainda.&lt;/em&gt; Grandes
providências estavam sendo&amp;nbsp;tomadas!&lt;/p&gt;
&lt;p&gt;Na manhã seguinte, o pessoal do &lt;span class="caps"&gt;CAIS&lt;/span&gt; respondeu dizendo que ia entrar em
contato com o Bradesco sobre o site. Não entendi muito bem, pois o
problema estava no &lt;span class="caps"&gt;DNS&lt;/span&gt; do virtua, mas achei que pelo menos alguma
providência iria ser tomada. O servidor coreano saiu do ar, e o &lt;span class="caps"&gt;DNS&lt;/span&gt; do
Virtua voltou a apontar para o endereço&amp;nbsp;certo.&lt;/p&gt;
&lt;p&gt;Fico na dúvida sobre o que estava acontecendo, e por que demorou tanto
tempo para ter alguma ação. Será que estavam investigando a origem do
ataque? Será que estavam tentando pegar quem tinha feito isso, e
precisavam deixar o &lt;span class="caps"&gt;DNS&lt;/span&gt; intacto? Coletando evidências? Acordando o
responsável? Consertando a falha sem derrubar um servidor &lt;span class="caps"&gt;DNS&lt;/span&gt;? E os
outros servidores de backup? Iriam ser inundados se desligassem o
servidor comprometido? Será que acharam que era fraude ou&amp;nbsp;trote?&lt;/p&gt;
&lt;p&gt;Fico sem&amp;nbsp;saber.&lt;/p&gt;
</content><category term="call center"></category><category term="dns"></category><category term="internet"></category><category term="net"></category><category term="security"></category><category term="virtua"></category></entry><entry><title>Resolução? - 4</title><link href="http://mfactor.sdf.org/blog/2009_04_13_resolution.html" rel="alternate"></link><published>2009-04-13T16:06:00-03:00</published><updated>2009-04-13T16:06:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-13:/blog/2009_04_13_resolution.html</id><summary type="html">&lt;p&gt;O Rafael Walrus fez um trabalho de documentação bem mais decente que o
meu - eu fiz quase um sitrep rápido. Juro que vou editar depois melhor o
post e repostar, com comentários meus. Segue o link do Walrus:
&lt;a class="reference external" href="http://stoa.usp.br/calsaverini/weblog/47528.html"&gt;http://stoa.usp.br/calsaverini/weblog/47528.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;O gosto amargo que …&lt;/p&gt;</summary><content type="html">&lt;p&gt;O Rafael Walrus fez um trabalho de documentação bem mais decente que o
meu - eu fiz quase um sitrep rápido. Juro que vou editar depois melhor o
post e repostar, com comentários meus. Segue o link do Walrus:
&lt;a class="reference external" href="http://stoa.usp.br/calsaverini/weblog/47528.html"&gt;http://stoa.usp.br/calsaverini/weblog/47528.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;O gosto amargo que o Walrus falou ficou &lt;strong&gt;bem&lt;/strong&gt; amargo na minha boca.
Quem já trabalho um pouco com segurança de redes sabe como é importante
a integridade dos dados do usuário e o tempo de resposta à incidentes. O
que aconteceu, pelo menos nas nossas descrições, foi um &lt;strong&gt;descalabro&lt;/strong&gt;.
E ou nos consideram completamente incapazes de entender sobre redes
&lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt;, e portanto fiquem quietinhos que a gente conserta nossos buracos
sem vocês perceberem e danem-se se se fodem, ou tem algo que não estou
conseguindo&amp;nbsp;entender.&lt;/p&gt;
&lt;p&gt;Mais tarde rola um&amp;nbsp;repost.&lt;/p&gt;
</content><category term="dns"></category><category term="dns poisoning"></category><category term="net"></category><category term="security"></category><category term="segurança"></category></entry><entry><title>Derrubado - 3</title><link href="http://mfactor.sdf.org/blog/2009_04_13_its_down.html" rel="alternate"></link><published>2009-04-13T11:33:00-03:00</published><updated>2009-04-13T11:33:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-13:/blog/2009_04_13_its_down.html</id><summary type="html">&lt;p&gt;O pessoal do &lt;span class="caps"&gt;CAIS&lt;/span&gt; respondeu hoje ao relatório do incidente de segurança,
dizendo que o pessoal do Bradesco foi avisado. O site coreano também
está inacessível agora. Não sei quem foi que fez o quê, mas pelo menos
isso. E ainda não tenho confirmação de que o &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua …&lt;/p&gt;</summary><content type="html">&lt;p&gt;O pessoal do &lt;span class="caps"&gt;CAIS&lt;/span&gt; respondeu hoje ao relatório do incidente de segurança,
dizendo que o pessoal do Bradesco foi avisado. O site coreano também
está inacessível agora. Não sei quem foi que fez o quê, mas pelo menos
isso. E ainda não tenho confirmação de que o &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua foi desligado
ou&amp;nbsp;consertado.&lt;/p&gt;
</content><category term="dns poisoning"></category><category term="net"></category><category term="south corea"></category></entry><entry><title>Continuação: DNS poisoning Virtua Bradesco - 2</title><link href="http://mfactor.sdf.org/blog/2009_04_12_dns_poisoning_3.html" rel="alternate"></link><published>2009-04-12T23:02:00-03:00</published><updated>2009-04-12T23:02:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-12:/blog/2009_04_12_dns_poisoning_3.html</id><summary type="html">&lt;p&gt;A história do &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua comprometido continua. Eis um scan das
portas da famigerada máquina na&amp;nbsp;Coréia:&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;nostromo:~$ nmap -P0&amp;nbsp;210.205.6.50&lt;/p&gt;
&lt;p&gt;Starting Nmap 4.68 ( &lt;a class="reference external" href="http://nmap.org"&gt;http://nmap.org&lt;/a&gt; ) at 2009-04-12 22:51 &lt;span class="caps"&gt;BRT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="mailto:ispmarin&amp;#64;nostromo"&gt;ispmarin&amp;#64;nostromo&lt;/a&gt;:~$ nmap&amp;nbsp;210.205.6.50&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Starting Nmap 4.68 ( &lt;a class="reference external" href="http://nmap.org"&gt;http://nmap …&lt;/a&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;p&gt;A história do &lt;span class="caps"&gt;DNS&lt;/span&gt; do Virtua comprometido continua. Eis um scan das
portas da famigerada máquina na&amp;nbsp;Coréia:&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;nostromo:~$ nmap -P0&amp;nbsp;210.205.6.50&lt;/p&gt;
&lt;p&gt;Starting Nmap 4.68 ( &lt;a class="reference external" href="http://nmap.org"&gt;http://nmap.org&lt;/a&gt; ) at 2009-04-12 22:51 &lt;span class="caps"&gt;BRT&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class="reference external" href="mailto:ispmarin&amp;#64;nostromo"&gt;ispmarin&amp;#64;nostromo&lt;/a&gt;:~$ nmap&amp;nbsp;210.205.6.50&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Starting Nmap 4.68 ( &lt;a class="reference external" href="http://nmap.org"&gt;http://nmap.org&lt;/a&gt; ) at 2009-04-12 22:52 &lt;span class="caps"&gt;BRT&lt;/span&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Interesting ports on 210.205.6.50:&lt;/div&gt;
&lt;div class="line"&gt;Not shown: 1698 closed ports&lt;/div&gt;
&lt;div class="line"&gt;&lt;span class="caps"&gt;PORT&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;STATE&lt;/span&gt;&amp;nbsp;&amp;nbsp;&amp;nbsp; &lt;span class="caps"&gt;SERVICE&lt;/span&gt;&lt;/div&gt;
&lt;div class="line"&gt;21/tcp&amp;nbsp;&amp;nbsp;&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ftp&lt;/div&gt;
&lt;div class="line"&gt;22/tcp&amp;nbsp;&amp;nbsp;&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; ssh&lt;/div&gt;
&lt;div class="line"&gt;25/tcp&amp;nbsp;&amp;nbsp;&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; smtp&lt;/div&gt;
&lt;div class="line"&gt;80/tcp&amp;nbsp;&amp;nbsp;&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; http&lt;/div&gt;
&lt;div class="line"&gt;110/tcp&amp;nbsp;&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; pop3&lt;/div&gt;
&lt;div class="line"&gt;135/tcp&amp;nbsp;&amp;nbsp; filtered msrpc&lt;/div&gt;
&lt;div class="line"&gt;136/tcp&amp;nbsp;&amp;nbsp; filtered profile&lt;/div&gt;
&lt;div class="line"&gt;137/tcp&amp;nbsp;&amp;nbsp; filtered netbios-ns&lt;/div&gt;
&lt;div class="line"&gt;138/tcp&amp;nbsp;&amp;nbsp; filtered netbios-dgm&lt;/div&gt;
&lt;div class="line"&gt;139/tcp&amp;nbsp;&amp;nbsp; filtered netbios-ssn&lt;/div&gt;
&lt;div class="line"&gt;199/tcp&amp;nbsp;&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; smux&lt;/div&gt;
&lt;div class="line"&gt;445/tcp&amp;nbsp;&amp;nbsp; filtered microsoft-ds&lt;/div&gt;
&lt;div class="line"&gt;3128/tcp&amp;nbsp; filtered squid-http&lt;/div&gt;
&lt;div class="line"&gt;3306/tcp&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; mysql&lt;/div&gt;
&lt;div class="line"&gt;4444/tcp&amp;nbsp; filtered krb524&lt;/div&gt;
&lt;div class="line"&gt;9876/tcp&amp;nbsp; open&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; sd&lt;/div&gt;
&lt;div class="line"&gt;17300/tcp filtered kuang2&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;Nmap done: 1 &lt;span class="caps"&gt;IP&lt;/span&gt; address (1 host up) scanned in 141.190&amp;nbsp;seconds&lt;/p&gt;
&lt;hr class="docutils" /&gt;
&lt;p&gt;Com um sd aberto, há uma chance muito boa de ser uma máquina invadida. É
Windows, para&amp;nbsp;variar&amp;#8230;&lt;/p&gt;
&lt;p&gt;Edit 23:39: kuang2 é uma espécie de vírus modificada para pegar senhas.
Lame. Resta saber o que vai virar a partir de agora. Sitrep agora está
em compasso de espera. Qualquer novidade,&amp;nbsp;posto.&lt;/p&gt;
</content><category term="history"></category><category term="net"></category><category term="security"></category><category term="virtua"></category></entry><entry><title>DNS poisoning on Virtua Servers - 1</title><link href="http://mfactor.sdf.org/blog/2009_04_12_dns_poisoning.html" rel="alternate"></link><published>2009-04-12T20:13:00-03:00</published><updated>2009-04-12T20:13:00-03:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-04-12:/blog/2009_04_12_dns_poisoning.html</id><summary type="html">&lt;p&gt;Alerta: Walrus acabou de achar um provável &lt;span class="caps"&gt;DNS&lt;/span&gt; Poisoning no &lt;span class="caps"&gt;DNS&lt;/span&gt; do
Virtua 201.6.0.43. O post dele está em
&lt;a class="reference external" href="http://stoa.usp.br/walrus/weblog/47454.html"&gt;post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;**Estou confirmando agora as informações usando o dig nesse &lt;span class="caps"&gt;DNS&lt;/span&gt; contra
as informações do whois da &lt;span class="caps"&gt;RNP&lt;/span&gt;. Vou atualizar conforme mais informações
forem&amp;nbsp;chegando.**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Atualmente este &lt;span class="caps"&gt;DNS …&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;</summary><content type="html">&lt;p&gt;Alerta: Walrus acabou de achar um provável &lt;span class="caps"&gt;DNS&lt;/span&gt; Poisoning no &lt;span class="caps"&gt;DNS&lt;/span&gt; do
Virtua 201.6.0.43. O post dele está em
&lt;a class="reference external" href="http://stoa.usp.br/walrus/weblog/47454.html"&gt;post&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;**Estou confirmando agora as informações usando o dig nesse &lt;span class="caps"&gt;DNS&lt;/span&gt; contra
as informações do whois da &lt;span class="caps"&gt;RNP&lt;/span&gt;. Vou atualizar conforme mais informações
forem&amp;nbsp;chegando.**&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Atualmente este &lt;span class="caps"&gt;DNS&lt;/span&gt; está derrubado! - correção 22:31: ainda está de&amp;nbsp;pé!!!&lt;/strong&gt;&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;**Edit 20:16: o &lt;span class="caps"&gt;DNS&lt;/span&gt; 201.6.0.43 está derrubado, e o outro &lt;span class="caps"&gt;DNS&lt;/span&gt; para
&lt;span class="caps"&gt;SP&lt;/span&gt;, 201.6.0.113, está recusando acessos via dig.**&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;Se você estiver no linux, teste os seus dns da seguinte forma:&lt;/strong&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;dig &amp;#64;&amp;lt;nameserver&amp;gt; &amp;lt;site de&amp;nbsp;banco&amp;gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;assim:&lt;/strong&gt; dig &amp;#64;189.7.80.15&amp;nbsp;www.bradesco.com.br&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;e vejam se a informação bate com a do whois&amp;nbsp;brasileiro:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;whois&amp;nbsp;www.bradesco.com.br&lt;/p&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;Edit 20:22: esse erro continua sendo confirmado por Walrus a partir
de um virtua de &lt;span class="caps"&gt;SP&lt;/span&gt;. Estamos montando os logs para enviar para a &lt;span class="caps"&gt;RNP&lt;/span&gt;&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;Edit 20:32: confirmado que o &lt;span class="caps"&gt;IP&lt;/span&gt; é sul-coreano, e o site é uma
reprodução fiel do site do bradesco - Walrus está checando outros
sites nesse &lt;span class="caps"&gt;DNS&lt;/span&gt;, eu estou tentando, mas aqui de &lt;span class="caps"&gt;SC&lt;/span&gt; está dando time
out&lt;/strong&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;Edit 21:40: Report de segurança foi enviado para a &lt;span class="caps"&gt;RNP&lt;/span&gt;, estou
tentando entrar em contato com o &lt;span class="caps"&gt;SAC&lt;/span&gt; do Bradesco, e não tem
ninguém!!!&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;Edit 21:44: Consegui entrar em contato com uma atendente do
Bradesco. Ela anotou os dados que eu passei e disse que a equipe do
internet banking funciona de segunda&amp;nbsp; a sábado (!!!). Pelo menos ela
anotou, e disse que vai retornar com informações. Agora, passo de
aguardo.&lt;/strong&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;p&gt;&lt;strong&gt;Edit 22:16: O Daniel sugeriu ligar para a Net. No telefone com eles&amp;nbsp;agora.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Edit 22:21: O Rafael Walrus postou algo mais detalhado em
&lt;a class="reference external" href="http://stoa.usp.br/calsaverini/weblog/47461.html.Email"&gt;em&lt;/a&gt; para a Folha foi&amp;nbsp;enviado.&lt;/p&gt;
&lt;p&gt;Edit 22:27: a atendente da &lt;span class="caps"&gt;NET&lt;/span&gt; não consegue me transferir para alguém
que saiba o que é um incidente de&amp;nbsp;segurança!&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Edit 22:33: A mulher do setor técnico da &lt;span class="caps"&gt;NET&lt;/span&gt; &lt;span class="caps"&gt;DESLIGOU&lt;/span&gt; na minha&amp;nbsp;cara.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Edit 22:45: consegui falar com uma atendente da &lt;span class="caps"&gt;NET&lt;/span&gt;, e ela disse que
este assunto está sendo verificado. Mas o Rafael ainda consegue fazer
dig no &lt;span class="caps"&gt;DNS&lt;/span&gt; comprometido, e o ip errado continua&amp;nbsp;lá.&lt;/p&gt;
</content><category term="dns"></category><category term="dns poisoning"></category><category term="net"></category><category term="net security"></category><category term="sitrep"></category><category term="third post"></category></entry><entry><title>3 Smart things about sleeping late</title><link href="http://mfactor.sdf.org/blog/2009_01_03_sleeping_late.html" rel="alternate"></link><published>2009-01-03T01:38:00-02:00</published><updated>2009-01-03T01:38:00-02:00</updated><author><name>Ivan Marin</name></author><id>tag:mfactor.sdf.org,2009-01-03:/blog/2009_01_03_sleeping_late.html</id><summary type="html">&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;1 // You may need more sleep than you think.&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Research by Henry Ford Hospital Sleep Disorders Center found that
people who slept eight hours and then claimed they were &amp;#8220;well rested&amp;#8221;
actually performed better and were more alert if they slept another
two hours. That figures. Until the invention of …&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;</summary><content type="html">&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;1 // You may need more sleep than you think.&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Research by Henry Ford Hospital Sleep Disorders Center found that
people who slept eight hours and then claimed they were &amp;#8220;well rested&amp;#8221;
actually performed better and were more alert if they slept another
two hours. That figures. Until the invention of the lightbulb (damn
you, Edison!), the average person slumbered &lt;a class="reference external" href="http://www.msnbc.msn.com/id/23052850/page/2/"&gt;10
hours&lt;/a&gt; a night.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;2 // Night owls are more creative.&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;Artists, writers, and coders typically fire on all cylinders by
crashing near dawn and awakening at the crack of noon. In one study,
&amp;#8220;evening people&amp;#8221; &lt;a class="reference external" href="http://www.abc.net.au/science/news/stories/2006/1810399.htm"&gt;almost
universally&lt;/a&gt;
slam-dunked a standardized creativity test. Their early-bird brethren
struggled for passing scores.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;&lt;strong&gt;3 // Rising early is stressful.&lt;/strong&gt;&lt;/div&gt;
&lt;div class="line-block"&gt;
&lt;div class="line"&gt;The stress hormone cortisol &lt;a class="reference external" href="http://www.ncbi.nlm.nih.gov/pubmed/176503?dopt=Abstract"&gt;peaks in your
blood&lt;/a&gt;
around 7 am. So if you get up then, you may experience tension. Grab
some extra Zs! You&amp;#8217;ll wake up feeling less like Bert, more like Ernie.&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</content><category term="personal"></category></entry></feed>