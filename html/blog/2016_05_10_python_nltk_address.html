<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags always come first -->
  <meta charset="utf-8">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Address normalization with Python and NLTK | Another Life Form
</title>
  <link rel="canonical" href="http://mfactor.sdf.org/blog/2016_05_10_python_nltk_address.html">

  <link rel="alternate" type="application/atom+xml" href="http://mfactor.sdf.org/blog/feeds/all.atom.xml" title="Full Atom Feed">
  <link rel="alternate" type="application/atom+xml" href="http://mfactor.sdf.org/blog/feeds/data-science.atom.xml" title="Categories Atom Feed">


  <link rel="stylesheet" href="http://mfactor.sdf.org/blog/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="http://mfactor.sdf.org/blog/theme/css/font-awesome.min.css">
  <link rel="stylesheet" href="http://mfactor.sdf.org/blog/theme/css/pygments/monokai.min.css">
  <link rel="stylesheet" href="http://mfactor.sdf.org/blog/theme/css/style.css">


<meta name="description" content="Address normalization and match">
</head>

<body>
  <header class="header">
    <div class="container">
      <div class="row">
        <div class="col-sm-12">
          <h1 class="title"><a href="http://mfactor.sdf.org/blog">Another Life Form</a></h1>
          <p class="text-muted">Science, Data Science and Python</p>
          <ul class="list-inline">
            <li class="list-inline-item"><a href="https://br.linkedin.com/in/ispmarin/en" target="_blank">linkedin</a></li>
            <li class="list-inline-item"><a href="https://github.com/ispmarin" target="_blank">github</a></li>
            <li class="list-inline-item text-muted">|</li>
            <li class="list-inline-item"><a href="http://mfactor.sdf.org/blog/pages/about.html">About</a></li>
          </ul>
        </div>
      </div>
    </div>
  </header>

  <div class="main">
    <div class="container">
      <h1>Address normalization with Python and <span class="caps">NLTK</span>
</h1>
      <hr>
<article class="article">
  <header>
    <ul class="list-inline">
      <li class="list-inline-item text-muted" title="2016-05-10T00:00:00-03:00">
        <i class="fa fa-clock-o"></i>
        ter 10 maio 2016
      </li>
      <li class="list-inline-item">
        <i class="fa fa-folder-open-o"></i>
        <a href="http://mfactor.sdf.org/blog/category/data-science.html">data science</a>
      </li>
      <li class="list-inline-item">
        <i class="fa fa-user-o"></i>
        <a href="http://mfactor.sdf.org/blog/author/ivan-marin.html">Ivan Marin</a>      </li>
      <li class="list-inline-item">
        <i class="fa fa-files-o"></i>
        <a href="http://mfactor.sdf.org/blog/tag/data-science.html">#data science</a>,         <a href="http://mfactor.sdf.org/blog/tag/nlp.html">#NLP</a>,         <a href="http://mfactor.sdf.org/blog/tag/text-mining.html">#text mining</a>      </li>
    </ul>
  </header>
  <div class="content">
    <p>Addresses in databases, especially ones that are inserted by human operators, are prone to a wide range of forms and errors.
To be able to correctly identify a location from a address and to compare two entities we need to normalize them.
(We&#8217;re calling normalization both the entire process and one of the processing&nbsp;steps.)</p>
<p>Two problems: first is to identify address on a string by field, with errors; second is to match with existing address database to remove&nbsp;uncertanty.</p>
<h2>Preparation&nbsp;steps</h2>
<p>To start tackling the problem we have first to prepare the data. The usual steps for that&nbsp;are:</p>
<ul>
<li>normalization</li>
<li>stemming</li>
<li>lemmatization</li>
<li>segmentation&nbsp;(tokenization)</li>
<li>text&nbsp;rebuild</li>
</ul>
<h3>Normalization</h3>
<p>Normalization consists on transforming the text to a canonical form (equal to all entries) so they can be compared.
The usual steps&nbsp;are</p>
<ul>
<li>standardize&nbsp;encoding</li>
<li>remove&nbsp;punctuation</li>
<li>transform to&nbsp;lowercase</li>
<li>remove stopwords and punctuation (with&nbsp;care!)</li>
<li>separate prefixes and suffixes that doesn&#8217;t contain&nbsp;information</li>
</ul>
<h3>Stemming</h3>
<p>Stemming is the process of reducing words in different forms (conjugated verbs, plural) to a radical form.
This step is not useful for addresses because most of the addresses are not in different forms.
Proper names, for example, are very common in addresses and don&#8217;t benefit a lot from&nbsp;stemming.</p>
<h2>Lemmatization</h2>
<p>As we&#8217;re not going to stem the words, we also don&#8217;t need to lemmatizate them.
Lemmatization is the process of grouping together the flexionated forms of the words so they can be analysed&nbsp;together.</p>
<h3>Segmentation</h3>
<p>Segmentation is the task of breaking up the text into tokens, so each token can be analysed separately.
In our case, the tokenization can be done by address field: preffixes, location, complements and suffixes. For example, the&nbsp;address</p>
<p><code>Rua Nove de Julho, 2983 ap 33 bloco 1 CEP 00043-424 São Paulo SP</code></p>
<p>can be break up&nbsp;into</p>
<ul>
<li>Preffix: <code>Rua</code></li>
<li>Location: <code>Nove de Julho 2983</code></li>
<li>Complements: <code>ap 33 bloco 1 CEP 00043-424</code></li>
<li>Suffixes: <code>São Paulo SP</code></li>
</ul>
<p>This is helpful because now we can match each part of the address with an existing canonical form without a lot of noise.
Each of the fields can be further processed to extract more information, like the postal code&nbsp;number.</p>
<h3>Parsing</h3>
<p>The next step is to parse the address.
Parsing consists in break up the address string into fields that compose the address, the breaking up of the fields
mentioned above. To parse we have to assume a structure for the address, either by rules or by some techiques like
 Named Entity&nbsp;Recognization.</p>
<h3>Rebuild&nbsp;text</h3>
<p>This task consists in rebuild the normalized and annotated text to a final form. This will be done after the match&nbsp;phase.</p>
<h2>Identification and&nbsp;Match</h2>
<p>After cleaning up and normalizing the text we need to check if the value of the address exists in our canonical database. Two&nbsp;approaches:</p>
<ol>
<li>Match with existing&nbsp;database</li>
<li>Name Entity Recognition on&nbsp;address</li>
</ol>
<h3>Match with canonical&nbsp;database</h3>
<p>If we have a canonical database with the data considered correct, our job is to match the target addresses with the ones
on this canonical database. This is a <em>match problem</em>. We can attack this problem following these&nbsp;steps:</p>
<ul>
<li>split address by field (prefix, location,&nbsp;suffixes)</li>
<li>retrieve match candidates (search&nbsp;engine)</li>
<li>Match address with candidates by&nbsp;similarity</li>
</ul>
<p>For this approach we&#8217;re going to work directly on the text patterns, without any kind of machine learning.
The canonical database is usually provided by the Post&nbsp;Office.</p>
<p>The match between two addresses is a way to check if two addresses are the same.
For example, let&#8217;s say that we have in our canonical database the&nbsp;entry</p>
<table>
<thead>
<tr>
<th><span class="caps">CEP</span></th>
<th>Location</th>
<th>City</th>
<th>State</th>
</tr>
</thead>
<tbody>
<tr>
<td>00043243</td>
<td>Nove de Julho</td>
<td>São Paulo</td>
<td><span class="caps">SP</span></td>
</tr>
<tr>
<td>00032312</td>
<td>Nove de Setembro</td>
<td>São Paulo</td>
<td><span class="caps">SP</span></td>
</tr>
</tbody>
</table>
<p>and we need to compare with the address above. Which one is the best match?
We could try to do an exact match: only the location strings that are exactly same are the same address.
But this would miss lots of entries that could have typing errors but are otherwise valid addresses,&nbsp;like</p>
<p><code>Rua nov de Julho, 2938</code></p>
<p>So how do we compensate for these&nbsp;errors?</p>
<h3>Match</h3>
<p>One approach is to retrieve candidates from the canonical database that are similar to the address we want to normalize. Search engines do that using different strategies. We&#8217;re not going to detail this process, so let&#8217;s just say that our search engine returned candidates to be&nbsp;compared.</p>
<p>For each of these candidates we do a comparison with our target address using some metric of similarity. There are several of such&nbsp;metrics:</p>
<ul>
<li>Jaro&nbsp;distance</li>
<li>Jaro-Winkler&nbsp;distance</li>
<li>Cosine&nbsp;distance</li>
</ul>
<p>For now we&#8217;re going to use Jaro-Winkler distance. We compare the target address with each of the candidates and rank by the similarity between&nbsp;them.</p>
<h4>Search&nbsp;engines</h4>
<p>Search engines usually already make the string similarity comparison to retrive the candidates, so it could, in principle, already compute the similarity score withou the need to program it by ourselves. But sometimes the search engine similarity algorithm cannot be tuned to the type of text, like addresses. We also have more information than only the Location string, like the postal code and suffixes. This could help in the decision&nbsp;process.</p>
<h3><span class="caps">NER</span></h3>
<p>Instead of using regular expressions to break up the address text into components we could create a Named Entity Recognizer and let it separate the address by&nbsp;fields.</p>
<ul>
<li>tag canonical database with relevant&nbsp;tags</li>
<li>train <span class="caps">CRF</span> with tagged&nbsp;database</li>
<li>classify each&nbsp;address</li>
<li>match classified entity with canonical&nbsp;base</li>
</ul>
<h2>Decision&nbsp;process</h2>
<p>After the text normalization and match we hopefully have a list of candidates with a similarity score between the target and a canonical address. How we decide if the address is indeed the correct address? We can set a score threshold, for example, based on our experience, and test the error rate. We also can create a classification model and train manually with some&nbsp;entries.</p>
<h2>In&nbsp;Python</h2>
<p>Let&#8217;s show the steps above now with some Python and the Natural Language&nbsp;Toolkit.</p>
  </div>
</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
      <div class="row">
       <ul class="col-sm-6 list-inline">
          <li class="list-inline-item"><a href="http://mfactor.sdf.org/blog/authors.html">Authors</a></li>
          <li class="list-inline-item"><a href="http://mfactor.sdf.org/blog/archives.html">Archives</a></li>
          <li class="list-inline-item"><a href="http://mfactor.sdf.org/blog/categories.html">Categories</a></li>
          <li class="list-inline-item"><a href="http://mfactor.sdf.org/blog/tags.html">Tags</a></li>
        </ul>
        <p class="col-sm-6 text-sm-right text-muted">
          Generated by <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a> / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>
        </p>
      </div>
    </div>
  </footer>
</body>

</html>